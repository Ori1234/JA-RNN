{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis 8 march",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ori1234/JA-RNN/blob/master/Thesis_8_march.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oFP8V9qDldY",
        "colab_type": "text"
      },
      "source": [
        "https://webcache.googleusercontent.com/search?q=cache:viNLSTwuTS0J:https://www.reddit.com/r/datascience/comments/bkrzah/google_colab_how_to_avoid_timeoutdisconnect_issues/+&cd=2&hl=en&ct=clnk&gl=il\n",
        "\n",
        "Go to the google Colab console (ctrl+shift+i)\n",
        "\n",
        "Dont exit the console until you get \"Working\" as the output in the console window.\n",
        "\n",
        "\n",
        "Note to self: Make sure you dont run anything for more than 12 hrs on Colab\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "function ClickConnect(){console.log(\"Working\");if (document.querySelector(\"paper-button#ok\")!=null){document.querySelector(\"paper-button#ok\").click()}}val=setInterval(ClickConnect,60000)\n",
        "\n",
        "clearInterval(val)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ltiajqo3ptE",
        "colab_type": "text"
      },
      "source": [
        "**SUMMERY**\n",
        "\n",
        "say somthing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdTdNSHUmCvD",
        "colab_type": "text"
      },
      "source": [
        "#IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roia04jL0jCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"IMPORTS\"\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import math\n",
        "from termcolor import colored, cprint\n",
        "import editdistance\n",
        "\n",
        "\n",
        "#We recommend you upgrade now or ensure your notebook will continue to use TensorFlow 1.x via the %tensorflow_version 1.x magic: more info.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVSrDNbLhC7H",
        "colab_type": "text"
      },
      "source": [
        "#GLOBAL VARS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1fPaxl8g_BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "this_time=str(datetime.now())\n",
        "GLOBAL_epoch=0\n",
        "DEBUG=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AndYz46gsER",
        "colab_type": "text"
      },
      "source": [
        "#LOGGING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldvhaPtVF0Kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######To clean logs\n",
        "######!rm log*.log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raxiE-PU7A-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e12c3d71-766f-40d8-a588-3852ff0b4b57"
      },
      "source": [
        "CELL_NAME=\"START LOG\"\n",
        "\n",
        "\n",
        "log_file=\"LOG___\"+this_time+\".txt\"\n",
        "f_logg= open(log_file,\"w\")\n",
        "print(\"logging to file (will be added to mail)\",log_file)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _print_log(also_print,*txts):  \n",
        "  txt=\"\"\n",
        "  for t in txts:\n",
        "    txt+=\" \"+str(t)\n",
        "  f_logg.write(CELL_NAME+\" \"+str(datetime.now())+\": \"+txt+'\\n') #TODO ADD TIME!!!!\n",
        "  if also_print:\n",
        "    print(*txts)\n",
        "\n",
        "def print_log(*txts):\n",
        "  if (DEBUG):\n",
        "    print(*txts)\n",
        "  _print_log(False,*txts)\n",
        "\n",
        "\n",
        "def print_log_screen(*txts):\n",
        "  _print_log(True,*txts)\n",
        "\n",
        "\n",
        "def log_flush():\n",
        "  f_logg.flush()\n",
        "\n",
        "def close_log():\n",
        "  f_logg.close()\n",
        "\n",
        "\n",
        "\n",
        "#DON'T FORGET TO CLOSE THE FILE AT THE END\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logging to file (will be added to mail) LOG___2020-05-07 13:02:50.491787.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh93f3m4fb3Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3b5f63f1-bbcc-453e-a72f-3c23ed0744a9"
      },
      "source": [
        "\n",
        "#PAIST HERE TO SEE PROPERLY THE SHOW DIFF PART IN LOGS\n",
        "text='''MAIN:  (1) ‫ אלא באד'נה . פכיפ לא | إلاّ بإذنه . فكيف لا | إلاّ بإذنه . فكيف لا | 0.0000\n",
        "MAIN:  (2) ‫ להמ , ולטלבוא וג'והא | لهم , ولطلبوا وجوها\u001b[1m\u001b[31mً\u001b[0m | لهم , ولطلبوا وجوها | 0.0500\n",
        "MAIN:  (3) ‫ , ודפעהמא אלי מוסי H | , ودفعهما إلى موسى H | , ودفعهما إلى موسى H | 0.0000\n",
        "MAIN:  LER (label error rate):  0.033400332030791034'''\n",
        "print(text)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAIN:  (1) ‫ אלא באד'נה . פכיפ לא | إلاّ بإذنه . فكيف لا | إلاّ بإذنه . فكيف لا | 0.0000\n",
            "MAIN:  (2) ‫ להמ , ולטלבוא וג'והא | لهم , ولطلبوا وجوها\u001b[1m\u001b[31mً\u001b[0m | لهم , ولطلبوا وجوها | 0.0500\n",
            "MAIN:  (3) ‫ , ודפעהמא אלי מוסי H | , ودفعهما إلى موسى H | , ودفعهما إلى موسى H | 0.0000\n",
            "MAIN:  LER (label error rate):  0.033400332030791034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF7hxxLw2gZp",
        "colab_type": "text"
      },
      "source": [
        "#Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seUeDrwE2cb7",
        "colab_type": "code",
        "outputId": "c9ae3c4a-4783-4888-b18f-8bb45de3346c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "CELL_NAME=\"MOUNT DRIVE\"\n",
        "print(\"mounting to drive at /gdrive\")\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mounting to drive at /gdrive\n",
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6lTDTAb9VqY",
        "colab_type": "text"
      },
      "source": [
        "#MODEL PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ8uN3dj9Uhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "10b8376e-0096-42bb-d548-7395f892e9d8"
      },
      "source": [
        "CELL_NAME=\"BATCH_SIZE and STATEFUL\"\n",
        "\n",
        "STATEFUL=False\n",
        "BATCH_SIZE = 128\n",
        "TO_SHUFFLE=True\n",
        "\n",
        "embedding_dim = 8\n",
        "rnn_units = 1024\n",
        "\n",
        "\n",
        "print_log_screen(\"set batch size to \"+str(BATCH_SIZE))\n",
        "print_log_screen(\"STATEFUL: \"+str(STATEFUL))\n",
        "print_log_screen(\"embedding_dim: \"+str(embedding_dim))\n",
        "print_log_screen(\"rnn_units: \"+str(rnn_units))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "set batch size to 128\n",
            "STATEFUL: False\n",
            "embedding_dim: 8\n",
            "rnn_units: 1024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMwuVCRK0upw",
        "colab_type": "text"
      },
      "source": [
        "# INIT RANDOM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_gEIvtr0znU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"RANDOM SEED\"\n",
        "\n",
        "#https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\n",
        "def init_random():\n",
        "  print_log_screen(\"init random to 1\")\n",
        "  np.random.seed(1)\n",
        "  tf.compat.v1.set_random_seed(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUbUyZx3i1OB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"RANDOM SEED\"\n",
        "init_random()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn9DB__L2M9g",
        "colab_type": "text"
      },
      "source": [
        "#CONSTANTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57tqrGT52Nrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arab_nikud=[u\"\\u0652\",u\"\\u0650\", u\"\\u064F\",u\"\\u064E\", ]#sukuun,kasra, Damma,# fatHa\n",
        "tanween=[u\"\\u064B\", # fatHatayn\n",
        "         u\"\\u064C\", # Dammatayn\n",
        "         u\"\\u064D\", ]\n",
        "shada=u\"\\u0651\"\n",
        "\n",
        "hamza_on_line=u\"\\u0621\"\n",
        "\n",
        "LTRchar=u'\\u202B'   #align rtl symbole\n",
        "BLANK=\"_\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBZBFNnRFscK",
        "colab_type": "text"
      },
      "source": [
        "#UTILS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXctuG0ZIwCT",
        "colab_type": "text"
      },
      "source": [
        "##show diff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWhnKORfyw8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"DEF show diff\"\n",
        "import difflib\n",
        "\n",
        "def show_diff(t1,t2,col):\n",
        "    \"\"\"Unify operations between two compared strings\n",
        "seqm is a difflib.SequenceMatcher instance whose a & b are strings\"\"\"\n",
        "    seqm= difflib.SequenceMatcher(None,t1,t2)   \n",
        "    output1=[]\n",
        "    output2= []\n",
        "    for opcode, a0, a1, b0, b1 in seqm.get_opcodes():\n",
        "        \n",
        "        if opcode == 'equal':            \n",
        "            output1.append(seqm.a[a0:a1])\n",
        "            output2.append(seqm.b[b0:b1])\n",
        "        elif opcode == 'insert':            \n",
        "            output2.append(colored(seqm.b[b0:b1],col,attrs=['bold']))\n",
        "        elif opcode == 'delete':\n",
        "            output1.append(colored(seqm.a[a0:a1],col,attrs=['bold']))\n",
        "        elif opcode == 'replace':            \n",
        "            output1.append(colored(seqm.a[a0:a1],col,attrs=['bold']))\n",
        "            output2.append(colored(seqm.b[b0:b1],col,attrs=['bold']))\n",
        "        else:\n",
        "            raise RuntimeError(\"unexpected opcode\")\n",
        "    return ''.join(output1),''.join(output2)\n",
        "\n",
        "# #USEAGE:\n",
        "# s1=\"لامة النصارى واستحقو\" \n",
        "# s2=\"لأمّة النصارى واستحقوّا\"\n",
        "# a,b=show_diff(s1,s2,'blue')\n",
        "# #print_log(\"\".join(b))\n",
        "# print_log(a,\"|\",b)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2EONT-4FvdF",
        "colab_type": "text"
      },
      "source": [
        "##send mail"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6YGN7tvFu2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"SEND MAIL\"\n",
        "\n",
        "#NEED TO ALLOW LESS SECURE APPS AT:  \n",
        "#https://myaccount.google.com/lesssecureapps?utm_source=google-account&utm_medium=web\n",
        "\n",
        "#Send Alert Email at finish with GMail\n",
        "##ref: https://webcache.googleusercontent.com/search?q=cache:peuNIUcC5eAJ:https://rohitmidha23.github.io/Colab-Tricks/+&cd=1&hl=en&ct=clnk&gl=il\n",
        "#https://www.google.com/search?safe=strict&rlz=1C1SQJL_iwIL818IL818&sxsrf=ACYBGNQn05BVmX0bKCQOdxEZsOV8sylztA%3A1568909507810&ei=w6iDXeKYMZLSxgO1qYSICg&q=smtplib.smtp+sendmail+attachment&oq=smtplib.smtp+sendmail+att&gs_l=psy-ab.3.0.33i21j33i160.1435.2378..3438...0.2..0.188.632.0j4......0....1..gws-wiz.......0i71j0j0i22i30.7MbuYV36t10\n",
        "####how to define app password see: https://kinsta.com/knowledgebase/free-smtp-server/\n",
        "\n",
        "import smtplib\n",
        "from os import path\n",
        "from os.path import basename\n",
        "from email.mime.application import MIMEApplication\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from email.utils import COMMASPACE, formatdate\n",
        "\n",
        "def send_results(subject,description):\n",
        "  THISTHIS=\"qczvfrlypitxxsfc\"\n",
        "\n",
        "  server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "  #server = smtplib.SMTP('localhost')\n",
        "  server.starttls()\n",
        "  server.login(\"kuti.sulimani@gmail.com\", THISTHIS)\n",
        "\n",
        "  msg = MIMEMultipart()\n",
        "  msg['From'] = \"sender_gmail_here@gmail.com\"\n",
        "  msg['To'] = COMMASPACE.join([\"oriterner@gmail.com\"])\n",
        "  msg['Date'] = formatdate(localtime=True)\n",
        "  msg['Subject'] = subject\n",
        "\n",
        "\n",
        "  msg.attach(MIMEText(description))\n",
        "  files=[log_file,\"/content/train.png\",\"/content/test.png\",\"/content/accuracys.png\",\"/content/my_log.txt\"]  #list of graphs to send or logs....\n",
        "  for f in files or []:\n",
        "      if not path.exists(f):\n",
        "        continue\n",
        "      with open(f, \"rb\") as fil:\n",
        "          part = MIMEApplication(\n",
        "              fil.read(),\n",
        "              Name=basename(f)\n",
        "          )\n",
        "      # After the file is closed\n",
        "      part['Content-Disposition'] = 'attachment; filename=\"%s\"' % basename(f)\n",
        "      msg.attach(part)\n",
        "\n",
        "\n",
        "  server.sendmail(\"sender_gmail_here@gmail.com\", \"oriterner@gmail.com\", msg.as_string())\n",
        "  server.quit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzg25sCsGdYP",
        "colab_type": "text"
      },
      "source": [
        "##plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFDNZ49DGcgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"PLOT\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "losses=[1,2,3]\n",
        "def my_plot_save(data_series,save_name,decor='r--'):\n",
        "  t = range(0, len(data_series))\n",
        "  plt.plot(t, data_series, decor)\n",
        "  plt.savefig(save_name) #\"/content/foo.png\"\n",
        "  plt.show()\n",
        "#my_plot_save(losses,\"train.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zQtssRgtEvv1"
      },
      "source": [
        "##letter mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kMPZNXh4Zoz",
        "colab_type": "code",
        "outputId": "ac0f4ce6-78d5-46b7-fda4-b2dc6fe80eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "CELL_NAME=\"LETTER MAPPING\"\n",
        "\n",
        "tag=\"'\"\n",
        "\n",
        "additional_letters=\".H,?:;[]()!-\\\" 0123456789\"+tag\n",
        "\n",
        "#\"א\": \"اإآٱأ\", with wasla\n",
        "letter_dict={   #make sure all are here\n",
        "    \"א\": \"اإآٱأ\",\n",
        "    \"ב\":\"ب\" ,\n",
        "    \"ג\":\"غ\",\n",
        "    \"ג\"+tag:\"ج\",\n",
        "    \"ד\":\"د\",\n",
        "    \"ד\"+tag:\"ذ\",\n",
        "    \"ה\":\"ه\",\n",
        "    \"ה\"+tag:\"ة\",\n",
        "    \"ו\":\"وؤ\",\n",
        "    \"ז\":\"ز\",\n",
        "    \"ח\":\"ح\",\n",
        "    \"ט\":\"ط\",\n",
        "    \"ט\"+tag:\"ظ\",\n",
        "    \"י\":\"يىئ\",\n",
        "    \"כ\":\"ك\",\n",
        "    \"כ\"+tag:\"خ\",\n",
        "    \"ל\":\"ل\",\n",
        "    \"מ\":\"م\",\n",
        "    \"נ\":\"ن\",\n",
        "    \"ס\":\"س\",\n",
        "    \"ע\":\"ع\",\n",
        "    \"פ\":\"ف\",\n",
        "    \"צ\":\"ص\",\n",
        "    \"צ\"+tag:\"ض\",\n",
        "    \"ק\":\"ق\",\n",
        "    \"ר\":\"ر\",\n",
        "    \"ש\":\"ش\",\n",
        "    \"ת\":\"ت\",\n",
        "    \"ת\"+tag:\"ث\",\n",
        "}\n",
        "#######################################################\n",
        "for c in additional_letters:\n",
        "  letter_dict[c]=c\n",
        "\n",
        "arab_heb_maping={}\n",
        "heb_arab_maping={}\n",
        "for heb,arr in letter_dict.items():\n",
        "  heb_arab_maping[heb]=arr[0]\n",
        "  for a in arr:\n",
        "    arab_heb_maping[a]=heb\n",
        "\n",
        "\n",
        "print_log(\"arab_heb_maping\",arab_heb_maping)\n",
        "print_log(\"length:\",len(arab_heb_maping))\n",
        "print_log(\"heb_arab_maping\",heb_arab_maping)\n",
        "print_log(\"length:\",len(heb_arab_maping))\n",
        "\n",
        "#################################################################3\n",
        "#FUNCTIONS:\n",
        "\n",
        "def remove_chars_not_in_map(phrase,map):\n",
        "  res=[]\n",
        "  for c in phrase:  \n",
        "    if c in map:\n",
        "      res.append(c)\n",
        "    else:\n",
        "      print_log(LTRchar+\"Skipping char not in predefined map\\n ( \"+c+\" )\\nin sentences:\\n\"+phrase+'\\n')      \n",
        "  return \"\".join(res)\n",
        "\n",
        "def remove_chars_not_in_JA_map(ja):\n",
        "  return remove_chars_not_in_map(ja,heb_arab_maping)\n",
        "\n",
        "extended_arab_chars=list(arab_heb_maping.keys())\n",
        "extended_arab_chars+=tanween\n",
        "extended_arab_chars.append(shada)\n",
        "extended_arab_chars.append(hamza_on_line)\n",
        "\n",
        "def remove_chars_not_in_arab_map(arr):\n",
        "  return remove_chars_not_in_map(arr,extended_arab_chars)\n",
        "\n",
        "\n",
        "def simple_letter_map(heb_str): \n",
        "  res=[]\n",
        "  tag=\"'\"\n",
        "  iterator = iter(range(len(heb_str)))\n",
        "  for i in iterator:\n",
        "    if i+1!=len(heb_str) and heb_str[i+1]==tag:     \n",
        "      if heb_str[i]+tag in heb_arab_maping:\n",
        "        ar_leter=heb_arab_maping[heb_str[i]+tag]\n",
        "        res.append(ar_leter)\n",
        "      else:\n",
        "        ar_leter=heb_arab_maping[heb_str[i]]\n",
        "        res.append(ar_leter)\n",
        "        res.append(tag)\n",
        "      next(iterator, None)\n",
        "    else:      \n",
        "      ar_leter=heb_arab_maping[heb_str[i]]\n",
        "      res.append(ar_leter)\n",
        "  return \"\".join(res)     \n",
        "\n",
        "\n",
        "def reverse_simple_map(arr_str):\n",
        "  ja_str=[]\n",
        "  for c in arr_str:\n",
        "    if c in arab_heb_maping:\n",
        "      ja_str.append(arab_heb_maping[c])\n",
        "    #else:\n",
        "      #print_log(\"reverse_simple_map: char ( \"+c+\" ) not in letter mapping and will be skiped\")\n",
        "      #print_log(arr_str)\n",
        "  return \"\".join(ja_str)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arab_heb_maping {'ا': 'א', 'إ': 'א', 'آ': 'א', 'ٱ': 'א', 'أ': 'א', 'ب': 'ב', 'غ': 'ג', 'ج': \"ג'\", 'د': 'ד', 'ذ': \"ד'\", 'ه': 'ה', 'ة': \"ה'\", 'و': 'ו', 'ؤ': 'ו', 'ز': 'ז', 'ح': 'ח', 'ط': 'ט', 'ظ': \"ט'\", 'ي': 'י', 'ى': 'י', 'ئ': 'י', 'ك': 'כ', 'خ': \"כ'\", 'ل': 'ל', 'م': 'מ', 'ن': 'נ', 'س': 'ס', 'ع': 'ע', 'ف': 'פ', 'ص': 'צ', 'ض': \"צ'\", 'ق': 'ק', 'ر': 'ר', 'ش': 'ש', 'ت': 'ת', 'ث': \"ת'\", '.': '.', 'H': 'H', ',': ',', '?': '?', ':': ':', ';': ';', '[': '[', ']': ']', '(': '(', ')': ')', '!': '!', '-': '-', '\"': '\"', ' ': ' ', '0': '0', '1': '1', '2': '2', '3': '3', '4': '4', '5': '5', '6': '6', '7': '7', '8': '8', '9': '9', \"'\": \"'\"}\n",
            "length: 61\n",
            "heb_arab_maping {'א': 'ا', 'ב': 'ب', 'ג': 'غ', \"ג'\": 'ج', 'ד': 'د', \"ד'\": 'ذ', 'ה': 'ه', \"ה'\": 'ة', 'ו': 'و', 'ז': 'ز', 'ח': 'ح', 'ט': 'ط', \"ט'\": 'ظ', 'י': 'ي', 'כ': 'ك', \"כ'\": 'خ', 'ל': 'ل', 'מ': 'م', 'נ': 'ن', 'ס': 'س', 'ע': 'ع', 'פ': 'ف', 'צ': 'ص', \"צ'\": 'ض', 'ק': 'ق', 'ר': 'ر', 'ש': 'ش', 'ת': 'ت', \"ת'\": 'ث', '.': '.', 'H': 'H', ',': ',', '?': '?', ':': ':', ';': ';', '[': '[', ']': ']', '(': '(', ')': ')', '!': '!', '-': '-', '\"': '\"', ' ': ' ', '0': '0', '1': '1', '2': '2', '3': '3', '4': '4', '5': '5', '6': '6', '7': '7', '8': '8', '9': '9', \"'\": \"'\"}\n",
            "length: 54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCn2zeq_2sGE",
        "colab_type": "text"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtRTahEBmLU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"DATA PATHS\"\n",
        "\n",
        "hakuzari=\"/gdrive/My Drive/thesis-data/for_ctc_train22_FRIDBERG3.txt\"\n",
        "haemunot=\"/gdrive/My Drive/thesis-data/haemunot_vedeot/for_ctc_train22_FRIDBERG5.txt\"\n",
        "kfir_kuzari_test=\"/gdrive/My Drive/thesis-data/kfir1/kfir_kuzari_test.txt\"\n",
        "kfir_rasag_test=\"/gdrive/My Drive/thesis-data/kfir1/kfir_rasag_test.txt\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWjUhtjL2-31",
        "colab_type": "text"
      },
      "source": [
        "##preprocess sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nrphwz1_7Wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"HELPERS\"\n",
        "\n",
        "##HELPERS\n",
        "\n",
        "\n",
        "# def view_data(data):\n",
        "#   for i,j,l1,l2 in data.take(3):\n",
        "#     print_log_screen(LTRchar,undouble_hebrew(decode_JA(i[0],l1[0])),\" | \",decode_arr(j[0],l2[0]))\n",
        "\n",
        "def view_data(data):\n",
        "  print_log(\"=\"*200)\n",
        "  for i,j,l1,l2 in data.take(1):\n",
        "    for t in range(5):\n",
        "      print_log_screen(LTRchar,undouble_hebrew(decode_JA(i[t],l1[t])),\" | \",decode_arr(j[t],l2[t]))\n",
        "  print_log(\"=\"*200)\n",
        "\n",
        "\n",
        "def clear_blank(s):\n",
        "  return s.replace(BLANK,\"\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXqPPcio2_go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"PREPROCESS SENTENCES\"\n",
        "\n",
        "\n",
        "def normalize_unicode(s):\n",
        "    s = s.strip()\n",
        "    return ''.join(c for c in unicodedata.normalize('NFC', s))\n",
        "        #if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "#ARABIC:\n",
        "def remove_arab_nikud(s):\n",
        "  return ''.join(c for c in  s  if c not in arab_nikud)\n",
        "\n",
        "def replace_arab_style_punctuation(s): \n",
        "  return s.replace(\"،\",\",\").replace(\"؛\",\";\").replace(\"؟\",\"?\")\n",
        "\n",
        "def standard_nunization(s):\n",
        "  return s.replace(\"ًا\",\"اً\")\n",
        "\n",
        "#CHECK\n",
        "assert(standard_nunization(\"بيتًا\")==\"بيتاً\")\n",
        "\n",
        "#JUDEO-ARABIC\n",
        "# def preprocess_JA(w):\n",
        "#     w = normalize_unicode(w.strip())\n",
        "#     w = w.replace('ם','מ').replace('ן','נ').replace('ץ','צ').replace('ף','פ').replace('ך','כ')\n",
        "#     w = w.replace('ֿ',\"'\") #sometimes instead of tag there is a horizontal line above letter\n",
        "#     return w\n",
        "\n",
        "\n",
        "def dropout(ja_str,keep):\n",
        "  res=[]\n",
        "  for c in ja_str:\n",
        "    if c==\" \":\n",
        "      res.append(c)\n",
        "    elif (np.random.binomial(1,keep)):\n",
        "      res.append(c)\n",
        "    else:\n",
        "      res.append(BLANK)\n",
        "  return \"\".join(res)\n",
        "\n",
        "\n",
        "def double_hebrew(w):    \n",
        "    res=\"\"\n",
        "    for i in w:\n",
        "      res+=i\n",
        "      if not i==\" \":  ##THIS 2 LINES IS THE CHANGE THAT WAS ADDED AT THE LAST MINUTE \n",
        "        res+=i    \n",
        "    return res\n",
        "\n",
        "\n",
        "def undouble_hebrew(s):\n",
        "  res=\"\"\n",
        "  words=s.split()\n",
        "  for w in words:\n",
        "    for i in range(0,len(w),2):\n",
        "      res+=w[i]\n",
        "    res+=' '\n",
        "  return res.strip()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ftz4BjtfDnq",
        "colab_type": "text"
      },
      "source": [
        "##languageIndex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMmOvLIryMPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"LANGUAGE INDEX\"\n",
        "\n",
        "# This class creates a char -> index mapping (e.g,. \"d\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"d\") for each language,\n",
        "\n",
        "#this class takes a corpus of lines (lang) and extract the vocab\n",
        "# (letters and signs), stores the corpus and the vocab (with revers map)\n",
        "# it also addes the BLANK symbol to the vocab. (makes sure that BLANK is not in the corpus)\n",
        "BLANK=\"_\"\n",
        "class LanguageIndex():\n",
        "  def __init__(self, allowed_letters):\n",
        "    self.allowed_letters = allowed_letters\n",
        "    self.char2idx = {}\n",
        "    self.idx2char = {}\n",
        "    self.vocab = set()\n",
        "    \n",
        "    self.create_index()\n",
        "    \n",
        "  def create_index(self):\n",
        "    for c in self.allowed_letters:\n",
        "      #for c in phrase:     #for the meantime don't habdle the diatrics in- hebrew (the tag) and hope the ctc will handle...wishfully\n",
        "        self.vocab.update(c)\n",
        "      #for c in additional_letters:\n",
        "      #  self.vocab.update(c)\n",
        "    self.vocab = sorted(self.vocab)\n",
        "    print_log(\"vocab: \",self.vocab)   # maps id (i.e. map index) to char\n",
        "    \n",
        "    \n",
        "    for index, char in enumerate(self.vocab): #reverse map: char to id\n",
        "      self.char2idx[char] = index\n",
        "    print_log(\"len(self.vocab)\",len(self.vocab))\n",
        "    assert(BLANK not in self.char2idx)\n",
        "    self.char2idx[BLANK] = len(self.vocab)   #add BLANK to reverse map\n",
        "    print_log(\"len(self.char2idx)\",len(self.char2idx)) #should print successor of privous print\n",
        "    print_log(self.char2idx[BLANK],BLANK)\n",
        "    \n",
        "    \n",
        "    for char, index in self.char2idx.items():  #this is a map equal to the array vocab, but with BLANK\n",
        "      self.idx2char[index] = char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Ch9lK2o-Jp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "b064ccc3-47d9-4b6f-ff32-17bc9d8ef127"
      },
      "source": [
        "CELL_NAME=\"LANGUAGE INDEX\"\n",
        "\n",
        "inp_lang = LanguageIndex(\"\".join(heb_arab_maping.keys()))\n",
        "targ_lang = LanguageIndex(\"\".join(extended_arab_chars))\n",
        "\n",
        "\n",
        "def print_by_idx_CTC(idx,dict,leng=-1):\n",
        "     # print_log(len(idx))\n",
        "      if leng==-1:\n",
        "       # print_log(len(idx))\n",
        "        leng=len(idx)\n",
        "        \n",
        "      result=\"\"\n",
        "      for i in idx[:leng]:\n",
        "        result += dict[i.numpy()]\n",
        "      return result\n",
        "\n",
        "def decode_JA(idx,leng=-1):\n",
        "  return print_by_idx_CTC(idx,inp_lang.idx2char,leng)\n",
        "\n",
        "def decode_arr(idx,leng=-1):\n",
        "  return print_by_idx_CTC(idx,targ_lang.idx2char,leng)\n",
        "\n",
        "\n",
        "def vectorize(s,dict):  \n",
        "  #return [dict[c] for c in s]\n",
        "  res=[]\n",
        "  for c in s:\n",
        "    if c not in dict:\n",
        "      print_log_screen(\"VECTORIZE: char not in dict - need to call preprocess_lines before calling produce_dataset \")      \n",
        "    else:\n",
        "      res.append(dict[c])  \n",
        "  return res\n",
        "\n",
        "def encode_JA(ja):\n",
        "  return vectorize(ja,inp_lang.char2idx)\n",
        "\n",
        "def encode_arr(arr):\n",
        "  return vectorize(arr,targ_lang.char2idx)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab:  [' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'H', '[', ']', 'א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', 'י', 'כ', 'ל', 'מ', 'נ', 'ס', 'ע', 'פ', 'צ', 'ק', 'ר', 'ש', 'ת']\n",
            "len(self.vocab) 47\n",
            "len(self.char2idx) 48\n",
            "47 _\n",
            "vocab:  [' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'H', '[', ']', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ً', 'ٌ', 'ٍ', 'ّ', 'ٱ']\n",
            "len(self.vocab) 66\n",
            "len(self.char2idx) 67\n",
            "66 _\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E7wKGxCzxuE",
        "colab_type": "text"
      },
      "source": [
        "##FUCNTION FOR GEN DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xjn9m6nyHv7",
        "colab_type": "text"
      },
      "source": [
        "###SPLIT TEST TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e62bZRaH7L8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"TEST TRAIN SPLIT\"\n",
        "\n",
        "def split_test_train(input_file,output_train,output_test,test_percent=0.2):\n",
        "  with open(input_file, 'rb') as f:\n",
        "      text = f.read().decode(encoding='utf-8')  \n",
        "  text=text.replace(\"&nbsp\",\"\")\n",
        "  lines=text.strip().split('\\n')\n",
        "  num_of_lines=len(lines)\n",
        "  test_size=math.floor(num_of_lines*test_percent)\n",
        "  idx=[0]*test_size + [1]*(num_of_lines-test_size)\n",
        "  random.shuffle(idx)\n",
        "  print(idx)\n",
        "  \n",
        "  f_train=open(output_train,'w+')\n",
        "  f_test=open(output_test,'w+')\n",
        "  \n",
        "  train = []\n",
        "  test = []\n",
        "  for a,i in zip(lines,idx):\n",
        "    if i:\n",
        "      train.append(a)\n",
        "      f_train.write(a+'\\n')\n",
        "    else:\n",
        "      test.append(a)\n",
        "      f_test.write(a+'\\n')\n",
        "  \n",
        "  f_train.close()\n",
        "  f_test.close()\n",
        "\n",
        "  print(len(train),train[0:10])\n",
        "  print(len(test),test[0:10])\n",
        "\n",
        "#split_test_train(hakuzari,hakuzari+\".train.txt\",hakuzari+\".test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58vNbHqdTly_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "72c32907-6727-462a-8d7d-61add3ff1329"
      },
      "source": [
        "#SHOLD ONLY BE CALLED TO RESPLIT TEST AND TRAIN\n",
        "#split_test_train(hakuzari,hakuzari+\".train.txt\",hakuzari+\".test.txt\")\n",
        "#split_test_train(haemunot,haemunot+\".train.txt\",haemunot+\".test.txt\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "8739 [\"סילת עמא ענדי מן אלאחתג'אג'\\tسُئِلْتُ عمّا عنديَ من الاحتجاج\", \"עלי מכ'אלפינא מן אלפלאספה\\tعلى مُخالفينا من الفلاسفة\", \"אלכ'וארג' אלד'ין יכ'אלפון\\tالخوارج الذين يخالفون\", \"אלג'מהור . תד'כרת מה\\tالجمهور . تذكّرت ما\", \"קד סמעתה מן חג'ג' אלחבר\\tقد سمعتهُ من حجج الحَبْرِ\", \". , עלי מא שהד וג'א פי\\t. , على ما شُهِد وجاء في\", \"מלאכא יכ'אטבה ויקול לה\\tملاكاً يخاطبه ويقول له\", \": אן ניתך מרצ'יהֿ ענד\\t: إنَّ نيّتك مرضيّة عند\", \"אללה לכן עמלך ג'יר מרצ'י\\tالله لكن عملك غير مرضيّ\", \". וכאן יג'תהד ג'דא פי\\t. وكان يجتهد جدّاً في\"]\n",
            "2184 [\"ואהל אלאדיאן ת'ם עלי\\tوأهل الأديان ثمّ على\", \", אלד'י כאן ענד מלך אלכ'זר\\t, الذي كان عند مَلِك الخَزَرِ\", \"אלדאכ'ל פי דין אליהוד\\tالداخل في دين اليهود\", \"כתאב אלתואריך' , אנה\\tكتاب التواريخ , أنه\", 'תכרר עליה רויא , כאן\\tتكرّر عليه رؤيا , كأنَّ', 'אלהיכל ואלקראבין בנפסה\\tالهيكل والقرابين بنفسه', \"אג'תהד פי תלך אלאעמאל\\tاجتهد في تلك الأعمال\", \"ועמלך גיר מרצ'י . פסבב\\tوعملك غير مرضيّ . فسبّب\", \"וג'מהור אלכ'זר . וכאן\\tوجمهور الخَزَر . وكان\", \"אן את'בת ד'לך אלאחתג'אג'\\tأن أثبت ذلك الاحتجاج\"]\n",
            "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1]\n",
            "8287 [\"אלמכ'תאר פי אלאמאנאת\\t(المختار في) الأمانات\", 'ואלאעתקאדאת אפתתח מולפה\\tوالاعتقادات افتتح مؤلَّفَه', 'אסראיל אלחקיק במעני אלחק\\tإسرائيل الحقيق بمعنى الحق', 'אלמבין אלמחקק ללנאטקין\\tالمبين المحقِّق للناطقين', \"וג'דאן אנפסהם חקא יקינא\\tوجدان أنفسهم حقًا يقينًا\", \"פוג'דוא בהא מחסוסאתהם\\tفوجدوا بها محسوساتهم\", \"וג'דאנא צחיחא פעלמוא\\tوجدانًا صحيحًا فعلموا\", 'בהא מעלומאתהם עלמא צאדקא\\tبها معلوماتهم علمًا صادقًا', \"ארתפעת בד'לך ענהם אלשבה\\tارتفعت بذلك عنهم الشُبَه\", \"וזאלת מעה אלשכוך פכ'לצת\\tوزالت معه الشكوك فخلصت\"]\n",
            "2071 ['באן קאל תבארך אללה אלאה\\tبأنْ قالَ تبارك الله إله', \"אמא עלי את'ר מא אפתתחנא\\tأمّا على إثر ما افتتحنا\", \"פי מטאלבהם וען וג'ה זואלהא\\tفي مطالبهم وعن وجه زوالها\", \"H H H . וארי אן אג'על\\tH H H . وأرى أنْ أجعل\", 'אלשבה באי סבב כאן מן\\tالشُبَه بأي سبب كان من', 'אלוקוף בין ידיה פלא יערפה\\tالوقوف بين يديه فلا يعرفه', \"פיכ'אד' באלאכ'ף ותרך\\tفيأخذ بالأخف وترك\", \"יתבינה . כאנת איצ'א אלאשיא\\tيتبيّنه . كانت أيضًا الأشياء\", \"אלאסתדלאל ، פהו יג'על\\tالاستدلال ، فهو يجعل\", \"איצ'א גיר אלדליל דלילא\\tأيضًا غير الدليل دليلاً\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW_YqhOHyNUs",
        "colab_type": "text"
      },
      "source": [
        "###load_lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwEx-7TJ2uD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"LOAD_LINES\"\n",
        "\n",
        "def load_lines(input_file=hakuzari):\n",
        "  print_log_screen(\"loading text: \"+input_file)\n",
        "  with open(input_file, 'rb') as f:\n",
        "    text = f.read().decode(encoding='utf-8')\n",
        "    #text=text.replace('ֿ',\"'\")   ##allread doing it inside preprocess_JA()\n",
        "    text=text.replace(\"&nbsp\",\"\")\n",
        "  lines=text.strip().split('\\n')\n",
        "  print_log(\"first lines:\",lines[0:100])\n",
        "  print_log_screen(\"len(lines)\", len(lines)) # 10923 kuzari 10358 haemunot\n",
        "  return lines\n",
        "\n",
        "#lines=load_lines(haemunot)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyI8c-qU-DEe",
        "colab_type": "text"
      },
      "source": [
        "###preprocess_lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro14w9OP-Dt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_JA(ja):\n",
        "    ja=replace_arab_style_punctuation(ja)\n",
        "    ja=clear_blank(ja) #acctually should be taken care of by remove_chars_not_in_map ...\n",
        "    ja = normalize_unicode(ja.strip())\n",
        "    ja = ja.replace('ם','מ').replace('ן','נ').replace('ץ','צ').replace('ף','פ').replace('ך','כ')\n",
        "    ja = ja.replace('ֿ',\"'\") #sometimes instead of tag there is a horizontal line above letter\n",
        "    ja=remove_chars_not_in_JA_map(ja)\n",
        "    return ja\n",
        "\n",
        "def preprocess_arr(arr):\n",
        "    arr=remove_arab_nikud(arr)\n",
        "    arr=standard_nunization(arr)\n",
        "    arr=replace_arab_style_punctuation(arr)\n",
        "    arr=clear_blank(arr) #acctually should be taken care of by remove_chars_not_in_map ...\n",
        "    arr=normalize_unicode(arr)     \n",
        "    arr=remove_chars_not_in_arab_map(arr)\n",
        "    return arr\n",
        "\n",
        "def preprocess_lines(ja_arr_lines):\n",
        "  res=[]\n",
        "  for l in ja_arr_lines:\n",
        "    ja,arr=l.split('\\t')\n",
        "\n",
        "    ja=preprocess_JA(ja)\n",
        "      \n",
        "    arr=preprocess_arr(arr)\n",
        "    \n",
        "    res.append(ja+'\\t'+arr)\n",
        "  return res\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jWF3taWySyb",
        "colab_type": "text"
      },
      "source": [
        "###create_parralele_phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvF0XWGTzZ7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Takes a file of <heb, arab> phrases separated by tab\n",
        "# Return phares pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_parralel_phrases(lines,keep=1):\n",
        "    phrase_pairs=[]\n",
        "    for l in lines:\n",
        "      heb,arr=l.split('\\t')\n",
        "      \n",
        "      # heb=clear_blank(replace_arab_style_punctuation(heb)) #TODO needed?\n",
        "      # heb=preprocess_JA(heb)\n",
        "      heb=dropout(heb,keep)\n",
        "      heb=double_hebrew(heb)      \n",
        "\n",
        "      # arr=remove_arab_nikud(arr)\n",
        "      # arr=standard_nunization(arr)\n",
        "      # arr=clear_blank(replace_arab_style_punctuation(arr))\n",
        "      # arr=normalize_unicode(arr) \n",
        "      \n",
        "      phrase_pairs.append([heb,arr])        \n",
        "    return phrase_pairs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94LaMY0igcWT",
        "colab_type": "text"
      },
      "source": [
        "###produce_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuiTkrWRLYG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"produce_dataset\"\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "\n",
        "def produce_dataset(parallel_phrase,to_shuffle=False):\n",
        "  \n",
        "    input_tensor = [encode_JA(heb) for heb, arr in parallel_phrase]\n",
        "    input_lengths=[len(heb) for heb,arr in parallel_phrase]\n",
        "  \n",
        "    target_tensor = [encode_arr(arr) for heb, arr in parallel_phrase]\n",
        "    target_lengths = [len(arr)  for heb,arr in parallel_phrase]\n",
        "  \n",
        "\n",
        "    print_log(\"VECTORIZE EXAMPLE\")\n",
        "    print_log(LTRchar,parallel_phrase[0])\n",
        "    print_log(input_lengths[0])\n",
        "    print_log(target_lengths[0])\n",
        "    print_log(input_tensor[0])\n",
        "    print_log(target_tensor[0])\n",
        "    print_log(\"\\n\")\n",
        "\n",
        "    # Padding the input and output tensor to the maximum length\n",
        "    max=max_length(input_tensor)\n",
        "    if max>70:\n",
        "      max=70\n",
        "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=max,\n",
        "                                                                 padding='post',\n",
        "                                                                 value=inp_lang.char2idx[BLANK])\n",
        "    max=max_length(target_tensor)\n",
        "    if max>70:\n",
        "      max=70    \n",
        "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=max,\n",
        "                                                                  padding='post',\n",
        "                                                                  value=targ_lang.char2idx[BLANK])\n",
        "    print_log(len(input_tensor), \n",
        "        len(target_tensor))      \n",
        "    BUFFER_SIZE = len(input_tensor)\n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_tensor, \n",
        "                                                  target_tensor,\n",
        "                                                  input_lengths,\n",
        "                                                  target_lengths))\n",
        "    if to_shuffle:\n",
        "      dataset=dataset.shuffle(BUFFER_SIZE,reshuffle_each_iteration=True)\n",
        "\n",
        "                                                  \n",
        "    dataset_double=dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset_double\n",
        "    \n",
        "    return dataset_double\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kFSbZTPfe0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"DEF create_data_tensors\"\n",
        "\n",
        "# def max_length(tensor):\n",
        "#     return max(len(t) for t in tensor)\n",
        "\n",
        "\n",
        "# def create_data_tensors(pairs):\n",
        "  \n",
        "#     input_tensor = [encode_JA(heb) for heb, arr in pairs]\n",
        "#     input_lenghts=[len(heb) for heb,arr in pairs]\n",
        "  \n",
        "#     target_tensor = [encode_arr(arr) for heb, arr in pairs]\n",
        "#     target_lengths = [len(arr)  for heb,arr in pairs]\n",
        "  \n",
        "\n",
        "#     print_log()\n",
        "#     print_log(LTRchar,pairs[0])\n",
        "#     print_log(input_lenghts[0])\n",
        "#     print_log(target_lengths[0])\n",
        "#     print_log(input_tensor[0])\n",
        "#     print_log(target_tensor[0])\n",
        "\n",
        "#     # Padding the input and output tensor to the maximum length\n",
        "#     max=max_length(input_tensor)\n",
        "#     if max>70:\n",
        "#       max=70\n",
        "#     input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "#                                                                  maxlen=max,\n",
        "#                                                                  padding='post',\n",
        "#                                                                   value=inp_lang.char2idx[BLANK])\n",
        "#     max=max_length(target_tensor)\n",
        "#     if max>70:\n",
        "#       max=70    \n",
        "#     target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "#                                                                   maxlen=max,\n",
        "#                                                                   padding='post',\n",
        "#                                                                   value=targ_lang.char2idx[BLANK])\n",
        "#     return input_tensor, target_tensor ,input_lenghts,target_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQkyeHLzi_sN",
        "colab_type": "text"
      },
      "source": [
        "generate the data tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23ovSfOPxoy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"DEF GEN DATA\"\n",
        "\n",
        "# def gen_data(input_tensor, target_tensor,input_lenghts,target_lengths,_test_size=0.2):  \n",
        "#   input_tensor_train, input_tensor_val, \\\n",
        "#   target_tensor_train, target_tensor_val, \\\n",
        "#   input_lengths_train, input_lengths_val, \\\n",
        "#   target_lengths_train, target_lengths_val = train_test_split(input_tensor,\n",
        "#                                                               target_tensor,\n",
        "#                                                               input_lenghts,\n",
        "#                                                               target_lengths, test_size=_test_size)\n",
        "  \n",
        "#   print_log(len(input_tensor_train), \n",
        "#         len(target_tensor_train), \n",
        "#         len(input_tensor_val), \n",
        "#         len(target_tensor_val))\n",
        "  \n",
        "#   BUFFER_SIZE = len(input_tensor_train)\n",
        "  \n",
        "#   dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, \n",
        "#                                                 target_tensor_train,\n",
        "#                                                 input_lengths_train,\n",
        "#                                                 target_lengths_train)).shuffle(BUFFER_SIZE,reshuffle_each_iteration=True)\n",
        "\n",
        "\n",
        "#   test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, \n",
        "#                                                     target_tensor_val,\n",
        "#                                                     input_lengths_val,\n",
        "#                                                     target_lengths_val)).shuffle(BUFFER_SIZE,reshuffle_each_iteration=False)                                                  \n",
        "  \n",
        "#   dataset_double=dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "#   test_dataset_double=test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "#   return dataset_double,test_dataset_double\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI0elYUMb8Ls",
        "colab_type": "text"
      },
      "source": [
        "##activate gen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1izFnzJAMynm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48a5c418-bf96-42e5-ef4e-30d100bdb542"
      },
      "source": [
        "CELL_NAME=\"LOAD DATASET NEW\"\n",
        "\n",
        "#only once per file\n",
        "kuzari_lines_train=preprocess_lines(\n",
        "    load_lines(hakuzari+\".train.txt\")\n",
        ")\n",
        "\n",
        "#to recalc dropout:\n",
        "train_dataset_double_kuzari= produce_dataset(create_parralel_phrases(kuzari_lines_train,1),to_shuffle=TO_SHUFFLE)\n",
        "\n",
        "print_log_screen(\"train_dataset_double_kuzari\")\n",
        "view_data(train_dataset_double_kuzari)\n",
        "\n",
        "\n",
        "#only once per file\n",
        "kuzari_lines_test=preprocess_lines(\n",
        "    load_lines(hakuzari+\".test.txt\")\n",
        ")\n",
        "\n",
        "#to recalc dropout:\n",
        "test_dataset_double_kuzari= produce_dataset(create_parralel_phrases(kuzari_lines_test,1)\n",
        "                                      ,to_shuffle=False)\n",
        "\n",
        "print_log_screen(\"test_dataset_double_kuzari\")\n",
        "view_data(test_dataset_double_kuzari)\n",
        "\n",
        "\n",
        "#only once per file\n",
        "rasag_lines_test=preprocess_lines(\n",
        "    load_lines(haemunot+\".test.txt\")\n",
        ")\n",
        "\n",
        "#to recalc dropout:\n",
        "test_dataset_double_rasag= produce_dataset(create_parralel_phrases(rasag_lines_test,1)\n",
        "                                      ,to_shuffle=False)\n",
        "\n",
        "print_log_screen(\"test_dataset_double_rasag\")\n",
        "view_data(test_dataset_double_rasag)\n",
        "\n",
        " "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading text: /gdrive/My Drive/thesis-data/for_ctc_train22_FRIDBERG3.txt.train.txt\n",
            "first lines: [\"סילת עמא ענדי מן אלאחתג'אג'\\tسُئِلْتُ عمّا عنديَ من الاحتجاج\", \"עלי מכ'אלפינא מן אלפלאספה\\tعلى مُخالفينا من الفلاسفة\", \"אלכ'וארג' אלד'ין יכ'אלפון\\tالخوارج الذين يخالفون\", \"אלג'מהור . תד'כרת מה\\tالجمهور . تذكّرت ما\", \"קד סמעתה מן חג'ג' אלחבר\\tقد سمعتهُ من حجج الحَبْرِ\", \". , עלי מא שהד וג'א פי\\t. , على ما شُهِد وجاء في\", \"מלאכא יכ'אטבה ויקול לה\\tملاكاً يخاطبه ويقول له\", \": אן ניתך מרצ'יהֿ ענד\\t: إنَّ نيّتك مرضيّة عند\", \"אללה לכן עמלך ג'יר מרצ'י\\tالله لكن عملك غير مرضيّ\", \". וכאן יג'תהד ג'דא פי\\t. وكان يجتهد جدّاً في\", \"אלתעבד פי דין אלכ'זר\\tالتعبّد في دين الخَزَر\", \", חתי אנה כאן יכ'דם כ'דמה\\t, حتّى أنه كان يخدم خِدمة\", \"בניה צאפיה כ'אלצה . פכלמא\\tبنيّة صافية خالصة . فكلّما\", \", ג'א אלמלאך פי אלליל\\t, جاءه الملاك في الليل\", \"יקול לה : ניתך מרצ'יה\\tيقول له : نيّتك مرضيّة\", \"לה ד'לך אלבחת' ען אלאדיאן\\tله ذلك البحث عن الأديان\", \"ואלנחל ותהוד אכ'רא הוא\\tوالنحل وتهوّد آخرا هو\", \"מן חג'ג' אלחבר מא אקנעני\\tمن حجج الحَبْر ما أقنعني\", ', וטאבק אעתקאדי , פראית\\t, وطابق اعتقادي , فرأيت', 'כמא וקע H H . קיל אן\\tكما وقع H H . قيل إنَّ', \"מלך אלכ'זר למא ראי פי\\tمَلِك الخَزَر لمّا رأى في\", \"ענד אללה ועמלה גיר מרצ'י\\tعند الله وعمله غير مرضيّ\", ', ואמרה פי אלנום אן יטלב\\t, وأمره في النوم أن يطلب', \"אלעמל אלמרצ'י ענד אללה\\tالعمل المرضيّ عند الله\", ', סאל פילסופא ען מעתקדה\\t, سأل فيلسوفاً عن معتقده', '. פקאל לה אלפילסוף :\\t. فقال له الفيلسوف :', \"ליס ענד אללה רצ'י ולא\\tليس عند الله رضا ولا\", \"אלאראדאת ואלאג'ראץ' .\\tالإرادات والأغراض .\", \"לאן אלג'רץ' ידל עלי נקצאן\\tلأنَّ الغرض يدلّ على نقصان\", \"אלמג'רץ' . ואן תמאם ג'רצ'ה\\tالمُغرض . وأنَّ تمام غرضه\", 'כמאל לה , ומהמא לם יתם\\tكمال له , ومهما لم يتمّ', \"פהו נקצאן . וכד'לך הו\\tفهو نقصان . وكذلك هو\", 'מנזה ענד אלפלאספה ען\\tمُنزَّه عند الفلاسفة عن', \"עלם אלג'זאיאת . לאנהא\\tعلم الجزئيات . لأنّها\", \"מתג'ירה מע אלאחיאן .\\tمتغيّرة مع الأحيان .\", 'וליס פי עלם אללה תגיר\\tوليس في علم الله تغيّر', \". פהו לא ידריך , פצ'לא\\t. فهو لا يدريكَ , فضلاً\", \", פצ'לא ען אן יסמע צלאתך\\t, فضلاً عن أن يسمع صلاتكَ\", 'וירא חרכאתך . נעם , ואן\\tويرى حركاتكَ . نعم , وإنْ', \"קאלת אלפלאספה אנה כ'לקך\\tقالت الفلاسفة إنّه خلقكَ\", \"פעלי אלמג'אז , לאנה עלהֿ\\tفعلى المجاز , لأنّه علّة\", \"אלעלל פי כ'לקהֿ כל מכ'לוק\\tالعلل في خلقة كل مخلوق\", ', לא לאנה מקצוד מן קבלה\\t, لا لأنّه مقصود من قِبَلِهِ', \". נעם , ולא כ'לק קט אנסאנא\\t. نعم , ولا خلق قطّ إنساناً\", 'לאן אלעאלם קדים , לם\\tلأنَّ العالم قديم , لم', 'יזל ינשא אלאנסאן מן אנסאן\\tيزلْ ينشأ الإنسان من إنسان', 'קבלה , תתרכב פיה צור\\tقبله , تتركّب فيه صُوَر', \"וכ'לק [ו]אכ'לאק מן אביה\\tوخُلْق وأخلاق من أبيه\", 'ואמה וקראבתה , וכיפיאת\\tوأمّه وقرابته , وكيفيّات', \"אלאהויה ואלבלדאן ואלאגד'יה\\tالأهوية والبلدان والأغذية\", 'ואלמיאה , מע קוי אלאפלאך\\tوالمياه , مع قوى الأفلاك', \"ואלדרארי ואלברוג' באלנסב\\tوالدَّرَارِيّ والبروج بالنسب\", 'אלחאצלה מנהא . ואלכל\\tالحاصلة منها . والكلّ', \"ראג'ע אלא אלסבב אלאול\\tراجع إلى السبب الأوّل\", \", לא ען גרץ' לה , לכן\\t, لا عن غرض له , لكن\", \"פיץ' פאץ' ענה סבב ת'אן\\tفيض فاض عنه سبب ثانٍ\", \", ת'ם ת'ואלת' ורואבע\\t, ثمّ ثوالث وروابع\", ', ותלאזמת אלאסבאב ואלמסבבאת\\t, وتلازمت الأسباب والمسبّبات', 'אלסבב אלאול קדים , לא\\tالسبب الأوّل قديم , لا', \"אול לה . פלכל שכ'ץ מן\\tأوّل له . فلكلّ شخص من\", \"אשכ'אץ אלדניא אסבאב בהא\\tأشخاص الدنيا أسباب بها\", \"יתם . פשכ'ץ תכאמלת אסבאבה\\tيتمّ . فشخص تكاملت أسبابه\", \"פג'א כאמלא , ושכ'ץ נקצת\\tفجاء كاملاً , وشخص نقصت\", \"אסבאבה פג'א נאקצא , כאלחבשי\\tأسبابه فجاء ناقصاً , كالحبشيّ\", \"אלד'י לם יהיא לאכת'ר\\tالذي لم يُهيَّأ لأكثر\", 'מן קבול צורהֿ אלאנסאן\\tمن قبول صورة الإنسان', 'ואלנטק עלי אנקץ מא ימכן\\tوالنطق على أنقص ما يمكن', 'ינקצה שי מן אלכמאל .\\tينقصه شيء من الكمال .', \"לכן הד'ה אלכמאלאת באלקוה\\tلكن هذه الكمالات بالقوّة\", \", יחתאג' פי אכ'ראג'הא\\t, يُحتاج في إخراجها\", 'אלי אלפעל אלי אלתעלים\\tإلى الفعل إلى التعليم', \"ואלתאדיב , פתט'הר אלהיאת\\tوالتأديب , فتظهر الهيئات\", 'עלי מא היית לה מן כמאל\\tعلى ما هُيّئَت له من كمال', 'ונקצאן ותוסטאת אלי מא\\tونقصان وتوسّطات إلى ما', 'לא נהאיה לה . פאלכאמל\\tلا نهاية له . فالكامل', 'יתצל בה מן אלנמט אלאלאהי\\tيتّصل به من النمط الإلهيّ', ', יתצל בה עקלה אלמנפעל\\t, يتّصل به عقله المنفعل', \", לא תג'איר בינהמא ,\\t, لا تغايُر بينهما ,\", \"ותציר אלאתה , אעני אעצ'א\\tوتصير آلاته , أعني أعضاء\", \"ד'לך אלשכ'ץ , לא תתצרף\\tذلك الشخص , لا تتصرّف\", 'אלא פי אכמל אלאעמאל ופי\\tإلاّ في أكمل الأعمال وفي', \"אופק אלאוקאת , ועלי אפצ'ל\\tأوفق الأوقات , وعلى أفضل\", 'אלחאלאת , וכאנהא אלאת\\tالحالات , وكأنّها آلات', 'ללעקל אלפעאל לא ללעקל\\tللعقل الفعّال لا للعقل', \"אלהיולאני אלמנפעל אלד'י\\tالهيولانيّ المنفعل الذي\", 'כאן מן קבל יצרפהא , פכאן\\tكان من قبل يصرّفها , فكان', \"יציב מרה ויכ'טי מראת\\tيُصيب مرّة ويُخطئ مرّات\", \"והד'א אלדרג'ה אלגאיה\\tوهذه الدرجة الغاية\", \"אלקצוי אלמרג'וה ללאנסאן\\tالقُصوى المرجوّة للإنسان\", 'אלכאמל , בעד אן תציר\\tالكامل , بعد أن تصير', 'נפסה מטהרה מן אלשכוך\\tنفسه مطهَّرة من الشكوك', ', מחצלה ללעלום עלי חקאיקהא\\t, محصّلة للعلوم على حقائقها', ', פתציר כאנהא מלך , פתציר\\t, فتصير كأنّها مَلَك , فتصير', 'באדון רתבה מן אלמלכותיה\\tبأَدْون رتبة من المَلَكوتية', \"אלמפארקה ללאג'סאד , והי\\tالمفارقة للأجساد , وهي\", 'מלך רתבתה דון אלמלך אלמוכל\\tمَلَك رتبته دون المَلَك الموكَّل', \"מג'רדה ען אלמואד קדימה\\tمجرَّدة عن المَوادّ قديمة\", 'אלפנא אבדא . פתציר נפס\\tالفناء أبداً . فتصير نفس', \"אלאנסאן אלכאמל וד'לך\\tالإنسان الكامل وذلك\", \"יבאלי בפנא ג'סדה ואלאתה\\tيُخلى بفَناء جسده وآلاته\"]\n",
            "len(lines) 8739\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "للـ\"سكينة\" , H H يفلح ويحرث\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ׂ )\n",
            "in sentences:\n",
            "בלג עציאנ ישׂראל אלי\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "والـملء يقدر أن يلحّن H\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "إمّا H وإمّا \"هـ\" مثل H\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            ", والتحفّظ , والـ\"خلط\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "القياس , فرضه الله بـ\"العشور\"\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "كالـ\"ختان\" مع \"السبت\" , و\"الفصح\"\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "H , فإنّهم مؤيّدون بالـ\"سكينة\"\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "بالـ\"ملء\" و\"الترديد\" .\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "الحقيقة فلا ظهور للـ\"مجد\"\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "وللـ\"ملكوت\" إلاّ على أوليائه\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "أشبّههم بـ\"المتهوّدين\" الذين\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "للـ\"عجول\" , فأصحاب \"العجل\"\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( … )\n",
            "in sentences:\n",
            ". [……] קאל אלכ'זרי :\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( … )\n",
            "in sentences:\n",
            ". [……] קאל אלכ'זרי :\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "متعلّق بالـ\"جلد\" . ثمّ انتقل\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "يردّ من ذلك بالـ\"توبة\"\n",
            "\n",
            "VECTORIZE EXAMPLE\n",
            "‫ [\"ססייללתת עעממאא עעננדדיי ממננ אאללאאחחתתגג''אא__''\", 'سئلت عمّا عندي من الاحتجاج']\n",
            "50\n",
            "26\n",
            "[39, 39, 34, 34, 36, 36, 46, 46, 0, 40, 40, 37, 37, 25, 25, 0, 40, 40, 38, 38, 28, 28, 34, 34, 0, 37, 37, 38, 38, 0, 25, 25, 36, 36, 25, 25, 32, 32, 46, 46, 27, 27, 3, 3, 25, 25, 47, 47, 3, 3]\n",
            "[43, 30, 54, 34, 0, 49, 55, 64, 31, 0, 49, 56, 39, 60, 0, 55, 56, 0, 31, 54, 31, 37, 34, 36, 31, 36]\n",
            "\n",
            "\n",
            "8739 8739\n",
            "train_dataset_double_kuzari\n",
            "========================================================================================================================================================================================================\n",
            "‫ סילת עמא ענדי מנ אלאחתג'א_'  |  سئلت عمّا عندي من الاحتجاج\n",
            "‫ עלי מכ'אלפ_נא מנ אלפ_אספה  |  على مخالفينا من الفلاسفة\n",
            "‫ א_כ'וארג' אלד'ינ יכ'אלפונ  |  الخوارج الذين يخالفون\n",
            "‫ _ל_'מהור _ תד'כרת מה  |  الجمهور . تذكّرت ما\n",
            "‫ קד _מעת_ מנ חג_ג' אלחבר  |  قد سمعته من حجج الحبر\n",
            "========================================================================================================================================================================================================\n",
            "loading text: /gdrive/My Drive/thesis-data/for_ctc_train22_FRIDBERG3.txt.test.txt\n",
            "first lines: [\"ואהל אלאדיאן ת'ם עלי\\tوأهل الأديان ثمّ على\", \", אלד'י כאן ענד מלך אלכ'זר\\t, الذي كان عند مَلِك الخَزَرِ\", \"אלדאכ'ל פי דין אליהוד\\tالداخل في دين اليهود\", \"כתאב אלתואריך' , אנה\\tكتاب التواريخ , أنه\", 'תכרר עליה רויא , כאן\\tتكرّر عليه رؤيا , كأنَّ', 'אלהיכל ואלקראבין בנפסה\\tالهيكل والقرابين بنفسه', \"אג'תהד פי תלך אלאעמאל\\tاجتهد في تلك الأعمال\", \"ועמלך גיר מרצ'י . פסבב\\tوعملك غير مرضيّ . فسبّب\", \"וג'מהור אלכ'זר . וכאן\\tوجمهور الخَزَر . وكان\", \"אן את'בת ד'לך אלאחתג'אג'\\tأن أثبت ذلك الاحتجاج\", \"רויאה , אן ניתה מרצ'יה\\tرؤياه , أنَّ نيّته مرضيّة\", \"בג'ץ' . לאנה מנזה ען\\tبغض . لأنّه مُنزَّه عن\", 'ען אן ידרי ניתך ואעמאלך\\tعن أن يدري نيّتكَ وأعمالكَ', 'ותסלסלת , כמא תראהא ,\\tوتسلسلت , كما تراها ,', 'ותלאזמהא קדים כמא אן\\tوتلازمها قديم كما أنَّ', \". פאלפילסוף אלד'י תהיאת\\t. والفيلسوف الذي تهيأت\", 'לה אסתעדאדאת יקבל בהא\\tله استعدادات يقبل بها', \"אלפצ'איל אלכ'לקיה ואלכ'לקיה\\tالفضائل الخلَقية والخُلقية\", 'ואלעלמיה ואלעמליה ולם\\tوالعلمية والعملية ولم', 'נור , יסמי אלעקל אלפעאל\\tنور , يسمَّى العقل الفعّال', \"אתצאל אתחאד חתי ירי אלשכ'ץ\\tاتّصال اتّحاد حتّى يرى الشخص\", \"אנה הו ד'לך אלעקל אלפעאל\\tأنّه هو ذلك العقل الفعّال\", \". והד'א יציב דאימא .\\t. وهذا يصيب دائماً .\", 'רתבה אלעקל אלפעאל והו\\tرتبة العقل الفعّال وهو', 'בפלך אלקמר . והי עקול\\tبفلك القمر . وهي عقول', \"מע אלסבב אלאול , לא תכ'אף\\tمع السبب الأوّل , لا تخاف\", 'אלעקל שיא ואחדא , פלא\\tالعقل شيئاً واحداً , فلا', 'ואפלאטון וארסטוטאליס\\tوأفلاطون وأرسطوطاليس', 'בחקאיק אלאמור , ליציר\\tبحقائق الأمور , ليصير', 'ואלאעמאל לאנה מעונה פי\\tوالأعمال لأنّه معونة في', \"ליזיל ענך סכ'טה , בל\\tليزيل عنك سخطه , بل\", ', אן [כנת] מקבולא מנהם\\t, إن كنت مقبولاً منهم', \". ובאלג'מלה , פאטלב צפא\\t. وبالجُملة , فاطلب صفاء\", 'בעד תחציל כליאת אלעלום\\tبعد تحصيل كُلّيات العلوم', 'אלנפס מסדד אלאעמאל נחו\\tالنفس مسدَّد الأعمال نحو', \"אלט'נון . ואלא פאן אלנצראני\\tالظنون . وإلاَّ فإنَّ النصرانيّ\", 'אלי אללה , פיקתתלאן ,\\tإلى الله , فيقتتلان ,', \"אן מסירה אלי אלג'נה ואלפרדוס\\tأنَّ مسيره إلى الجنّة والفردَوْس\", ': ואי חירה ענד אלפלאספה\\t: وأيّ حيرةٍ عند الفلاسفة', \", ואן אלעאלם כ'לק פי\\t, وأنَّ العالم خُلق في\", 'H איאם , ואן אלסבב אלאול\\tH أيام , وأنَّ السبب الأوّل', \"יכלם שכ'צא מן אלנאס ,\\tيكلّم شخصاً من الناس ,\", \"ענהם גראיב ומעג'זאת וכראמאת\\tعنهم غرائب ومعجزات وكرامات\", \"כ'לק אלעאלם באסרה פי\\tخلق العالم بأَسْره في\", \"מן ד'ריה אדם ת'ם ד'ריה\\tمن ذرية آدم ثُمّ ذرية\", 'ואוליאה , וחלולא פי מא\\tوأوْليائه , وحُلولاً في ما', \"בין מן ירצ'אה מן אלג'מאהיר\\tبين من يرضاه من الجماهير\", 'אלאהותי אלבאטן , נביא\\tلاهوتيّ الباطن , نبيّاً', \"ואן ט'הר עלי לסאננא אלתת'לית'\\tوإنْ ظهر على لساننا التثليث\", 'אלאלאהי יתצל בהם , חתי\\tالإلهيّ يتّصل بهم , حتّى', \"עצי ג'מהורהם הד'א אלמסיח\\tعصى جمهورهم هذا المسيح\", \"וצלבוה . פצאר אלסכ'ט\\tوصلبوه . فصار السخط\", \"ללמסיח . ת'ם עלי אלאמם\\tللمسيح . ثمّ على الأمم\", \"אסראיל את'ני עשר מקאם\\tإسرائيل اثنا عشر مقامَ\", \"אלאסבאט . ת'ם ג'מלה מן\\tالأسباط . ثمّ جملة من\", 'בני אסראיל תאבעת לאולאיך\\tبني إسرائيل تابعت لأولئك', 'פי אלבלאד . וגמיע אלאמם\\tفي البلاد . وجميع الأمم', \"צליבה אלד'י צלב עליה\\tصليبه الذي صُلب عليه\", \"לאעצ'דהא ולאזידהא . קאל\\tلأعضدها ولأزيدها . قالَ\", \"חתי יאכ'ד' במג'אמע אלקלב\\tحتّى يأخذ بمجامع القلب\", \", ולא יג'ד מנדוחה פי\\t, ولا يجد مندوحة في\", \"תטרא עליהם , ממא לו חדת'וא\\tتطرأ عليهم , ممّا لو حُدّثوا\", \"ואלקדם ללה , ואלחדת'\\tوالقِدَم لله , والحَدَث\", 'אלקול תאולנאה וקלנא אנה\\tالقول تأوّلناه وقلنا إنّه', \"מג'אז ותקריב , מע אקרארנא\\tمَجاز وتقريب , مع إقرارنا\", ', ודאעי אלאמם כלהא אלי\\t, وداعي الأمم كُلّها إلى', 'הדאיתה באמר אללה ויחקק\\tهدايته بأمر الله ويحقَّق', \"והו יסתבעד ד'לך , ינבגי\\tوهو يستبعد ذلك , ينبغي\", 'אן יקרר ענדה אמור משהורה\\tأن يقرّر عنده أمور مشهورة', 'לא מדפע פיהא . ובלאחרי\\tلا مدفع فيها . وبالحَرَى', 'אלערבי . פקאל לה אלעאלם\\tالعربيّ . فقال له العالِمُ', 'אלי אן תקר אן אלאלאה\\tإلى أن تقرّ أنَّ الإله', \"מתצל באלבשר אלא במעג'זה\\tمتّصل بالبشر إلاّ بمعجزة\", 'ירונה עיאנא , ולא יאתיהם\\tيرونه عياناً , ولا يأتيهم', \"תקבל אלנפוס הד'א אלאמר\\tتقبل النفوس هذا الأمر\", \"אלעט'ים , אעני אן כ'אלק\\tالعظيم , أعني أنَّ خالق\", \"מן סכ'ט עליה , ת'ם אלמן\\tمن سخط عليه , ثُمّ المنّ\", 'ואלסלוי טול ארבעין עאמא\\tوالسَلوَى طول أربعين عاماً', ', ותכלימה מוסי פי אלטור\\t, وتكليمه موسى في الطور', \", אליס הד'א משהורא ,\\t, أليس هذا مشهوراً ,\", 'מסאילהֿ אליהוד , לאנהם\\tمُساءلة اليهود , لأنّهم', ', ומכתפלהם פי אלתיה ,\\t, ومُكتفلهم في التِيه ,', \"ומדברה , ובמן כ'לקך ורזקך\\tومدبّره , وبمن خلقك ورزقك\", 'פי חכמתה ועדלה ? קאל\\tفي حكمته وعدله ? قالَ', 'אלפלאספה ענה , ולן תגדהם\\tالفلاسفة عنه , ولن تجدهم', 'דעאוי , מנהא מא יקדרון\\tدَعاوى , منها ما يقدرون', ': ארי כלאמך , יא יהודי\\t: أرى كلامك , يا يهوديّ', 'לי פי מקדמאת אקדמהא ,\\tلي في مُقدّمات أُقدّمها ,', 'פאני אראך מסתחקרא לכלאמי\\tفإنّي أراك مستحقراً لكلامي', ': קדם מקדמאתך חתי אסמע\\t: قدّمْ مقدّماتك حتّى أسمع', \"לך אן צאחב אלהנד פאצ'ל\\tلك إنَّ صاحب الهند فاضل\", 'יתצל בך מן עדל אהל בלאדה\\tيتّصل بك من عدل أهل بلاده', \"הל עדלהם מן ד'אתהם וליס\\tهل عدلهم من ذاتهم وليس\", \"אנהא לא תג'ד אלא פי אלהנד\\tأنّها لا توجد إلاّ في الهند\", \"מן אמראצ'ך , ותחפט' עליך\\tمن أمراضك , وتحفظ عليك\", \"אלחבר : ואד'א סאלת ענה\\tالحَبْرُ : وإذا سُئِلت عنه\", \"תצפה ? קאל אלכ'זרי :\\tتصفه ? قالَ الخَزَرِيُّ :\", \"פאתח מוסי פרעון , אד'\\tفاتح موسى فرعون , إذ\", '. ולם יקל לה : רב אלסמא\\t. ولم يقل له : ربّ السماء', \": פאד'א , שריעתכם אנמא\\t: فإذاً , شريعتكم إنّما\"]\n",
            "len(lines) 2184\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "إنّ ذلك القربان والـ\"طعام\"\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ׁ )\n",
            "in sentences:\n",
            "קאל אלחבר : אנ ישׁראל\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "فكيف تمكّن بالـ\"كسرة , بل\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "الوضع إلى الـ\"كسرة عند\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "الربيع بحسب حسابهم بالـ\"دورة\"\n",
            "\n",
            "VECTORIZE EXAMPLE\n",
            "‫ [\"וואאההלל אאללאאדדייאאננ תת''ממ עעלליי\", 'وأهل الأديان ثمّ على']\n",
            "37\n",
            "20\n",
            "[30, 30, 25, 25, 29, 29, 36, 36, 0, 25, 25, 36, 36, 25, 25, 28, 28, 34, 34, 25, 25, 38, 38, 0, 46, 46, 3, 3, 37, 37, 0, 40, 40, 36, 36, 34, 34]\n",
            "[58, 27, 57, 54, 0, 31, 54, 27, 39, 60, 31, 56, 0, 35, 55, 64, 0, 49, 54, 59]\n",
            "\n",
            "\n",
            "2184 2184\n",
            "test_dataset_double_kuzari\n",
            "========================================================================================================================================================================================================\n",
            "‫ ואהל אלאדיאנ ת'מ עלי  |  وأهل الأديان ثمّ على\n",
            "‫ , אלד'י כאנ ענד מלכ אלכ'זר  |  , الذي كان عند ملك الخزر\n",
            "‫ אלדאכ'ל פי דינ אליהוד  |  الداخل في دين اليهود\n",
            "‫ כתאב אלתואריכ' , אנה  |  كتاب التواريخ , أنه\n",
            "‫ תכרר עליה רויא , כאנ  |  تكرّر عليه رؤيا , كأنّ\n",
            "========================================================================================================================================================================================================\n",
            "loading text: /gdrive/My Drive/thesis-data/haemunot_vedeot/for_ctc_train22_FRIDBERG5.txt.test.txt\n",
            "first lines: ['באן קאל תבארך אללה אלאה\\tبأنْ قالَ تبارك الله إله', \"אמא עלי את'ר מא אפתתחנא\\tأمّا على إثر ما افتتحنا\", \"פי מטאלבהם וען וג'ה זואלהא\\tفي مطالبهم وعن وجه زوالها\", \"H H H . וארי אן אג'על\\tH H H . وأرى أنْ أجعل\", 'אלשבה באי סבב כאן מן\\tالشُبَه بأي سبب كان من', 'אלוקוף בין ידיה פלא יערפה\\tالوقوف بين يديه فلا يعرفه', \"פיכ'אד' באלאכ'ף ותרך\\tفيأخذ بالأخف وترك\", \"יתבינה . כאנת איצ'א אלאשיא\\tيتبيّنه . كانت أيضًا الأشياء\", \"אלאסתדלאל ، פהו יג'על\\tالاستدلال ، فهو يجعل\", \"איצ'א גיר אלדליל דלילא\\tأيضًا غير الدليل دليلاً\", '. ואמא לאנה יבצר טרק\\t. وإمّا لأنَّه يبصر طرق', \"אלנט'ר לכנה יאכ'ד' נפסה\\tالنَّظر لكنَّه يأخذ نفسه\", \": H H H ופי אלאכ'רין\\t: H H H وفي الآخرين\", \"אן אנצ'ם אלי הד'ין אלאמרין\\tإنْ انضمّ إلى هذين الأمرين\", \"פאנה יכון חיניד' אבעד\\tفإنه يكون حينئذ أبعد\", 'בל לא כם מן אלדראהם לה\\tبل لا كم مِن الدراهم له', \"ואן אכ'ד' מנה אקל ממה\\tوإنْ أخذ منه أقل ممّا\", 'הי חאל אלמלתמס אלוזן\\tهي حال الملتمس الوزن', \"מא יאכ'ד' אלרדי וירד\\tما يأخذ الرديء ويردّ\", 'אלתאמל וקד שבה אלכתאב\\tالتأمّل وقد شبّه الكتاب', 'אנתקאד כלאם אלעדל בנקד\\tانتقاد كلام العدل بنقد', \"H ، H H H יג'עלון אלד'ין\\tH ، H H H يجعلون الذين\", \"، כקולה : H H H וג'על\\t، كقوله : H H H وجعل\", 'עליהם אלשכוך בצברהם עלי\\tعليهم الشُّكوك بصبرهم على', \"H H וקאל אלולי אלאכ'ר\\tH H وقال الوليُّ الآخر\", 'מן אלנאס עליה פי אמאנאתהם\\tمن الناس عليه في أماناتهم', '، H H H . ומנהם מן קד\\t، H H H . ومنهم من قد', 'אנה אלחק פהו מתמסך באלזור\\tأنه الحقّ فهو متمسِّك بالزُّور', \"אלי אכ'ר זמאנא ורמי בה\\tإلى آخر زمانًا ورمى به\", 'כמן יריד מדינה וליס יערף\\tكمَن يريد مدينة وليس يعرف', \"וכד'לך פי ת'אלת'ה וראבעה\\tوكذلك في ثالثة ورابعة\", 'ופיה יקול אלכתאב : H\\tوفيه يقول الكتاب : H', \"הד'ה אלאצול וסו פרועהא\\tهذه الأصول وسوء فروعها\", \"מן כת'יר מן אלמומנין\\tمن كثير من المؤمنين\", \"אימאנהם לא כ'אלץ ואעתקאדהם\\tإيمانهم لا خالص واعتقادهم\", \"יתט'אהרון באלפסאד וקד\\tيتظاهرون بالفساد وقد\", 'ענדי ממא עלמני רבי מא\\tعندي ممّا علَّمني ربِّي ما', \"ממא רזקני מא אצ'עה להם\\tممّا رزقني ما أضعُه لهم\", 'רפדא ראית אן אסעאפהם\\tرِفْدًا رأيتُ أنَّ إسعافهم', 'בקצר עלמי ען אלתמאם ומקר\\tبقصر عِلْمِي عن التَّمام ومُقرٌّ', 'בנקץ מערפתי ען אלכמאל\\tبنقص معرفتي عن الكمال', \"ולסת באעלם מן אהל ג'ילי\\tولستُ بأَعلم من أهل جيلي\", 'לכן בטאקתי ומא בלגה עקלי\\tلكِّن بطاقتي وما بلغه عقلي', 'H H H H H H H H H H .\\tH H H H H H H H H H .', 'H H ، H H . ואנא אנשד\\tH H ، H H . وأنا أَنشدُ', \"באללה כ'אלק אלכל אי עאלם\\tبالله خالق الكلّ أيَّ عالِم\", 'אלי אחסנה ולא יקעדה ען\\tإلى أحسنه ولا يقعده عن', \"ד'לך מעני אן אלכתאב ליס\\tذلك معنى أنَّ الكتاب ليس\", \"אלתעצב ואלתג'אזף ואלתכ'ליט\\tالتعصُّب والتَّجازف والتَّخليط\", 'אלולי : H H H H H H H\\tالوليُّ : H H H H H H H', 'שכה וצאר אלמומן תקלידא\\tشكَّه وصار المؤمن تقليدًا', \"יומן נט'רא ופהמא ווקף\\tيؤمن نظرًا وفهمًا ووقفَ\", 'אלטאען בתלביס ואסתחא\\tالطاعنُ بتلبيس واستحى', 'כמא קאל : H H H H H H\\tكما قالَ : H H H H H H', \"אלזאג'ר להם ען אלכ'טא\\tالزَّاجر لهم عن الخطأ\", 'H ، H H H H . וצחת אמאנאתהם\\tH ، H H H H . وصحَّت أَماناتهم', 'פי אלעאלם כאנבסאט אלמא\\tفي العالم كانبساط الماء', \"אחד אלאפעאל מחתאג'א אלי\\tأحد الأفعال مُحتاجًا إلى\", 'מא תבתדי עלומהם להם תבתדי\\tما تبتدئ علومهم لهم تبتدئ', 'משבהה פלא יזאלוא בקוהֿ\\tمشبَّهة فلا يزالوا بقوَّة', '. וכמא אן לכל צנאעה מן\\t. وكما أنَّ لكلِّ صناعةٍ من', \"צנאיעהם אג'זא אן הם קטעוא\\tصنائعهم أجزاء إنْ هم قطعوا\", 'תתם תלך אלצנאעה כאלזראעה\\tتتم تلك الصِّناعة كالزِّراعة', \"כד'לך צנאעהֿ אלעלם תחתאג'\\tكذلك صناعة العِلم تحتاجُ\", \"עשר מת'לא ופי אלחאל אלת'אני\\tعشر مثلاً وفي الحال الثاني\", \"תציר ת'מאן וכד'לך כל\\tتصير ثمان وكذلك كلّ\", \"וג'ד אלאצואת משבהה משככה\\tوجد الأصوات مشبَّهة مُشكَّكة\", 'לה אבתדא פי תפצילהא פפצל\\tله ابتدأ في تفصيلها ففصل', \"אלאג'ראם כוקוע אלחג'ר\\tالأجرام كوقوع الحجر\", \"אד' לא פאידה פיה ויחצל\\tإذ لا فائدة فيه ويحصل\", 'מנהא קיל מפרדא לא יפיד\\tمنها قيل مفردًا لا يفيد', \"אד'א כאנת מפרדה פי אן\\tإذا كانت مفردة في أن\", \"אלסאדס עלי אלכלאם אלמג'מוע\\tالسادس على الكلام المجموع\", \"מג'מועתין או כלמה ואסם\\tمجموعتين أو كلمة واسم\", \". ת'ם יפצל מנהא אלכלמתין\\t. ثمّ يفصل منها الكلمتين\", \"ומא אשבה ד'לך . ת'ם יעלם\\tوما أشبه ذلك . ثمّ يعلم\", 'חארה וממתנע כקולך אלנאר\\tحارَّة وممتنع كقولك النَّار', \". ת'ם יעזל קסמי אלואג'ב\\t. ثمّ يعزل قسمي الواجب\", \"אלכ'בר אלממכן פיפחץ ענה\\tالخبر الممكن فيفحص عنه\", \"פימנע בה נט'רא ד'לך אלשי\\tفيمنع به نظرًا ذلك الشيء\", \"אלד'י חכם בה . פאד'א\\tالذي حكم به . فإذا\", \"ד'לך אלואחד חצל עליה\\tذلك الواحد حصل عليه\", 'אלאבואב אלאואיל ען נפסה\\tالأبواب الأوائل عن نفسه', \"ותלבסה מן קבל אלנט'ר\\tوتلبسه من قبل النَّظر\", 'פיה ועזל ואחדא ואחדא\\tفيه وعزل واحدًا واحدًا', \"אבתדי מן אשיא כת'ירה\\tابتدأ من أشياء كثيرة\", \"מן תסעה ת'ם סבעה מן ת'מאניה\\tمن تسعة ثمّ سبعة من ثمانية\", \"אלמחץ' . פאן הו קטע אלנט'ר\\tالمحض . فإنْ هو قطع النَّظر\", 'יעוד עליה בתמאמה פאן\\tيعود عليه بتمامه فإنْ', \"אן יעיד אלנט'ר מן אולה\\tأنْ يُعيد النَّظر من أوَّله\", \"אכ'ר לאנה אכ'ד' פי טריקהא\\tآخر لأنَّه أخذ في طريقها\", 'ולם יסתתמהא פכאנוא מן\\tولم يستتمّها فكانوا من', 'פי מן לא יסתופי מעני\\tفي من لا يستوفي معنى', 'אלחכמה : H H H H H H\\tالحكمة : H H H H H H', 'H H H H , פדלנא קולהם\\tH H H H , فدلَّنا قولهم', 'הם אסתופוא אלתעלם לם\\tهم استوفوا التعلُّم لم', \"יכון פי מא בינהם כ'לף\\tيكون في ما بينهم خلف\", \"ולא שגב . פלא ירד אלג'אהל\\tولا شغب . فلا يرد الجاهل\", \"תמני אן יג'עלה . אללה\\tتمنَّى أنْ يجعله . الله\", \"פאנמא סאל אן יג'עלה רבה\\tفإنَّما سأل أنْ يجعله ربَّه\"]\n",
            "len(lines) 2071\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "يماسّ معد الشرّ* . وكذلك\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "*فإن كان للحاسّة فهي لا\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            ", بل بعضها هي فروع *من\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "الحكمة فنقول , خلق *منها\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "الـסנה وفي قبّة المحضر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ס )\n",
            "in sentences:\n",
            "الـסנה وفي قبّة المحضر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( נ )\n",
            "in sentences:\n",
            "الـסנה وفي قبّة المحضر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ה )\n",
            "in sentences:\n",
            "الـסנה وفي قبّة المحضر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ל )\n",
            "in sentences:\n",
            ": H : H H H H H H H לעולם\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ע )\n",
            "in sentences:\n",
            ": H : H H H H H H H לעולם\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ו )\n",
            "in sentences:\n",
            ": H : H H H H H H H לעולם\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ל )\n",
            "in sentences:\n",
            ": H : H H H H H H H לעולם\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ם )\n",
            "in sentences:\n",
            ": H : H H H H H H H לעולם\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            ". *وإنه لا يتغيّر ولا يحوّل\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ע )\n",
            "in sentences:\n",
            "H H H H H H עיניך فمن آمن\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( י )\n",
            "in sentences:\n",
            "H H H H H H עיניך فمن آمن\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( נ )\n",
            "in sentences:\n",
            "H H H H H H עיניך فمن آمن\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( י )\n",
            "in sentences:\n",
            "H H H H H H עיניך فمن آمن\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ך )\n",
            "in sentences:\n",
            "H H H H H H עיניך فمن آمن\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "*الذي مضى معهم ليس هم\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            ", وترك خارجها [يحفـ]ظها\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "ذلك جبراً , *وذلك مثل\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( מ )\n",
            "in sentences:\n",
            "H : H : H H H H מפניך وكذلك\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( פ )\n",
            "in sentences:\n",
            "H : H : H H H H מפניך وكذلك\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( נ )\n",
            "in sentences:\n",
            "H : H : H H H H מפניך وكذلك\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( י )\n",
            "in sentences:\n",
            "H : H : H H H H מפניך وكذلك\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ך )\n",
            "in sentences:\n",
            "H : H : H H H H מפניך وكذلك\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "H H H H H H H *يعني أنه\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "إنّ لكل إنسان شريعة *على\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "يقدر أن يفعل *خيراً ,\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "والأوساخ والآلام , *فبيّن\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            ", *فنقول له , جسم الإنسان\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ח )\n",
            "in sentences:\n",
            "H H חמצתו وقوله H : H : H\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( מ )\n",
            "in sentences:\n",
            "H H חמצתו وقوله H : H : H\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( צ )\n",
            "in sentences:\n",
            "H H חמצתו وقوله H : H : H\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ת )\n",
            "in sentences:\n",
            "H H חמצתו وقوله H : H : H\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ו )\n",
            "in sentences:\n",
            "H H חמצתו وقوله H : H : H\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ר )\n",
            "in sentences:\n",
            "H : H H רטשה ولو وجب هذا\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ט )\n",
            "in sentences:\n",
            "H : H H רטשה ولو وجب هذا\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ש )\n",
            "in sentences:\n",
            "H : H H רטשה ولو وجب هذا\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ה )\n",
            "in sentences:\n",
            "H : H H רטשה ولو وجب هذا\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "بالـ\"مغوثة\" أهل كما يعني\n",
            "\n",
            "VECTORIZE EXAMPLE\n",
            "‫ ['בבאאננ קקאאלל תתבבאאררככ אאללללהה אאללאאהה', 'بأن قال تبارك الله إله']\n",
            "42\n",
            "22\n",
            "[26, 26, 25, 25, 38, 38, 0, 43, 43, 25, 25, 36, 36, 0, 46, 46, 26, 26, 25, 25, 44, 44, 35, 35, 0, 25, 25, 36, 36, 36, 36, 29, 29, 0, 25, 25, 36, 36, 25, 25, 29, 29]\n",
            "[32, 27, 56, 0, 52, 31, 54, 0, 34, 32, 31, 41, 53, 0, 31, 54, 54, 57, 0, 29, 54, 57]\n",
            "\n",
            "\n",
            "2071 2071\n",
            "test_dataset_double_rasag\n",
            "========================================================================================================================================================================================================\n",
            "‫ באנ קאל תבארכ אללה אלאה  |  بأن قال تبارك الله إله\n",
            "‫ אמא עלי את'ר מא אפתתחנא  |  أمّا على إثر ما افتتحنا\n",
            "‫ פי מטאלבהמ וענ וג'ה זואלהא  |  في مطالبهم وعن وجه زوالها\n",
            "‫ H H H . וארי אנ אג'על  |  H H H . وأرى أن أجعل\n",
            "‫ אלשבה באי סבב כאנ מנ  |  الشبه بأي سبب كان من\n",
            "========================================================================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofru0hLdgwVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"LOAD DATASET\"\n",
        "\n",
        "\n",
        "# lines=load_lines(hakuzari)\n",
        "# pairs = create_parralel_phrases(lines,1)  \n",
        "# input_tensor, target_tensor ,input_lenghts,target_lengths = create_data_tensors(pairs)\n",
        "# dataset_double_kuzari,test_dataset_double_kuzari=gen_data(input_tensor, target_tensor,input_lenghts,target_lengths)\n",
        "# print_log_screen(\"test_dataset_double_kuzari\")\n",
        "# view_data(test_dataset_double_kuzari)\n",
        "\n",
        "# lines1=load_lines(haemunot)\n",
        "# pairs1 = create_parralel_phrases(lines1,1)  \n",
        "# input_tensor1, target_tensor1 ,input_lenghts1,target_lengths1 = create_data_tensors(pairs1)\n",
        "# dataset_double_rasag,test_dataset_double_rasag=gen_data(input_tensor1, target_tensor1,input_lenghts1,target_lengths1)\n",
        "# print_log_screen(\"test_dataset_double_rasag\")\n",
        "# view_data(test_dataset_double_rasag)\n",
        "\n",
        "\n",
        "# # def gen kuzari_drop(lines,keep):\n",
        "# #   pairs = create_parralel_phrases(lines,0.90)  \n",
        "# #   input_tensor, target_tensor ,input_lenghts,target_lengths = create_data_tensors(pairs)\n",
        "# #   dataset_double_kuzari,test_dataset_double_kuzari=gen_data(input_tensor, target_tensor,input_lenghts,target_lengths)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m_4H-rpFyk8",
        "colab_type": "text"
      },
      "source": [
        "##SYNTHETIC DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpKhndwM10b0",
        "colab_type": "text"
      },
      "source": [
        "###load_lines_synth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOU-bSFtpEgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"load_lines_synth\"\n",
        "\n",
        "#TODO edit when time permits\n",
        "\n",
        "def load_lines_synth(file_path=\"/gdrive/My Drive/JUDEO-ARAB/ibn_sina_ilhyat.txt\"):\n",
        "  with open(file_path, 'rb') as f:\n",
        "      text = f.read().decode(encoding='utf-8')\n",
        "\n",
        "\n",
        "  text=replace_arab_style_punctuation(text) #TODO WHAT ABOUT OTHER ARAB NORMALIZATION???\n",
        "  #TODO somthing with new line - this indicates new content!!!\n",
        "\n",
        "  #add space before and after punctuation signs\n",
        "  text = re.sub(r\"([:;?.!,¿])\", r\" \\1 \", text)\n",
        "  text = re.sub(r'[\" \"]+', \" \", text)    \n",
        "\n",
        "  words=text.split()  \n",
        "  SENTENCE_LIMIT=20\n",
        "  sentences=[]\n",
        "  char_count=0\n",
        "  res=[]\n",
        "  for w in words:\n",
        "  #  w=w.rstrip(\" \").strip(\" \")\n",
        "    char_count+=len(w)+1 #len of word + space afterwards\n",
        "    res.append(w)\n",
        "    if char_count>SENTENCE_LIMIT:    \n",
        "      #sentences.append(normalize_unicode(remove_arab_nikud(\" \".join(res))))\n",
        "      sentences.append(\" \".join(res))\n",
        "      res=[]\n",
        "      char_count=0\n",
        "  return sentences\n",
        "\n",
        "# res=load_lines_synth()\n",
        "# print(len(res))\n",
        "#res[-5:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9CAcJjeyB_E",
        "colab_type": "text"
      },
      "source": [
        "###preprocess_synth_lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdHcLRT0uhA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_synth_lines(arab_sentences):\n",
        "  res_sentences=[]\n",
        "  for arr in arab_sentences:    \n",
        "    arr=preprocess_arr(arr)\n",
        "    res_sentences.append(arr)\n",
        "  return res_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mOenDCDtDfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"GEN SYNTH\"\n",
        "\n",
        "# #TODO edit when time permits\n",
        "\n",
        "# def load_lines_synth(ibnsina=\"/gdrive/My Drive/JUDEO-ARAB/ibn_sina_ilhyat.txt\"):\n",
        "#   with open(ibnsina, 'rb') as f:\n",
        "#       ibnsina_text = f.read().decode(encoding='utf-8')\n",
        "\n",
        "\n",
        "#   ibnsina_text=replace_arab_style_punctuation(ibnsina_text) #TODO WHAT ABOUT OTHER ARAB NORMALIZATION???\n",
        "#   #TODO somthing with new line - this indicates new content!!!\n",
        "\n",
        "#   #add space before and after punctuation signs\n",
        "#   ibnsina_text = re.sub(r\"([:;?.!,¿])\", r\" \\1 \", ibnsina_text)\n",
        "#   ibnsina_text = re.sub(r'[\" \"]+', \" \", ibnsina_text)    \n",
        "  \n",
        "#   return ibnsina_text\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3kHwSPQLfIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"DEF gen_synth_sentences\"\n",
        "\n",
        "# def gen_synth_sentences(sina_words):\n",
        "#   #SENTENCE_LIMIT=random.randint(1,50) #this didn't work. try random with range1,10\n",
        "#   SENTENCE_LIMIT=20\n",
        "#   sentences=[]\n",
        "#   char_count=0\n",
        "#   res=[]\n",
        "#   for w in sina_words:\n",
        "#   #  w=w.rstrip(\" \").strip(\" \")\n",
        "#     char_count+=len(w)+1 #len of word + space afterwards\n",
        "#     res.append(w)\n",
        "#     if char_count>SENTENCE_LIMIT:    \n",
        "#       sentences.append(normalize_unicode(remove_arab_nikud(\" \".join(res))))\n",
        "#       res=[]\n",
        "#       char_count=0\n",
        "#     #  SENTENCE_LIMIT=random.randint(1,50)          \n",
        "#   return sentences\n",
        "\n",
        "# # #ACTIVATE\n",
        "# # sentences=gen_synth_sentences(sina_words)\n",
        "# # len(sentences)\n",
        "# # sentences[:5]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7AqGe0R1_a_",
        "colab_type": "text"
      },
      "source": [
        "###create_parralel_phrases_synth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMt2VQPrMtIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"DEF gen_dropout\"\n",
        "\n",
        "def create_parralel_phrases_synth(sentences,keep=0.90):\n",
        "  arab_setences=[]\n",
        "  heb_sentences=[]\n",
        "  for arr in sentences:\n",
        "    arab_setences.append(arr)           \n",
        "    heb=reverse_simple_map(arr)\n",
        "    heb=dropout(heb,keep)\n",
        "    heb_sentences.append(double_hebrew(heb))\n",
        "\n",
        "  print_log(heb_sentences[:5]) \n",
        "  print_log(arab_setences[:5])\n",
        "\n",
        "  print_log(len(arab_setences))\n",
        "  \n",
        "  return list(zip(heb_sentences,arab_setences))\n",
        "\n",
        "  #input_tensor_synth, target_tensor_synth, \\  \n",
        "  # input_lenghts_synth,target_lengths_synth = create_data_tensors(list(zip(heb_sentences,arab_setences)))\n",
        "  \n",
        "  # # Show length\n",
        "  # print_log(len(input_tensor_synth), len(target_tensor_synth))\n",
        "  # print_log(len(input_lenghts_synth), len(target_lengths_synth))\n",
        "\n",
        "  # BUFFER_SIZE = len(input_tensor_synth)\n",
        "\n",
        "  # dataset_synth = tf.data.Dataset.from_tensor_slices((input_tensor_synth,\n",
        "  #                                                     target_tensor_synth,\n",
        "  #                                                     input_lenghts_synth,\n",
        "  #                                                     target_lengths_synth)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "\n",
        "  # dataset_double_synt=dataset_synth.batch(BATCH_SIZE, drop_remainder=True)\n",
        "  # return dataset_double_synt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUcBdNP-Ms-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"DEF gen_dropout_all\"\n",
        "\n",
        "# def gen_dropout_all(sntcs1,*sentences,keep=1):\n",
        "#   result_dataset=gen_dropout(sntcs1,keep)\n",
        "#   for sntcs in sentences:\n",
        "#     result_dataset.concatenate(gen_dropout(sntcs,keep))\n",
        "#   return result_dataset.shuffle(1000)\n",
        "\n",
        "# #   BUFFER_SIZE=1000 #TODO get size\n",
        "# #   return dataset_double_synt3.concatenate(dataset_double_kuzari).shuffle(BUFFER_SIZE)  ##TODO: this is without dropout. \n",
        "# # #view_data(gen_dropout_all())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auU5EkGq5fW9",
        "colab_type": "text"
      },
      "source": [
        "##activate gen synth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WTc9QYMawy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e473e2f-8b08-496d-8a04-72e014af373c"
      },
      "source": [
        "synth_path0=\"/gdrive/My Drive/JUDEO-ARAB/ibn_sina_ilhyat.txt\"\n",
        "synth_sentences0=preprocess_synth_lines(\n",
        "    load_lines_synth(synth_path0)\n",
        ")\n",
        "\n",
        "\n",
        "synth_phrase_pairs0=create_parralel_phrases_synth(synth_sentences0,\n",
        "                                                  0.9)\n",
        "synth_dataset0=produce_dataset(synth_phrase_pairs0,\n",
        "                               to_shuffle=TO_SHUFFLE)\n",
        "view_data(synth_dataset0)\n",
        "\n",
        "#####################3\n",
        "synth_path1=\"/gdrive/My Drive/JUDEO-ARAB/daruri-IR.txt\"\n",
        "synth_sentences1=preprocess_synth_lines(\n",
        "    load_lines_synth(synth_path1)\n",
        ")\n",
        "synth_phrase_pairs1=create_parralel_phrases_synth(synth_sentences1,\n",
        "                                                  0.9)\n",
        "synth_dataset1=produce_dataset(synth_phrase_pairs1,\n",
        "                               to_shuffle=TO_SHUFFLE)\n",
        "view_data(synth_dataset1)\n",
        "\n",
        "\n",
        "#######################33\n",
        "synth_path2=\"/gdrive/My Drive/JUDEO-ARAB/farabi-tahsil.txt\"\n",
        "synth_sentences2=preprocess_synth_lines(\n",
        "    load_lines_synth(synth_path2)\n",
        ")\n",
        "synth_phrase_pairs2=create_parralel_phrases_synth(synth_sentences2,\n",
        "                                                  0.9)\n",
        "synth_dataset2=produce_dataset(synth_phrase_pairs2,\n",
        "                               to_shuffle=TO_SHUFFLE)\n",
        "view_data(synth_dataset2)\n",
        "\n",
        "##########################3\n",
        "synth_path3=\"/gdrive/My Drive/JUDEO-ARAB/huruf.txt\"\n",
        "synth_sentences3=preprocess_synth_lines(\n",
        "    load_lines_synth(synth_path3)\n",
        ")\n",
        "\n",
        "synth_phrase_pairs3=create_parralel_phrases_synth(synth_sentences3,\n",
        "                                                  0.9)\n",
        "synth_dataset3=produce_dataset(synth_phrase_pairs3,\n",
        "                               to_shuffle=False)\n",
        "view_data(synth_dataset3)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‫Skipping char not in predefined map\n",
            " ( ‏ )\n",
            "in sentences:\n",
            "صار نوعاً . ‏ وإن كانت\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ‎ )\n",
            "in sentences:\n",
            "لأنها زمانية . ‎ فلا\n",
            "\n",
            "['ככתתאאבב אאללששפפאא אאללאאללההיי__תת', \"אאללששייככ'' אאללררייייסס ____ננ ססיי__אא\", \"ממווקקעע אאללפפללסספפהה__ אאללאאססללאאממייהה''\", \"אאללפפההררססתת אאללממקקאאללהה'' אאללאאוולליי\", ':: אאללפפצצלל אאללאאוולל :: פפיי אאבבתת__אא']\n",
            "['كتاب الشفاء الإلهيات', 'الشيخ الرئيس ابن سينا', 'موقع الفلسفة الإسلامية', 'الفهرست المقالة الأولى', ': الفصل الأول : في ابتداء']\n",
            "21322\n",
            "VECTORIZE EXAMPLE\n",
            "‫ ('ככתתאאבב אאללששפפאא אאללאאללההיי__תת', 'كتاب الشفاء الإلهيات')\n",
            "36\n",
            "20\n",
            "[35, 35, 46, 46, 25, 25, 26, 26, 0, 25, 25, 36, 36, 45, 45, 41, 41, 25, 25, 0, 25, 25, 36, 36, 25, 25, 36, 36, 29, 29, 34, 34, 47, 47, 46, 46]\n",
            "[53, 34, 31, 32, 0, 31, 54, 44, 51, 31, 25, 0, 31, 54, 29, 54, 57, 60, 31, 34]\n",
            "\n",
            "\n",
            "21322 21322\n",
            "========================================================================================================================================================================================================\n",
            "‫ כתאב אלשפא אלאלהי_ת  |  كتاب الشفاء الإلهيات\n",
            "‫ אלשיכ' אלרייס __נ סי_א  |  الشيخ الرئيس ابن سينا\n",
            "‫ מוקע אלפלספה_ אלאסלאמיה'  |  موقع الفلسفة الإسلامية\n",
            "‫ אלפהרסת אלמקאלה' אלאולי  |  الفهرست المقالة الأولى\n",
            "‫ : אלפצל אלאול : פי אבת_א  |  : الفصل الأول : في ابتداء\n",
            "========================================================================================================================================================================================================\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "القسم الأول 11 – أما\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            ". 12ـ وأما المعتزلة فاستدلوا\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "13ـ والقول في هذه المسألة\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "حصول العلم به . 14ـ وقد\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "نهاية . 15ـ والذي ينبغي\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            ". ] . 16ـ أما من ذهب\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            "الأول 17ـ وهو يتضمن النظر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ". 76 /1 مسألة ثالثة :\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "الحرام ضد الواجب 28 –\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( { )\n",
            "in sentences:\n",
            ": {لا تقربوا الصلاة وأنتم\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( } )\n",
            "in sentences:\n",
            "سكارى} فإنه إن سلم ظهور\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "من هذا –كما زعموا-وجوب\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "فصول : 93/1 الفصل الأول\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "ذلك . 95/1 الفصل الثالث\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ـ )\n",
            "in sentences:\n",
            ": 63 62ـ وهو يتضمن النظر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "المجتهد) ص 8990/ ج 1\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( A )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( l )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( b )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( a )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( n )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( y )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( S )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( t )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( a )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( t )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( e )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( U )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( n )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( v )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( e )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( r )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( t )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( y )\n",
            "in sentences:\n",
            "1977 : Albany State University\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( f )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( N )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( e )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( w )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( Y )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( r )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( k )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( P )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( r )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( e )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            "of New York Press . 194189]\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "للزركشي 4/239 . أنظر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            ". 77 –وإذا وضع هذا ,\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "78 – فهذا ما ينبغي أن\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            ". 80 –ويلحق بخبر الواحد\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "بخبر الواحد شرعا 81 –\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ﴿ )\n",
            "in sentences:\n",
            "عزوجل : ﴿ فلولا نفر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ﴿ )\n",
            "in sentences:\n",
            "وجل ﴿إن الذين يكتمون\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( ﴾ )\n",
            "in sentences:\n",
            "والهدى ﴾ وبقوله) : نضر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "للزركشي 4/364 . أنظر\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "بقوله عليه السلام- *لا\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( * )\n",
            "in sentences:\n",
            "وصية لوارث*- لكن في هذا\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "السلام – لا وصية للوارث\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "– وكذلك احتجوا بقوله\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ". ص326/ج2 . ] وهو نسخ\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "قال : ( ص74/جI) (وقد\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( I )\n",
            "in sentences:\n",
            "قال : ( ص74/جI) (وقد\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "من البداية (ص126/جi)\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            "من البداية (ص126/جi)\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "عليه . [221/1] 142- والاستصحاب\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( | )\n",
            "in sentences:\n",
            "| . . . على الأمة أن\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( | )\n",
            "in sentences:\n",
            "بدليل العصمة | [ كلمة\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "المرسل . انظر ص197/ج2\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ", 327/ج2 وسننقل في الهوامش\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( | )\n",
            "in sentences:\n",
            "سبب خاص فأخرج مخرج |\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( | )\n",
            "in sentences:\n",
            "العام | [ كتب الناسخ\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "القاهر الجرجاني 2/719\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "ومجاز القرآن 1/328 وجمل\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "القاهر الجرجانى 1/720\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "للزركشي 3/280 , وعلق\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "–وأما هل يكون المستثنى\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "ص : 288 / ج ا . –] .\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "ص : 288 / ج ا . –] .\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "ص 3/ ج 1 . ] . والشىء\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "أو الطوافات ص 21 / ج\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "ص 143 / ج ا من بداية\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "ص 275 / ج 2 . ] , فان\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "بداية المجتهد ص 273 /\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ". انظرالبداية ص202-220/\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ". . . ص 15/ 2 . ] وهو\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "انظر ص 101/ج ا . ] ,\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ". ص 80 /ج 2 . ] وربما\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ". ص3 /ج ا . ] , ولا يوجد\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            "من خطاب العرب ص 3-4/ج1\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ". انظر 42-108-347/ج ا\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ". 142 / ج2 . ] . 240\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ": 105-136-138-140-311/ج1-45-55-75-96-104-111-116-131-147-152-165-173-189-255-274-289-290-291-332/ج2\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( / )\n",
            "in sentences:\n",
            ": 105-136-138-140-311/ج1-45-55-75-96-104-111-116-131-147-152-165-173-189-255-274-289-290-291-332/ج2\n",
            "\n",
            "['בבססממ אאללללהה אאללרר__ממננ אאללררחחייממ', \"אאללצצ''ררוורריי פפיי אאצצוולל אאללפפקקהה\", \"אאוו ממככ''תתצצרר אאללממססתתצצפפיי ללאאבביי\", 'אאללוולל__דד __חחממדד בבננ ררשש__ אאללחח__יידד', \"אאלל__תתוופפיי ססננהה'' 559955הה תתקקדדיי__\"]\n",
            "['بسم الله الرحمن الرحيم', 'الضروري في أصول الفقه', 'أو مختصر المستصفى لأبي', 'الوليد محمد بن رشد الحفيد', 'المتوفى سنة 595ه تقديم']\n",
            "5610\n",
            "VECTORIZE EXAMPLE\n",
            "‫ ('בבססממ אאללללהה אאללרר__ממננ אאללררחחייממ', 'بسم الله الرحمن الرحيم')\n",
            "41\n",
            "22\n",
            "[26, 26, 39, 39, 37, 37, 0, 25, 25, 36, 36, 36, 36, 29, 29, 0, 25, 25, 36, 36, 44, 44, 47, 47, 37, 37, 38, 38, 0, 25, 25, 36, 36, 44, 44, 32, 32, 34, 34, 37, 37]\n",
            "[32, 43, 55, 0, 31, 54, 54, 57, 0, 31, 54, 41, 37, 55, 56, 0, 31, 54, 41, 37, 60, 55]\n",
            "\n",
            "\n",
            "5610 5610\n",
            "========================================================================================================================================================================================================\n",
            "‫ בסמ אללה אלר_מנ אלרחימ  |  بسم الله الرحمن الرحيم\n",
            "‫ אלצ'רורי פי אצול אלפקה  |  الضروري في أصول الفقه\n",
            "‫ או מכ'תצר אלמסתצפי לאבי  |  أو مختصر المستصفى لأبي\n",
            "‫ אלול_ד _חמד בנ רש_ אלח_יד  |  الوليد محمد بن رشد الحفيد\n",
            "‫ אל_תופי סנה' 595ה תקדי_  |  المتوفى سنة 595ه تقديم\n",
            "========================================================================================================================================================================================================\n",
            "['בבססממ אאללללהה אאללררחחממננ __ללררחחייממ', 'וובבהה ננססתתעעייננ ככתתאאבב תתחחצציילל', \"אאללססעעאא__הה'' אאבבוו ננצצרר ____פפאארראאבב__\", \"__ללאאשש__אא אא__אא__ססאאננייהה'' אאללתתיי\", \"אאדד''אא חחצצללתת פפיי אאללאאממ__ וופפ__\"]\n",
            "['بسم الله الرحمن الرحيم', 'وبه نستعين كتاب تحصيل', 'السعادة ابو نصر الفارابي', 'الأشياء الإنسانية التي', 'إذا حصلت في الأمم وفي']\n",
            "2274\n",
            "VECTORIZE EXAMPLE\n",
            "‫ ('בבססממ אאללללהה אאללררחחממננ __ללררחחייממ', 'بسم الله الرحمن الرحيم')\n",
            "41\n",
            "22\n",
            "[26, 26, 39, 39, 37, 37, 0, 25, 25, 36, 36, 36, 36, 29, 29, 0, 25, 25, 36, 36, 44, 44, 32, 32, 37, 37, 38, 38, 0, 47, 47, 36, 36, 44, 44, 32, 32, 34, 34, 37, 37]\n",
            "[32, 43, 55, 0, 31, 54, 54, 57, 0, 31, 54, 41, 37, 55, 56, 0, 31, 54, 41, 37, 60, 55]\n",
            "\n",
            "\n",
            "2274 2274\n",
            "========================================================================================================================================================================================================\n",
            "‫ בסמ אללה אלרחמנ _לרחימ  |  بسم الله الرحمن الرحيم\n",
            "‫ ובה נסתעינ כתאב תחציל  |  وبه نستعين كتاب تحصيل\n",
            "‫ אלסעא_ה' אבו נצר __פאראב_  |  السعادة ابو نصر الفارابي\n",
            "‫ _לאש_א א_א_סאניה' אלתי  |  الأشياء الإنسانية التي\n",
            "‫ אד'א חצלת פי אלאמ_ ופ_  |  إذا حصلت في الأمم وفي\n",
            "========================================================================================================================================================================================================\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "الأبيض – وهو شخص الأبيض\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "– يعنون به الوجود والوجدان\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( w )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( w )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( w )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( u )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( l )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( p )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( h )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( l )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( p )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( h )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( y )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( c )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( w )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( e )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( b )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( a )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( t )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( e )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( r )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( @ )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( u )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( l )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( p )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( h )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( l )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( p )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( h )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( y )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "[\"ככתתאאבב ררססאאללהה'' אאללחחררוופפ ללללפפייללססוופפ\", 'אאבביי ננצצרר אאללפפאארראאבביי בבססממ', 'אאללללהה אאללררחחממננ אאללררחחיי__ וובבהה', 'ננסס__עעייננ אאללחחממדד ללללהה __בב', '__ללעעאאללממייננ וו__ללססלל__ממ עעלליי']\n",
            "['كتاب رسالة الحروف للفيلسوف', 'أبي نصر الفارابيّ بسم', 'الله الرحمن الرحيم وبه', 'نستعين الحمد لله ربّ', 'العالمين والسلام على']\n",
            "9940\n",
            "VECTORIZE EXAMPLE\n",
            "‫ (\"ככתתאאבב ררססאאללהה'' אאללחחררוופפ ללללפפייללססוופפ\", 'كتاب رسالة الحروف للفيلسوف')\n",
            "51\n",
            "26\n",
            "[35, 35, 46, 46, 25, 25, 26, 26, 0, 44, 44, 39, 39, 25, 25, 36, 36, 29, 29, 3, 3, 0, 25, 25, 36, 36, 32, 32, 44, 44, 30, 30, 41, 41, 0, 36, 36, 36, 36, 41, 41, 34, 34, 36, 36, 39, 39, 30, 30, 41, 41]\n",
            "[53, 34, 31, 32, 0, 41, 43, 31, 54, 33, 0, 31, 54, 37, 41, 58, 51, 0, 54, 54, 51, 60, 54, 43, 58, 51]\n",
            "\n",
            "\n",
            "9940 9940\n",
            "========================================================================================================================================================================================================\n",
            "‫ כתאב רסאלה' אלחרופ ללפילסופ  |  كتاب رسالة الحروف للفيلسوف\n",
            "‫ אבי נצר אלפאראבי בסמ  |  أبي نصر الفارابيّ بسم\n",
            "‫ אללה אלרחמנ אלרחי_ ובה  |  الله الرحمن الرحيم وبه\n",
            "‫ נס_עינ אלחמד ללה _ב  |  نستعين الحمد لله ربّ\n",
            "‫ _לעאלמינ ו_לסל_מ עלי  |  العالمين والسلام على\n",
            "========================================================================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT4q_5EwyowP",
        "colab_type": "text"
      },
      "source": [
        "##gen_all_synth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkbugLUuw2Ux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "0d4f1ef0-7215-4bac-b4a3-a8b0171ad861"
      },
      "source": [
        "CELL_NAME=\"GEN_ALL_SYNTH\"\n",
        "all_synth_lines=synth_sentences0+synth_sentences1+synth_sentences2+synth_sentences3\n",
        "\n",
        "def gen_all_synth(keep):\n",
        "  all_synth_phrase_pairs=create_parralel_phrases_synth(all_synth_lines,\n",
        "                                                      keep)\n",
        "  all_synth_dataset=produce_dataset(all_synth_phrase_pairs,\n",
        "                                   to_shuffle=TO_SHUFFLE)\n",
        "  view_data(all_synth_dataset)\n",
        "  return all_synth_dataset"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ככתתאאבב אאללששפפאא אאללאאללההייאאתת', \"אאללשש____'' אאללרר__ייסס אאבבננ ססיי__אא\", \"ממווקקעע אאללפפללסספפהה'' אאללאאססללאאממייהה''\", \"אאללפפההררססתת אא__ממקקאאלל__'' אאללאאוולליי\", ':: אאללפפצצלל אאלל__וו__ :: פפיי אאבבתתדדאא']\n",
            "['كتاب الشفاء الإلهيات', 'الشيخ الرئيس ابن سينا', 'موقع الفلسفة الإسلامية', 'الفهرست المقالة الأولى', ': الفصل الأول : في ابتداء']\n",
            "39146\n",
            "VECTORIZE EXAMPLE\n",
            "‫ ('ככתתאאבב אאללששפפאא אאללאאללההייאאתת', 'كتاب الشفاء الإلهيات')\n",
            "36\n",
            "20\n",
            "[35, 35, 46, 46, 25, 25, 26, 26, 0, 25, 25, 36, 36, 45, 45, 41, 41, 25, 25, 0, 25, 25, 36, 36, 25, 25, 36, 36, 29, 29, 34, 34, 25, 25, 46, 46]\n",
            "[53, 34, 31, 32, 0, 31, 54, 44, 51, 31, 25, 0, 31, 54, 29, 54, 57, 60, 31, 34]\n",
            "\n",
            "\n",
            "39146 39146\n",
            "========================================================================================================================================================================================================\n",
            "‫ הו נוע , ב_ _י_א הו נוע  |  هو نوع , بل فيما هو نوع\n",
            "‫ _ליה באלעקל אנה ואג'ב  |  إليه بالعقل أنه واجب\n",
            "‫ , ואחדהמא מעדומ ומא אשבה  |  , وأحدهما معدوم وما أشبه\n",
            "‫ _וקע אלפרצ' אל_ול . אלצפחה'  |  موقع الفرض الأول . الصفحة\n",
            "‫ נ_יר מנהא אלי מא הו מת'אלה  |  نصير منها إلى ما هو مثاله\n",
            "========================================================================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9PbEec88luZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "045b1f55-d364-49b0-95cc-54d7545f0da9"
      },
      "source": [
        "# synth_path3=\"/gdrive/My Drive/JUDEO-ARAB/huruf.txt\"\n",
        "# synth_sentences3=preprocess_synth_lines(\n",
        "#     load_lines_synth(synth_path3)\n",
        "# )\n",
        "# ################\n",
        "# synth_phrase_pairs3=create_parralel_phrases_synth(synth_sentences3,\n",
        "#                                                   0.9)\n",
        "# synth_dataset3=produce_dataset(synth_phrase_pairs3,\n",
        "#                                to_shuffle=TO_SHUFFLE)\n",
        "# view_data(synth_dataset3)\n",
        "\n",
        "# #################\n",
        "# synth_phrase_pairs3=create_parralel_phrases_synth(synth_sentences3,\n",
        "#                                                   0.9)\n",
        "# synth_dataset3=produce_dataset(synth_phrase_pairs3,\n",
        "#                                to_shuffle=TO_SHUFFLE)\n",
        "# view_data(synth_dataset3)\n",
        "\n",
        "# ##################\n",
        "# synth_phrase_pairs3=create_parralel_phrases_synth(synth_sentences3,\n",
        "#                                                   0.9)\n",
        "# synth_dataset3=produce_dataset(synth_phrase_pairs3,\n",
        "#                                to_shuffle=TO_SHUFFLE)\n",
        "# view_data(synth_dataset3)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "الأبيض – وهو شخص الأبيض\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( – )\n",
            "in sentences:\n",
            "– يعنون به الوجود والوجدان\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( w )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( w )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( w )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( u )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( l )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( p )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( h )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( l )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( p )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( h )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( y )\n",
            "in sentences:\n",
            "(www . muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( c )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( w )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( e )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( b )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( a )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( t )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( e )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( r )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( @ )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( u )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( l )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( m )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( p )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( h )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( i )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( l )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( s )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( o )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( p )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( h )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "‫Skipping char not in predefined map\n",
            " ( y )\n",
            "in sentences:\n",
            ". com) للمراسلة : webmaster@muslimphilosophy\n",
            "\n",
            "[\"ככתתאאבב ררסס__ללהה'' אא__חחררוופפ ללללפפיי__ססוופפ\", 'אאבביי ננצצרר אאללפפאארראאבביי בבססממ', '____ללהה אאללררחחממננ אאללררחחייממ וובבהה', 'ננ__תת__ייננ אאללחחממדד לל__הה ררבב', 'אאללעע__ללממייננ __אאללססללאאממ עע__יי']\n",
            "['كتاب رسالة الحروف للفيلسوف', 'أبي نصر الفارابيّ بسم', 'الله الرحمن الرحيم وبه', 'نستعين الحمد لله ربّ', 'العالمين والسلام على']\n",
            "9940\n",
            "VECTORIZE EXAMPLE\n",
            "‫ (\"ככתתאאבב ררסס__ללהה'' אא__חחררוופפ ללללפפיי__ססוופפ\", 'كتاب رسالة الحروف للفيلسوف')\n",
            "51\n",
            "26\n",
            "[35, 35, 46, 46, 25, 25, 26, 26, 0, 44, 44, 39, 39, 47, 47, 36, 36, 29, 29, 3, 3, 0, 25, 25, 47, 47, 32, 32, 44, 44, 30, 30, 41, 41, 0, 36, 36, 36, 36, 41, 41, 34, 34, 47, 47, 39, 39, 30, 30, 41, 41]\n",
            "[53, 34, 31, 32, 0, 41, 43, 31, 54, 33, 0, 31, 54, 37, 41, 58, 51, 0, 54, 54, 51, 60, 54, 43, 58, 51]\n",
            "\n",
            "\n",
            "9940 9940\n",
            "========================================================================================================================================================================================================\n",
            "‫ כתאב רס_לה' א_חרופ ללפי_סופ  |  كتاب رسالة الحروف للفيلسوف\n",
            "‫ אבי נצר אלפאראבי בסמ  |  أبي نصر الفارابيّ بسم\n",
            "‫ __לה אלרחמנ אלרחימ ובה  |  الله الرحمن الرحيم وبه\n",
            "‫ נ_ת_ינ אלחמד ל_ה רב  |  نستعين الحمد لله ربّ\n",
            "‫ אלע_למינ _אלסלאמ ע_י  |  العالمين والسلام على\n",
            "========================================================================================================================================================================================================\n",
            "[\"ככתתאאבב ררססאאללהה'' אאללחחררוופפ ללללפפ__ללססוו__\", 'אאבביי ננצצרר אאלל__אא__אאבביי בבססממ', 'אאללללהה אאללררחח__ננ אאלל__חחייממ וובבהה', 'ננססתתעעייננ אאללחחממ__ לללל__ ררבב', 'אאללעעאא____ייננ וואאללססללאאממ עעלליי']\n",
            "['كتاب رسالة الحروف للفيلسوف', 'أبي نصر الفارابيّ بسم', 'الله الرحمن الرحيم وبه', 'نستعين الحمد لله ربّ', 'العالمين والسلام على']\n",
            "9940\n",
            "VECTORIZE EXAMPLE\n",
            "‫ (\"ככתתאאבב ררססאאללהה'' אאללחחררוופפ ללללפפ__ללססוו__\", 'كتاب رسالة الحروف للفيلسوف')\n",
            "51\n",
            "26\n",
            "[35, 35, 46, 46, 25, 25, 26, 26, 0, 44, 44, 39, 39, 25, 25, 36, 36, 29, 29, 3, 3, 0, 25, 25, 36, 36, 32, 32, 44, 44, 30, 30, 41, 41, 0, 36, 36, 36, 36, 41, 41, 47, 47, 36, 36, 39, 39, 30, 30, 47, 47]\n",
            "[53, 34, 31, 32, 0, 41, 43, 31, 54, 33, 0, 31, 54, 37, 41, 58, 51, 0, 54, 54, 51, 60, 54, 43, 58, 51]\n",
            "\n",
            "\n",
            "9940 9940\n",
            "========================================================================================================================================================================================================\n",
            "‫ כתאב רסאלה' אלחרופ ללפ_לסו_  |  كتاب رسالة الحروف للفيلسوف\n",
            "‫ אבי נצר אל_א_אבי בסמ  |  أبي نصر الفارابيّ بسم\n",
            "‫ אללה אלרח_נ אל_חימ ובה  |  الله الرحمن الرحيم وبه\n",
            "‫ נסתעינ אלחמ_ לל_ רב  |  نستعين الحمد لله ربّ\n",
            "‫ אלעא__ינ ואלסלאמ עלי  |  العالمين والسلام على\n",
            "========================================================================================================================================================================================================\n",
            "['ככתתאאבב __ססאאללהה__ __ללחחררוופפ ללללפפייללססוופפ', 'אאבביי ננצצרר אאללפפאארר__בביי בבסס__', 'אאללללהה אאללררחחממננ אאללררחחייממ וובבהה', 'ננססתת__ייננ אאללחחממדד ללללהה ררבב', 'אא__עעאאללממיי__ וואא__ססללאאממ עעלליי']\n",
            "['كتاب رسالة الحروف للفيلسوف', 'أبي نصر الفارابيّ بسم', 'الله الرحمن الرحيم وبه', 'نستعين الحمد لله ربّ', 'العالمين والسلام على']\n",
            "9940\n",
            "VECTORIZE EXAMPLE\n",
            "‫ ('ככתתאאבב __ססאאללהה__ __ללחחררוופפ ללללפפייללססוופפ', 'كتاب رسالة الحروف للفيلسوف')\n",
            "51\n",
            "26\n",
            "[35, 35, 46, 46, 25, 25, 26, 26, 0, 47, 47, 39, 39, 25, 25, 36, 36, 29, 29, 47, 47, 0, 47, 47, 36, 36, 32, 32, 44, 44, 30, 30, 41, 41, 0, 36, 36, 36, 36, 41, 41, 34, 34, 36, 36, 39, 39, 30, 30, 41, 41]\n",
            "[53, 34, 31, 32, 0, 41, 43, 31, 54, 33, 0, 31, 54, 37, 41, 58, 51, 0, 54, 54, 51, 60, 54, 43, 58, 51]\n",
            "\n",
            "\n",
            "9940 9940\n",
            "========================================================================================================================================================================================================\n",
            "‫ כתאב _סאלה_ _לחרופ ללפילסופ  |  كتاب رسالة الحروف للفيلسوف\n",
            "‫ אבי נצר אלפאר_בי בס_  |  أبي نصر الفارابيّ بسم\n",
            "‫ אללה אלרחמנ אלרחימ ובה  |  الله الرحمن الرحيم وبه\n",
            "‫ נסת_ינ אלחמד ללה רב  |  نستعين الحمد لله ربّ\n",
            "‫ א_עאלמי_ וא_סלאמ עלי  |  العالمين والسلام على\n",
            "========================================================================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR2BCYUxIVv4",
        "colab_type": "text"
      },
      "source": [
        "#MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwLpB4zfAY7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "4d52046f-ecf6-40d6-f979-84f7d0cce75b"
      },
      "source": [
        "CELL_NAME=\"BUILD MODEL\"\n",
        "\n",
        "#BASED ON THE MODEL FROM https://www.tensorflow.org/tutorials/sequences/text_generation\n",
        "\n",
        "\n",
        "if tf.test.is_gpu_available():\n",
        "  rnn=tf.compat.v1.keras.layers.CuDNNGRU\n",
        "else:\n",
        "  import functools\n",
        "  rnn = functools.partial(\n",
        "    tf.keras.layers.GRU, recurrent_activation='sigmoid')\n",
        "  \n",
        "def build_model(vocab_size_heb1,vocab_size_ar, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size_heb1, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.Bidirectional(rnn(rnn_units,\n",
        "        return_sequences=True,\n",
        "        recurrent_initializer='glorot_uniform',\n",
        "        stateful=STATEFUL)),\n",
        "   tf.keras.layers.Bidirectional(rnn(rnn_units, \n",
        "        return_sequences=True,\n",
        "        recurrent_initializer='glorot_uniform',\n",
        "        stateful=STATEFUL)),\n",
        "   tf.keras.layers.Bidirectional(rnn(rnn_units,\n",
        "        return_sequences=True,\n",
        "        recurrent_initializer='glorot_uniform',\n",
        "        stateful=STATEFUL)),\n",
        "    tf.keras.layers.Bidirectional(rnn(rnn_units,\n",
        "        return_sequences=True,\n",
        "        recurrent_initializer='glorot_uniform',\n",
        "        stateful=STATEFUL)),\n",
        "    tf.keras.layers.Dense(vocab_size_ar\n",
        "                         )\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-34-fe0c13a5ddfd>:6: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAfj8zQGhKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"BUILD MODEL1\"\n",
        "def rebuild():\n",
        "  #BUILD MODEL\n",
        "  model = build_model(\n",
        "    vocab_size_ar = len(targ_lang.char2idx),\n",
        "    vocab_size_heb1 = len(inp_lang.char2idx),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    )\n",
        "\n",
        "  model.summary()\n",
        "  return model\n",
        "#model=rebuild()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mdbbN5XLlGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "4a38d52a-1882-4f8a-88f2-f551721cd0a1"
      },
      "source": [
        "model=rebuild()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 8)            384       \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (128, None, 2048)         6352896   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (128, None, 2048)         18886656  \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (128, None, 2048)         18886656  \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (128, None, 2048)         18886656  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 67)           137283    \n",
            "=================================================================\n",
            "Total params: 63,150,531\n",
            "Trainable params: 63,150,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRAxxqXvBekE",
        "colab_type": "text"
      },
      "source": [
        "##CHECKPOINTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAGaUtdVBcj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"DEFINE CHECKPOINT\"\n",
        "\n",
        "checkpoint_path='/gdrive/My Drive/checkpoints/'+this_time+\"/ckpt\"\n",
        "def save_checkpoint(massage,ckp_path=checkpoint_path):\n",
        "  print_log_screen(\"saving checkpoing at \"+checkpoint_path)\n",
        "  model.save_weights(checkpoint_path)\n",
        "  f_check= open(checkpoint_path+\".txt\",\"a+\")  \n",
        "  f_check.write(\"saving chekcpoing at epoch\"+ str(GLOBAL_epoch) +'\\n')\n",
        "  f_check.write(massage+'\\n')\n",
        "  f_check.close()\n",
        "  \n",
        "def load_checkpoint(checkpoint_path=checkpoint_path):\n",
        "  print_log_screen(\"loading checkpoing from \"+checkpoint_path)\n",
        "  model1=rebuild()\n",
        "  model1.load_weights(checkpoint_path)\n",
        "  return model1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK87dh5brMUG",
        "colab_type": "text"
      },
      "source": [
        "#TESTING FUNCTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13p5-wog3JMo",
        "colab_type": "text"
      },
      "source": [
        "## forward run single letters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwSqhhfqy6Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"TEST single letters\"\n",
        "def test_single_letters(): \n",
        "  total_accuracy=0\n",
        "  total_examples=0\n",
        "\n",
        "  all_heb_letters=inp_lang.vocab\n",
        "  \n",
        "  num_of_letters=len(inp_lang.vocab)\n",
        "  num_of_arab_letters=len(targ_lang.vocab)\n",
        "\n",
        "#  print_log(num_of_letters)\n",
        "  letters_as_int=[]\n",
        "  tag=inp_lang.char2idx[\"'\"]\n",
        "  for t in range(num_of_letters):\n",
        "    letters_as_int.append([t]*2)\n",
        "  for t in range(BATCH_SIZE-num_of_letters):\n",
        "    letters_as_int.append([0,0])    \n",
        "\n",
        "  letters_tensor=tf.convert_to_tensor(letters_as_int)\n",
        "  \n",
        "  predict_ltrs=model(letters_tensor)\n",
        "  \n",
        "  \n",
        "  for jj in range(num_of_letters):\n",
        "      print(\"candidate:***({0})***\".format(inp_lang.vocab[jj]))\n",
        "      \n",
        "      pred_distr=predict_ltrs[jj][1]\n",
        "      pred_distr=tf.nn.softmax(pred_distr)\n",
        "      for ii in range(num_of_arab_letters):\n",
        "       print(\"{0:.3f}({1})  \".format(pred_distr[ii],targ_lang.vocab[ii]),end = '')\n",
        "      print(\"{0:.3f} <blank>\".format(pred_distr[num_of_arab_letters]))\n",
        "      maximum=tf.argmax(pred_distr).numpy()\n",
        "      max_score=tf.math.reduce_max(pred_distr).numpy()\n",
        "      if (maximum<num_of_arab_letters):\n",
        "        print(\"prediction***({0})***{1:.3f}\".format(targ_lang.vocab[maximum],max_score))\n",
        "      else:\n",
        "        print(\"####max is the blank symbole\")\n",
        "      print_log('-'*10)\n",
        "  \n",
        "#test_single_letters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B8G14-fL8Ez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba147903-9f6a-47b2-e04e-52ffe910cab1"
      },
      "source": [
        "test_single_letters()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "candidate:***( )***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(8)***0.015\n",
            "----------\n",
            "candidate:***(!)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ذ)***0.015\n",
            "----------\n",
            "candidate:***(\")***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(9)***0.015\n",
            "----------\n",
            "candidate:***(')***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ت)***0.015\n",
            "----------\n",
            "candidate:***(()***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ئ)***0.015\n",
            "----------\n",
            "candidate:***())***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(6)***0.015\n",
            "----------\n",
            "candidate:***(,)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(!)***0.015\n",
            "----------\n",
            "candidate:***(-)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(?)***0.015\n",
            "----------\n",
            "candidate:***(.)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(س)***0.015\n",
            "----------\n",
            "candidate:***(0)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(م)***0.015\n",
            "----------\n",
            "candidate:***(1)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(إ)***0.015\n",
            "----------\n",
            "candidate:***(2)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ٌ)***0.015\n",
            "----------\n",
            "candidate:***(3)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(!)***0.015\n",
            "----------\n",
            "candidate:***(4)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(6)***0.015\n",
            "----------\n",
            "candidate:***(5)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(م)***0.015\n",
            "----------\n",
            "candidate:***(6)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ف)***0.015\n",
            "----------\n",
            "candidate:***(7)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(م)***0.015\n",
            "----------\n",
            "candidate:***(8)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(!)***0.015\n",
            "----------\n",
            "candidate:***(9)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ّ)***0.015\n",
            "----------\n",
            "candidate:***(:)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(إ)***0.015\n",
            "----------\n",
            "candidate:***(;)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ع)***0.015\n",
            "----------\n",
            "candidate:***(?)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ذ)***0.015\n",
            "----------\n",
            "candidate:***(H)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(')***0.015\n",
            "----------\n",
            "candidate:***([)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ٌ)***0.015\n",
            "----------\n",
            "candidate:***(])***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ٌ)***0.015\n",
            "----------\n",
            "candidate:***(א)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(م)***0.015\n",
            "----------\n",
            "candidate:***(ב)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(')***0.015\n",
            "----------\n",
            "candidate:***(ג)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ة)***0.015\n",
            "----------\n",
            "candidate:***(ד)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(م)***0.015\n",
            "----------\n",
            "candidate:***(ה)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ج)***0.015\n",
            "----------\n",
            "candidate:***(ו)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(!)***0.015\n",
            "----------\n",
            "candidate:***(ז)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ة)***0.015\n",
            "----------\n",
            "candidate:***(ח)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "####max is the blank symbole\n",
            "----------\n",
            "candidate:***(ט)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ئ)***0.015\n",
            "----------\n",
            "candidate:***(י)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(6)***0.015\n",
            "----------\n",
            "candidate:***(כ)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(?)***0.015\n",
            "----------\n",
            "candidate:***(ל)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ذ)***0.015\n",
            "----------\n",
            "candidate:***(מ)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ة)***0.015\n",
            "----------\n",
            "candidate:***(נ)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ل)***0.015\n",
            "----------\n",
            "candidate:***(ס)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(,)***0.015\n",
            "----------\n",
            "candidate:***(ע)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ة)***0.015\n",
            "----------\n",
            "candidate:***(פ)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(د)***0.015\n",
            "----------\n",
            "candidate:***(צ)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ف)***0.015\n",
            "----------\n",
            "candidate:***(ק)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(م)***0.015\n",
            "----------\n",
            "candidate:***(ר)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ء)***0.015\n",
            "----------\n",
            "candidate:***(ש)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(ت)***0.015\n",
            "----------\n",
            "candidate:***(ת)***\n",
            "0.015( )  0.015(!)  0.015(\")  0.015(')  0.015(()  0.015())  0.015(,)  0.015(-)  0.015(.)  0.015(0)  0.015(1)  0.015(2)  0.015(3)  0.015(4)  0.015(5)  0.015(6)  0.015(7)  0.015(8)  0.015(9)  0.015(:)  0.015(;)  0.015(?)  0.015(H)  0.015([)  0.015(])  0.015(ء)  0.015(آ)  0.015(أ)  0.015(ؤ)  0.015(إ)  0.015(ئ)  0.015(ا)  0.015(ب)  0.015(ة)  0.015(ت)  0.015(ث)  0.015(ج)  0.015(ح)  0.015(خ)  0.015(د)  0.015(ذ)  0.015(ر)  0.015(ز)  0.015(س)  0.015(ش)  0.015(ص)  0.015(ض)  0.015(ط)  0.015(ظ)  0.015(ع)  0.015(غ)  0.015(ف)  0.015(ق)  0.015(ك)  0.015(ل)  0.015(م)  0.015(ن)  0.015(ه)  0.015(و)  0.015(ى)  0.015(ي)  0.015(ً)  0.015(ٌ)  0.015(ٍ)  0.015(ّ)  0.015(ٱ)  0.015 <blank>\n",
            "prediction***(,)***0.015\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9vM09mq0ZSF",
        "colab_type": "text"
      },
      "source": [
        "##forward run text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM2_GVYmOwdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "5e61ad39-97a3-4453-d126-3bcf8a353792"
      },
      "source": [
        "CELL_NAME=\"DEF test__CTC_word_multiline\"\n",
        "\n",
        "#TODO edit code when time permits\n",
        "\n",
        "def forward_text(lines,num_of_paths=5,_BATCH_SIZE=BATCH_SIZE,print_deteils=False): \n",
        "  num_of_lines=len(lines)\n",
        "  assert(num_of_lines<=BATCH_SIZE)\n",
        "\n",
        "  inputs=[]\n",
        "  inputs_len=[]\n",
        "  for l in lines:\n",
        "    l = preprocess_JA(l)\n",
        "    l = double_hebrew(l)\n",
        "    v= encode_JA(l)\n",
        "    inputs.append(v)\n",
        "    inputs_len.append(len(v))\n",
        "\n",
        "  #PADD HORIZANTALY REST OF LINES TO FILL BATCH\n",
        "  for i in range(BATCH_SIZE-num_of_lines):\n",
        "    inputs.append([0])\n",
        "    inputs_len.append(1)\n",
        "\n",
        "  res=[]\n",
        "\n",
        "  #PADDDDDD\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, \n",
        "                                                         maxlen=max_length(inputs),\n",
        "                                                         padding='post',\n",
        "                                                         value=inp_lang.char2idx[BLANK])\n",
        "    \n",
        "  inputs=tf.convert_to_tensor(inputs)\n",
        "    \n",
        "  predict_ltrs=model(inputs)\n",
        "  \n",
        "  inputs=tf.transpose(predict_ltrs,perm=[1,0,2]) #[max_time, batch_size, num_classes]\n",
        "  \n",
        "  decoded, log_probabilities=tf.nn.ctc_beam_search_decoder(\n",
        "                      inputs,\n",
        "                      inputs_len,top_paths=num_of_paths) \n",
        "\n",
        "  total_res=\"\"\n",
        "  for t in range(num_of_lines):\n",
        "    print_log(lines[t])\n",
        "    for i in reversed(range(num_of_paths)):\n",
        "      dense=tf.sparse.to_dense(decoded[i])   \n",
        "      prediction=decode_arr(dense[t])\n",
        "      print_log(\"#####PREDICTION\"+str(i)+\": \",prediction)\n",
        "    total_res+='\\n'+prediction\n",
        "  return total_res\n",
        "  \n",
        "#IMPORTED OBSERV: it seems that ctc decodes make much more than just argmax over sequences see https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7\n",
        "###  ا-ل-ط-ب-ي-ع-ي-ة  و-ك-ا-ل-اا   -م---ع-ع-ا-ا   ---> الطبيعية كمالاً مستعدّاً\n",
        "\n",
        "\n",
        "lines='''כמאלא\n",
        "כמאלא'''\n",
        "\n",
        "print_log_screen(forward_text(lines.split('\\n'),3,BATCH_SIZE))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "כמאלא\n",
            "#####PREDICTION2:  حطحتش\n",
            "#####PREDICTION1:  طحطحش\n",
            "#####PREDICTION0:  طحتحش\n",
            "כמאלא\n",
            "#####PREDICTION2:  حطحتش\n",
            "#####PREDICTION1:  طحطحش\n",
            "#####PREDICTION0:  طحتحش\n",
            "\n",
            "طحتحش\n",
            "طحتحش\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K6i5QWGO4DS",
        "colab_type": "text"
      },
      "source": [
        "##TEST KFIR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsqzEV2rtpgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c31d79e5-88d1-41b2-b2cd-a4a526911b95"
      },
      "source": [
        "CELL_NAME=\"DEF TEST KFIR\"\n",
        "\n",
        "#TODO edit code when time permits\n",
        "\n",
        "def test_text_kfir(JA_lines,arr_lines,indexes=None,num_of_paths=1,_BATCH_SIZE=BATCH_SIZE,SHOW_PRINT=False): \n",
        "  # JA_lines=word_str.split('\\n')\n",
        "  # arr_lines=targ_str.split('\\n')\n",
        "  num_of_lines=len(JA_lines)\n",
        "  num_of_letters= 0\n",
        "  assert(num_of_lines==len(arr_lines))\n",
        "  assert(num_of_lines<=BATCH_SIZE)\n",
        "\n",
        "  inputs=[]\n",
        "  inputs_len=[]\n",
        "  for l in JA_lines:\n",
        "    l = preprocess_JA(l)\n",
        "    #l = double_hebrew(l)\n",
        "    v=encode_JA(l)\n",
        "    inputs.append(v)\n",
        "    inputs_len.append(len(v))\n",
        "  #max_len=max_len(inputs)\n",
        "  #PADD HORIZANTALY\n",
        "  for i in range(BATCH_SIZE-num_of_lines):\n",
        "    inputs.append([0])\n",
        "    inputs_len.append(1)\n",
        "\n",
        "\n",
        "\n",
        "  res=[]\n",
        "  #PADDDDDD\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, \n",
        "                                                         maxlen=max_length(inputs),\n",
        "                                                         padding='post',\n",
        "                                                         value=inp_lang.char2idx[BLANK])\n",
        "    \n",
        "  inputs=tf.convert_to_tensor(inputs)\n",
        "  predict_ltrs=model(inputs)\n",
        "\n",
        "  inputs=tf.transpose(predict_ltrs,perm=[1,0,2]) #[max_time, batch_size, num_classes]\n",
        "  \n",
        "  decoded, log_probabilities=tf.nn.ctc_beam_search_decoder(\n",
        "                      inputs,\n",
        "                      inputs_len,top_paths=num_of_paths) \n",
        "  \n",
        "  total_res=[]\n",
        "  total_edit_dist=0\n",
        "  total_normalized_edit_dist=0\n",
        "  line_counter=1\n",
        "  for t in range(num_of_lines):\n",
        "    real=arr_lines[t]\n",
        "    for i in reversed(range(num_of_paths)):\n",
        "      dense=tf.sparse.to_dense(decoded[i])   \n",
        "      prediction=decode_arr(dense[t]).strip() \n",
        "      # print_log(\"#####PREDICTION\"+str(i)+\": \",prediction)\n",
        "      total_res.append(prediction)\n",
        "    if indexes:\n",
        "      real=real.split()[indexes[t]]            \n",
        "      prediction=prediction.split()[indexes[t]]\n",
        "    ed_dist=editdistance.eval(real, prediction)\n",
        "    #print(real, len(real))\n",
        "    num_of_letters+=len(real)\n",
        "\n",
        "    normalized_ed_dist=ed_dist/len(real)\n",
        "    real,prediction=show_diff(real,prediction,'red')\n",
        "    if SHOW_PRINT:\n",
        "      print_log_screen(\"({0})\".format(line_counter),LTRchar,undouble_hebrew(JA_lines[t]),\"|\",real,\"|\",prediction,\"|\",\"{0:.4f}\".format(ed_dist))\n",
        "    line_counter+=1\n",
        "    total_normalized_edit_dist+=normalized_ed_dist\n",
        "    total_edit_dist+=ed_dist\n",
        "  return total_res,total_normalized_edit_dist,num_of_lines,total_edit_dist,num_of_letters\n",
        "  \n",
        "#IMPORTED OBSERV: it seems that ctc decodes make much more than just argmax over sequences see https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7\n",
        "###  ا-ل-ط-ب-ي-ع-ي-ة  و-ك-ا-ل-اا   -م---ع-ع-ا-ا   ---> الطبيعية كمالاً مستعدّاً\n",
        "\n",
        "\n",
        "JA_lines='''יכ'אלף\n",
        "עלי\n",
        "הד'ה\n",
        "אלאמאנה\n",
        "ולא'''\n",
        "\n",
        "JA_lines='''ייככ''אאללףף\n",
        "עעלליי\n",
        "ההדד''הה\n",
        "אאללאאממאאננהה\n",
        "ווללאא'''\n",
        "\n",
        "JA_lines='''ייככ''אאללףף\n",
        "אאללאאממאאננהה ששללווםם'''\n",
        "\n",
        "# arr_lines='''يخالف\n",
        "# على\n",
        "# هذه\n",
        "# الأمانة\n",
        "# ولا'''\n",
        "\n",
        "arr_lines='''يخالف\n",
        "الأمانة الأمانة'''\n",
        "\n",
        "#indexes=[0,1]\n",
        "indexes=None\n",
        "\n",
        "\n",
        "test_text_kfir(JA_lines.split('\\n'),arr_lines.split('\\n'),indexes,SHOW_PRINT=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1) ‫ יכ'אלף | \u001b[1m\u001b[31mيخالف\u001b[0m | \u001b[1m\u001b[31mطحطحتح\u001b[0m | 6.0000\n",
            "(2) ‫ אלאמאנה שלום | \u001b[1m\u001b[31mالأمانة الأمانة\u001b[0m | \u001b[1m\u001b[31mطحطحتحتحتحتش\u001b[0m | 15.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['طحطحتح', 'طحطحتحتحتحتش'], 2.2, 2, 21, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA5e5-59jCxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b4945b8-9c59-4518-fe3e-0fc70a10dda6"
      },
      "source": [
        "CELL_NAME=\"DEF test_kfir1\"\n",
        "\n",
        "#data_path options:\n",
        "# kfir_kuzari_test\n",
        "# kfir_rasag_test\n",
        "\n",
        "#replace_GAIN - replace JAIN with GIMEL\n",
        "\n",
        "\n",
        "def test_kfir(data_path,replace_GAIN=False,SHOW_PRINT=False,index_path=None):\n",
        "\n",
        "  lines=load_lines(data_path)\n",
        "  pairs = create_parralel_phrases(lines)\n",
        "  if index_path:\n",
        "    indexes=[]\n",
        "    f_indexes=open(index_path,'r')\n",
        "    ind_lines=f_indexes.readlines()\n",
        "    assert(len(ind_lines)==len(lines))\n",
        "    for il in ind_lines:\n",
        "      indexes.append(int(il))\n",
        "    f_indexes.close()\n",
        "   # print(indexes)\n",
        "  if replace_GAIN:\n",
        "    hebrew_lines=[heb.replace(\"גג\",\"גג''\").replace(\"גג''''\",\"גג\") for heb, arr in pairs]\n",
        "  else:\n",
        "    hebrew_lines=[heb for heb, arr in pairs]\n",
        "  arab_lines=[arr for heb, arr in pairs]\n",
        "\n",
        "  num_of_lines=len(pairs)\n",
        "  index=0\n",
        "  total_num_of_examples=0\n",
        "  total_num_of_letters=0\n",
        "  total_sum_e_d_normalized=0\n",
        "  total_sum_e_d=0\n",
        "  while index<=num_of_lines:\n",
        "    batch_hebrew=hebrew_lines[index:index+BATCH_SIZE]\n",
        "    batch_arab=arab_lines[index:index+BATCH_SIZE]\n",
        "    if index_path:\n",
        "      batch_indexes=indexes[index:index+BATCH_SIZE]\n",
        "    else:\n",
        "      batch_indexes=None\n",
        "    _,sum_of_e_d_normalized,num_of_examples,sum_of_e_d,num_of_letters=test_text_kfir(batch_hebrew,batch_arab,batch_indexes,SHOW_PRINT=SHOW_PRINT)\n",
        "    if SHOW_PRINT:\n",
        "      print_log_screen(\"BATCH (sum_of_e_d_normalized,num_of_examples): \",sum_of_e_d_normalized,num_of_examples)\n",
        "      print_log_screen(\"BATCH (sum_of_e_d,num_of_letters): \",sum_of_e_d,num_of_letters)\n",
        "    total_num_of_examples+=num_of_examples\n",
        "    total_num_of_letters+=num_of_letters\n",
        "    total_sum_e_d+=sum_of_e_d\n",
        "    total_sum_e_d_normalized+=sum_of_e_d_normalized\n",
        "    index+=BATCH_SIZE\n",
        "\n",
        "  print_log_screen(\"#examples:\",total_num_of_examples,\", accuracy:\",1-total_sum_e_d_normalized/total_num_of_examples)\n",
        "  print_log_screen(\"#letters:\",total_num_of_letters,\", accuracy1:\",1-total_sum_e_d/total_num_of_letters)\n",
        "  return total_sum_e_d_normalized/total_num_of_examples,total_sum_e_d/total_num_of_letters\n",
        "\n",
        "# test_kfir(kfir_kuzari_test,SHOW_PRINT=True)\n",
        "\n",
        "test_kfir(kfir_rasag_test,SHOW_PRINT=True)\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading text: /gdrive/My Drive/thesis-data/kfir1/kfir_rasag_test.txt\n",
            "first lines: ['דאר\\tدار', 'אלגזא\\tالجزاء', 'וקבל\\tوقبل', \"ד'לך\\tذلك\", 'מא\\tما', 'ראי\\tرأى', 'אן\\tأن', 'יפרק\\tيفرّق', 'בין\\tبين', 'רוחה\\tروحه', 'וגסמה\\tوجسمه', 'אלי\\tإلى', 'וקת\\tوقت', 'אסתכמאל\\tاستكمال', 'אלנפוס\\tالنفوس', 'חתי\\tحتى', 'יגמעהא\\tيجمعها', 'אלגמיע\\tالجميع', 'עלי\\tعلى', 'מא\\tما', 'בינת\\tبيّنت', 'פלא\\tفلا', 'נעלם\\tنعلم', 'יהודיא\\tيهوديّاً', \"יכ'אלף\\tيخالف\", 'עלי\\tعلى', \"הד'ה\\tهذه\", 'אלאמאנה\\tالأمانة', 'ולא\\tولا', 'יסתצעב\\tيستصعب', 'ענד\\tعند', 'עקלה\\tعقله', 'כיף\\tكيف', 'יחיי\\tيحيي', 'רבה\\tربّه', 'אלמותי\\tالموتى', \"אד'\\tإذ\", 'קד\\tقد', 'צח\\tصحّ', 'לה\\tله', 'אנה\\tأنه', \"כ'לק\\tخلق\", 'שיא\\tشيئاً', 'לא\\tلا', 'מן\\tمن', 'שי\\tشيء', 'פלא\\tفلا', 'יגוז\\tيجوز', 'אן\\tأن', 'יסתעסר\\tيستعسر']\n",
            "len(lines) 50\n",
            "(1) ‫ דאר | \u001b[1m\u001b[31mدار\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(2) ‫ אלגזא | \u001b[1m\u001b[31mالجزاء\u001b[0m | \u001b[1m\u001b[31mطحطحت\u001b[0m | 6.0000\n",
            "(3) ‫ וקבל | \u001b[1m\u001b[31mوقبل\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(4) ‫ ד'לך | \u001b[1m\u001b[31mذلك\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(5) ‫ מא | \u001b[1m\u001b[31mما\u001b[0m | \u001b[1m\u001b[31mطح\u001b[0m | 2.0000\n",
            "(6) ‫ ראי | \u001b[1m\u001b[31mرأى\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(7) ‫ אן | \u001b[1m\u001b[31mأن\u001b[0m | \u001b[1m\u001b[31mطح\u001b[0m | 2.0000\n",
            "(8) ‫ יפרק | \u001b[1m\u001b[31mيفرّق\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 5.0000\n",
            "(9) ‫ בין | \u001b[1m\u001b[31mبين\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(10) ‫ רוחה | \u001b[1m\u001b[31mرو\u001b[0mح\u001b[1m\u001b[31mه\u001b[0m | \u001b[1m\u001b[31mط\u001b[0mح\u001b[1m\u001b[31mطح\u001b[0m | 4.0000\n",
            "(11) ‫ וגסמה | \u001b[1m\u001b[31mوجسمه\u001b[0m | \u001b[1m\u001b[31mطحطحت\u001b[0m | 5.0000\n",
            "(12) ‫ אלי | \u001b[1m\u001b[31mإلى\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(13) ‫ וקת | \u001b[1m\u001b[31mوقت\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(14) ‫ אסתכמאל | \u001b[1m\u001b[31mاس\u001b[0mت\u001b[1m\u001b[31mكمال\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0mت\u001b[1m\u001b[31mحش\u001b[0m | 7.0000\n",
            "(15) ‫ אלנפוס | \u001b[1m\u001b[31mالنفوس\u001b[0m | \u001b[1m\u001b[31mطحطحتح\u001b[0m | 6.0000\n",
            "(16) ‫ חתי | ح\u001b[1m\u001b[31mتى\u001b[0m | ح\u001b[1m\u001b[31mطح\u001b[0m | 2.0000\n",
            "(17) ‫ יגמעהא | \u001b[1m\u001b[31mيجمعها\u001b[0m | \u001b[1m\u001b[31mطحطحتح\u001b[0m | 6.0000\n",
            "(18) ‫ אלגמיע | \u001b[1m\u001b[31mالجميع\u001b[0m | \u001b[1m\u001b[31mطحطحتح\u001b[0m | 6.0000\n",
            "(19) ‫ עלי | \u001b[1m\u001b[31mعلى\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(20) ‫ מא | \u001b[1m\u001b[31mما\u001b[0m | \u001b[1m\u001b[31mطح\u001b[0m | 2.0000\n",
            "(21) ‫ בינת | \u001b[1m\u001b[31mبيّنت\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 5.0000\n",
            "(22) ‫ פלא | \u001b[1m\u001b[31mفلا\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(23) ‫ נעלם | \u001b[1m\u001b[31mنعلم\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(24) ‫ יהודיא | \u001b[1m\u001b[31mيهوديّاً\u001b[0m | \u001b[1m\u001b[31mطحطحتح\u001b[0m | 8.0000\n",
            "(25) ‫ יכ'אלף | \u001b[1m\u001b[31mيخالف\u001b[0m | \u001b[1m\u001b[31mطحطحتح\u001b[0m | 6.0000\n",
            "(26) ‫ עלי | \u001b[1m\u001b[31mعلى\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(27) ‫ הד'ה | \u001b[1m\u001b[31mهذه\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(28) ‫ אלאמאנה | \u001b[1m\u001b[31mالأمانة\u001b[0m | \u001b[1m\u001b[31mطحطحتحش\u001b[0m | 7.0000\n",
            "(29) ‫ ולא | \u001b[1m\u001b[31mولا\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(30) ‫ יסתצעב | \u001b[1m\u001b[31mيس\u001b[0mت\u001b[1m\u001b[31mصعب\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0mت\u001b[1m\u001b[31mح\u001b[0m | 6.0000\n",
            "(31) ‫ ענד | \u001b[1m\u001b[31mعند\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(32) ‫ עקלה | \u001b[1m\u001b[31mعقله\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(33) ‫ כיף | \u001b[1m\u001b[31mكيف\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(34) ‫ יחיי | \u001b[1m\u001b[31mي\u001b[0mح\u001b[1m\u001b[31mيي\u001b[0m | \u001b[1m\u001b[31mط\u001b[0mح\u001b[1m\u001b[31mطح\u001b[0m | 3.0000\n",
            "(35) ‫ רבה | \u001b[1m\u001b[31mربّه\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(36) ‫ אלמותי | \u001b[1m\u001b[31mالمو\u001b[0mت\u001b[1m\u001b[31mى\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0mت\u001b[1m\u001b[31mح\u001b[0m | 5.0000\n",
            "(37) ‫ אד' | \u001b[1m\u001b[31mإذ\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(38) ‫ קד | \u001b[1m\u001b[31mقد\u001b[0m | \u001b[1m\u001b[31mطح\u001b[0m | 2.0000\n",
            "(39) ‫ צח | \u001b[1m\u001b[31mص\u001b[0mح\u001b[1m\u001b[31mّ\u001b[0m | \u001b[1m\u001b[31mط\u001b[0mح | 2.0000\n",
            "(40) ‫ לה | \u001b[1m\u001b[31mله\u001b[0m | \u001b[1m\u001b[31mطح\u001b[0m | 2.0000\n",
            "(41) ‫ אנה | \u001b[1m\u001b[31mأنه\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(42) ‫ כ'לק | \u001b[1m\u001b[31mخلق\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(43) ‫ שיא | \u001b[1m\u001b[31mشيئاً\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 5.0000\n",
            "(44) ‫ לא | \u001b[1m\u001b[31mلا\u001b[0m | \u001b[1m\u001b[31mطح\u001b[0m | 2.0000\n",
            "(45) ‫ מן | \u001b[1m\u001b[31mمن\u001b[0m | \u001b[1m\u001b[31mطح\u001b[0m | 2.0000\n",
            "(46) ‫ שי | \u001b[1m\u001b[31mشيء\u001b[0m | \u001b[1m\u001b[31mطح\u001b[0m | 3.0000\n",
            "(47) ‫ פלא | \u001b[1m\u001b[31mفلا\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(48) ‫ יגוז | \u001b[1m\u001b[31mيجوز\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0m | 4.0000\n",
            "(49) ‫ אן | \u001b[1m\u001b[31mأن\u001b[0m | \u001b[1m\u001b[31mطح\u001b[0m | 2.0000\n",
            "(50) ‫ יסתעסר | \u001b[1m\u001b[31mيس\u001b[0mت\u001b[1m\u001b[31mعسر\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0mت\u001b[1m\u001b[31mح\u001b[0m | 6.0000\n",
            "BATCH (sum_of_e_d_normalized,num_of_examples):  55.45000000000001 50\n",
            "BATCH (sum_of_e_d,num_of_letters):  207 192\n",
            "#examples: 50 , accuracy: -0.10900000000000021\n",
            "#letters: 192 , accuracy1: -0.078125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.1090000000000002, 1.078125)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qhhb8OaD1QT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "8150cd10-4f92-4ab4-8842-84e65392b0b8"
      },
      "source": [
        "CELL_NAME=\"FOR NACHUM - CONTEXT ON KFIR\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#adjust test kfir to comp edits only for index word!\n",
        "DO_EMUNOT=True\n",
        "\n",
        "if DO_EMUNOT:\n",
        "  file_all = open(haemunot, \"r\")\n",
        "  file = open(kfir_rasag_test, \"r\")\n",
        "else:\n",
        "  file_all = open(hakuzari, \"r\")\n",
        "  file = open(kfir_kuzari_test, \"r\")\n",
        "\n",
        "arabic_lines=[]\n",
        "for l in file_all:\n",
        "  arabic_lines.append(remove_arab_nikud(standard_nunization(normalize_unicode(l))))\n",
        "\n",
        "greped=[]\n",
        "for l in file:\n",
        "  greped.append(remove_arab_nikud(standard_nunization(normalize_unicode(l))))\n",
        "\n",
        "\n",
        "def grep(reg,ja,full_f,single_f,index_f):\n",
        "  #file_all = open(haemunot, \"r\")\n",
        "  for line in arabic_lines:\n",
        "      line=remove_arab_nikud(line)     \n",
        "      JA_line,arab_line=line.split('\\t')\n",
        "      if re.search(reg, arab_line):          \n",
        "          arab_words=arab_line.split()\n",
        "          JA_words=JA_line.split()\n",
        "          reg_ind=arab_words.index(reg.strip(\" $^\"))\n",
        "          if (not JA_words[reg_ind]==ja):\n",
        "            #TODO search for other option in text....\n",
        "             print(\"ja:\"+ja+ \"JA_words[reg_ind]:\" +JA_words[reg_ind])\n",
        "             print(\"JA_WORDS[reg_ind] (my version) will be outputed to both tests (with and without context)\")\n",
        "          assert(len(JA_words)==len(arab_words)) #MAYBE NOT ALWAYS THE CASE!!!          \n",
        "          arab_text=[]\n",
        "          JA_text=[]\n",
        "          for i in range(len(arab_words)):\n",
        "            if i==reg_ind:\n",
        "              arab_text.append(colored(arab_words[i],'red'))\n",
        "              JA_text.append(colored(JA_words[i],'red'))\n",
        "            else:\n",
        "              arab_text.append(arab_words[i]) \n",
        "              JA_text.append(JA_words[i])\n",
        "          full_line=\" \".join(JA_text)+'\\t'+\" \".join(arab_text)+'\\t'+str(reg_ind)\n",
        "          full_f.write(\" \".join(JA_words)+'\\t'+\" \".join(arab_words)+'\\n')\n",
        "          index_f.write(str(reg_ind)+'\\n')\n",
        "          single_words=JA_words[reg_ind]+'\\t'+arab_words[reg_ind]\n",
        "          single_f.write(single_words+'\\n')\n",
        "          return full_line\n",
        "  return\n",
        "          \n",
        "\n",
        "not_found_counter=0\n",
        "\n",
        "f1=open(\"with_context.txt\",'w+')\n",
        "f2=open(\"no_context.txt\",'w+')\n",
        "f3=open(\"context_idexes.txt\",'w+')\n",
        "\n",
        "for l in greped:  \n",
        "  arab=l.split('\\t')[1].strip()\n",
        "  ja=l.split('\\t')[0].strip()\n",
        " # print(ja)\n",
        "  if DO_EMUNOT:\n",
        "    ja=ja.replace(\"ג\",\"ג'\").replace(\"ג''\",\"ג\")    ##only for kuzari - change to regular (or won't grep)\n",
        " # print(ja)\n",
        "  arab=' '+arab+' ' \n",
        "  found=grep(arab,ja,f1,f2,f3)\n",
        " # print(\"grep: \"+arab)\n",
        "  if not found:\n",
        "    found=grep(\"^\"+arab.lstrip(),ja,f1,f2,f3)\n",
        "    if not found:\n",
        "      found=grep(arab.rstrip()+\"$\",ja,f1,f2,f3)\n",
        "      if not found:\n",
        "        not_found_counter+=1\n",
        "  if not found:\n",
        "    print(\"not found:\"+arab)\n",
        "  else:\n",
        "    print(found)\n",
        "f1.close()\n",
        "f2.close()\n",
        "f3.close()\n",
        "print(\"#not founds:\"+str(not_found_counter))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "פי \u001b[31mדאר\u001b[0m אלדניא . ואבתדי\tفي \u001b[31mدار\u001b[0m الدنيا . وابتدئ\t1\n",
            "נפענא עלי \u001b[31mאלג'זא\u001b[0m אצ'עאף\tنفعنا على \u001b[31mالجزاء\u001b[0m أضعاف\t2\n",
            ". \u001b[31mוקבל\u001b[0m ד'לך מא ראי אן\t. \u001b[31mوقبل\u001b[0m ذلك ما رأى أن\t1\n",
            "מת'ל \u001b[31mד'לך\u001b[0m בקולה : H H\tمثل \u001b[31mذلك\u001b[0m بقوله : H H\t1\n",
            "אמא עלי את'ר \u001b[31mמא\u001b[0m אפתתחנא\tأمّا على إثر \u001b[31mما\u001b[0m افتتحنا\t3\n",
            "ואחד מן \u001b[31mראי\u001b[0m נפסה פי אכ'טארה\tواحد من \u001b[31mرأى\u001b[0m نفسه في إخطاره\t2\n",
            "H H H . וארי \u001b[31mאן\u001b[0m אג'על\tH H H . وأرى \u001b[31mأن\u001b[0m أجعل\t5\n",
            "\u001b[31mיפרק\u001b[0m בין רוחה וג'סמה\t\u001b[31mيفرّق\u001b[0m بين روحه وجسمه\t0\n",
            "אלוקוף \u001b[31mבין\u001b[0m ידיה פלא יערפה\tالوقوف \u001b[31mبين\u001b[0m يديه فلا يعرفه\t1\n",
            "וטארת \u001b[31mרוחה\u001b[0m כמא קאל H\tوطارت \u001b[31mروحه\u001b[0m كما قال H\t1\n",
            "יפרק בין רוחה \u001b[31mוג'סמה\u001b[0m\tيفرّق بين روحه \u001b[31mوجسمه\u001b[0m\t3\n",
            "חתי יתם וצולהם \u001b[31mאלי\u001b[0m אלמטלוב\tحتّى يتمّ وصولهم \u001b[31mإلى\u001b[0m المطلوب\t3\n",
            "אי \u001b[31mוקת\u001b[0m טלעתה כד'אך ואשד\tأي \u001b[31mوقت\u001b[0m طلعته كذاك وأشد\t1\n",
            "אלי וקת \u001b[31mאסתכמאל\u001b[0m אלנפוס\tإلى وقت \u001b[31mاستكمال\u001b[0m النفوس\t2\n",
            "פי \u001b[31mאלנפוס\u001b[0m פמאזג'תהא פצאר\tفي \u001b[31mالنفوس\u001b[0m فمازجتها فصار\t1\n",
            "וכל נאר \u001b[31mחתי\u001b[0m תלחק בתראב\tوكل نار \u001b[31mحتى\u001b[0m تلحق بتراب\t2\n",
            "מן גירכם \u001b[31mיג'מעהא\u001b[0m אלי\tمن غيركم \u001b[31mيجمعها\u001b[0m إلى\t2\n",
            ". ואכת'ר מן \u001b[31mאלג'מיע\u001b[0m מן\t. وأكثر من \u001b[31mالجميع\u001b[0m من\t3\n",
            "אמא \u001b[31mעלי\u001b[0m את'ר מא אפתתחנא\tأمّا \u001b[31mعلى\u001b[0m إثر ما افتتحنا\t1\n",
            "אמא עלי את'ר \u001b[31mמא\u001b[0m אפתתחנא\tأمّا على إثر \u001b[31mما\u001b[0m افتتحنا\t3\n",
            ". פאד' קד \u001b[31mבינת\u001b[0m הד'ה אלמקדמה\t. فإذا قد \u001b[31mبيّنت\u001b[0m هذه المقدمة\t3\n",
            "אלוקוף בין ידיה \u001b[31mפלא\u001b[0m יערפה\tالوقوف بين يديه \u001b[31mفلا\u001b[0m يعرفه\t3\n",
            "אן \u001b[31mנעלם\u001b[0m כיף ננט'ר ת'ם\tأن \u001b[31mنعلم\u001b[0m كيف ننظر ثمّ\t1\n",
            "not found: يهوديّاً \n",
            "\u001b[31mיכ'אלף\u001b[0m חקיקהֿ אלשי ,\t\u001b[31mيخالف\u001b[0m حقيقة لاشيء ,\t0\n",
            "אמא \u001b[31mעלי\u001b[0m את'ר מא אפתתחנא\tأمّا \u001b[31mعلى\u001b[0m إثر ما افتتحنا\t1\n",
            "אן \u001b[31mהד'ה\u001b[0m אלצ'רוב לא יסתפיד\tأنّ \u001b[31mهذه\u001b[0m الضروب لا يستفيد\t1\n",
            "למן כ'אלפנא פי הד'ה \u001b[31mאלאמאנה\u001b[0m\tلمن خالفنا في هذه \u001b[31mالأمانة\u001b[0m\t4\n",
            "אללבוס \u001b[31mולא\u001b[0m כ'איץ' יצעדהם\tالّلبوس \u001b[31mولا\u001b[0m خائضٌ يصعدهم\t1\n",
            "ולא \u001b[31mיסתצעב\u001b[0m ענד עקלה כיף\tولا \u001b[31mيستصعب\u001b[0m عند عقله كيف\t1\n",
            "אנמא הו \u001b[31mענד\u001b[0m עואמהם כמא\tإنّما هو \u001b[31mعند\u001b[0m عوامهم كما\t2\n",
            "לם יקם פי \u001b[31mעקלה\u001b[0m פאן הד'ה\tلم يقم في \u001b[31mعقله\u001b[0m فإنّ هذه\t3\n",
            "פינבגי אן נשרח \u001b[31mכיף\u001b[0m אלאסתדלאל\tفينبغي أن نشرح \u001b[31mكيف\u001b[0m الاستدلال\t3\n",
            "אן \u001b[31mיחיי\u001b[0m בחכמה וימית בחכמה\tأن \u001b[31mيحيي\u001b[0m بحكمة ويميت بحكمة\t1\n",
            "בהד'א ד'נבה עלי \u001b[31mרבה\u001b[0m לכנה\tبهذا ذنبه على \u001b[31mربّه\u001b[0m لكنّه\t3\n",
            "פי אחיה \u001b[31mאלמותי\u001b[0m . אלמקאלה\tفي إحياء \u001b[31mالموتى\u001b[0m . المقالة\t2\n",
            "אלמאל \u001b[31mאד'\u001b[0m קאל : H H H\tالمال \u001b[31mإذ\u001b[0m قال : H H H\t1\n",
            ". ומנהם מן \u001b[31mקד\u001b[0m וצל אלי\t. ومنهم من \u001b[31mقد\u001b[0m وصل إلى\t3\n",
            "כת'ירה פאד'א \u001b[31mצח\u001b[0m אן ד'לך\tكثيرة فإذا \u001b[31mصحّ\u001b[0m أنّ ذلك\t2\n",
            "יתפק \u001b[31mלה\u001b[0m אן יואפיה והו\tيتّفق \u001b[31mله\u001b[0m أن يوافيه وهو\t1\n",
            "לם יצח ענדה \u001b[31mאנה\u001b[0m ופאה\tلم يصحّ عنده \u001b[31mأنه\u001b[0m وفّاه\t3\n",
            "אן אלקול באנה \u001b[31mכ'לק\u001b[0m שיא\tأن القول بأنه \u001b[31mخلق\u001b[0m شيئاً\t3\n",
            "חסנא \u001b[31mשיא\u001b[0m מא ותחקקה ,\tحسّنا \u001b[31mشيئاً\u001b[0m ما وتحقّقه ,\t1\n",
            "קולא קריבא \u001b[31mלא\u001b[0m בעידא מן\tقولاً قريباً \u001b[31mلا\u001b[0m بعيداً من\t2\n",
            "בה \u001b[31mמן\u001b[0m חמד רבנא ואלת'נא\tبه \u001b[31mمن\u001b[0m حمد ربّنا والثناء\t1\n",
            "לכל \u001b[31mשי\u001b[0m מעלום באלחאל אלתי\tلكل \u001b[31mشيء\u001b[0m معلوم بالحال التي\t1\n",
            "אלוקוף בין ידיה \u001b[31mפלא\u001b[0m יערפה\tالوقوف بين يديه \u001b[31mفلا\u001b[0m يعرفه\t3\n",
            "בל לא \u001b[31mיג'וז\u001b[0m אן יכון פעל\tبل لا \u001b[31mيجوز\u001b[0m أن يكون فعل\t2\n",
            "H H H . וארי \u001b[31mאן\u001b[0m אג'על\tH H H . وأرى \u001b[31mأن\u001b[0m أجعل\t5\n",
            "\u001b[31mיסתעסר\u001b[0m לה אן יעיד שיא\t\u001b[31mيستعسر\u001b[0m له أن يعيد شيئاً\t0\n",
            "#not founds:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNrQSIk2f9iG",
        "colab_type": "code",
        "outputId": "80515799-a9c3-4545-fc95-90583ef5e13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "CELL_NAME=\"FOR NACHUM - CONTEXT ON KFIR 1\"\n",
        "\n",
        "\n",
        "PRINT_DETAILED=True\n",
        "\n",
        "\n",
        "\n",
        "#model=load_checkpoint('/gdrive/My Drive/checkpoints/2020-05-04 12:32:58.607342/ckpt')  #THIS IS THE FIRST ACTIVATIION, BY WHICH I PRODUCED THE EXCEL FOR NACHUM\n",
        "\n",
        "#model=load_checkpoint('/gdrive/My Drive/checkpoints/2020-05-05 13:01:42.636420/ckpt')\n",
        "#if STATEFUL:\n",
        "model.reset_states()\n",
        "test_kfir(\"with_context.txt\",replace_GAIN=True,SHOW_PRINT=PRINT_DETAILED,index_path=\"context_idexes.txt\")\n",
        "\n",
        "print(\"=\"*200)\n",
        "#if STATEFUL:\n",
        "model.reset_states()\n",
        "\n",
        "test_kfir(\"no_context.txt\",replace_GAIN=True,SHOW_PRINT=PRINT_DETAILED)\n",
        "\n",
        "# print(\"=\"*200)\n",
        "# model.reset_states()\n",
        "\n",
        "# test_kfir(\"no_context.txt\",True)\n",
        "\n",
        "# print(\"=\"*200)\n",
        "# model.reset_states()\n",
        "\n",
        "# test_kfir(\"no_context.txt\",True)\n",
        "\n",
        "#model.reset_states()\n",
        "#test_kfir(kfir_rasag_test,True)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading text: with_context.txt\n",
            "first lines: ['פי דאר אלדניא . ואבתדי\\tفي دار الدنيا . وابتدئ', \"נפענא עלי אלג'זא אצ'עאף\\tنفعنا على الجزاء أضعاف\", \". וקבל ד'לך מא ראי אן\\t. وقبل ذلك ما رأى أن\", \"מת'ל ד'לך בקולה : H H\\tمثل ذلك بقوله : H H\", \"אמא עלי את'ר מא אפתתחנא\\tأمّا على إثر ما افتتحنا\", \"ואחד מן ראי נפסה פי אכ'טארה\\tواحد من رأى نفسه في إخطاره\", \"H H H . וארי אן אג'על\\tH H H . وأرى أن أجعل\", \"יפרק בין רוחה וג'סמה\\tيفرّق بين روحه وجسمه\", 'אלוקוף בין ידיה פלא יערפה\\tالوقوف بين يديه فلا يعرفه', 'וטארת רוחה כמא קאל H\\tوطارت روحه كما قال H', \"יפרק בין רוחה וג'סמה\\tيفرّق بين روحه وجسمه\", 'חתי יתם וצולהם אלי אלמטלוב\\tحتّى يتمّ وصولهم إلى المطلوب', \"אי וקת טלעתה כד'אך ואשד\\tأي وقت طلعته كذاك وأشد\", 'אלי וקת אסתכמאל אלנפוס\\tإلى وقت استكمال النفوس', \"פי אלנפוס פמאזג'תהא פצאר\\tفي النفوس فمازجتها فصار\", 'וכל נאר חתי תלחק בתראב\\tوكل نار حتى تلحق بتراب', \"מן גירכם יג'מעהא אלי\\tمن غيركم يجمعها إلى\", \". ואכת'ר מן אלג'מיע מן\\t. وأكثر من الجميع من\", \"אמא עלי את'ר מא אפתתחנא\\tأمّا على إثر ما افتتحنا\", \"אמא עלי את'ר מא אפתתחנא\\tأمّا على إثر ما افتتحنا\", \". פאד' קד בינת הד'ה אלמקדמה\\t. فإذا قد بيّنت هذه المقدمة\", 'אלוקוף בין ידיה פלא יערפה\\tالوقوف بين يديه فلا يعرفه', \"אן נעלם כיף ננט'ר ת'ם\\tأن نعلم كيف ننظر ثمّ\", \"יכ'אלף חקיקהֿ אלשי ,\\tيخالف حقيقة لاشيء ,\", \"אמא עלי את'ר מא אפתתחנא\\tأمّا على إثر ما افتتحنا\", \"אן הד'ה אלצ'רוב לא יסתפיד\\tأنّ هذه الضروب لا يستفيد\", \"למן כ'אלפנא פי הד'ה אלאמאנה\\tلمن خالفنا في هذه الأمانة\", \"אללבוס ולא כ'איץ' יצעדהם\\tالّلبوس ولا خائضٌ يصعدهم\", 'ולא יסתצעב ענד עקלה כיף\\tولا يستصعب عند عقله كيف', 'אנמא הו ענד עואמהם כמא\\tإنّما هو عند عوامهم كما', \"לם יקם פי עקלה פאן הד'ה\\tلم يقم في عقله فإنّ هذه\", 'פינבגי אן נשרח כיף אלאסתדלאל\\tفينبغي أن نشرح كيف الاستدلال', 'אן יחיי בחכמה וימית בחכמה\\tأن يحيي بحكمة ويميت بحكمة', \"בהד'א ד'נבה עלי רבה לכנה\\tبهذا ذنبه على ربّه لكنّه\", 'פי אחיה אלמותי . אלמקאלה\\tفي إحياء الموتى . المقالة', \"אלמאל אד' קאל : H H H\\tالمال إذ قال : H H H\", '. ומנהם מן קד וצל אלי\\t. ومنهم من قد وصل إلى', \"כת'ירה פאד'א צח אן ד'לך\\tكثيرة فإذا صحّ أنّ ذلك\", 'יתפק לה אן יואפיה והו\\tيتّفق له أن يوافيه وهو', 'לם יצח ענדה אנה ופאה\\tلم يصحّ عنده أنه وفّاه', \"אן אלקול באנה כ'לק שיא\\tأن القول بأنه خلق شيئاً\", 'חסנא שיא מא ותחקקה ,\\tحسّنا شيئاً ما وتحقّقه ,', 'קולא קריבא לא בעידא מן\\tقولاً قريباً لا بعيداً من', \"בה מן חמד רבנא ואלת'נא\\tبه من حمد ربّنا والثناء\", 'לכל שי מעלום באלחאל אלתי\\tلكل شيء معلوم بالحال التي', 'אלוקוף בין ידיה פלא יערפה\\tالوقوف بين يديه فلا يعرفه', \"בל לא יג'וז אן יכון פעל\\tبل لا يجوز أن يكون فعل\", \"H H H . וארי אן אג'על\\tH H H . وأرى أن أجعل\", 'יסתעסר לה אן יעיד שיא\\tيستعسر له أن يعيد شيئاً']\n",
            "len(lines) 49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-7350ffc72fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#if STATEFUL:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest_kfir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"with_context.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace_GAIN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSHOW_PRINT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRINT_DETAILED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"context_idexes.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-dc7e7052cac4>\u001b[0m in \u001b[0;36mtest_kfir\u001b[0;34m(data_path, replace_GAIN, SHOW_PRINT, index_path)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mbatch_indexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum_of_e_d_normalized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum_of_e_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_letters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_text_kfir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_hebrew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_arab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_indexes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSHOW_PRINT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSHOW_PRINT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mSHOW_PRINT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mprint_log_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BATCH (sum_of_e_d_normalized,num_of_examples): \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum_of_e_d_normalized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-f1627b48d6e9>\u001b[0m in \u001b[0;36mtest_text_kfir\u001b[0;34m(JA_lines, arr_lines, indexes, num_of_paths, _BATCH_SIZE, SHOW_PRINT)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0mreal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0med_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meditdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#print(real, len(real))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjJv0g7qoF5L",
        "colab_type": "text"
      },
      "source": [
        "##test baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnZGDfiE4brU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"TEST_BASELINE\"\n",
        "\n",
        "def baseline(this_dataset=test_dataset_double_kuzari,print_only_first_in_bath=True,limit=False):\n",
        "  num_of_paths=1\n",
        "  total_loss=0\n",
        "  total_accuracy=0\n",
        "  total_examples=0\n",
        "  line_counter=1\n",
        "  if limit:\n",
        "    this_dataset=this_dataset.take(limit)\n",
        "  for input_batch, target_batch, inputs_len,targets_len in this_dataset:\t\t\t\n",
        "          for i in range(BATCH_SIZE):\n",
        "                heb_input=decode_JA(input_batch[i])\n",
        "                heb_input=undouble_hebrew(heb_input).strip(BLANK)\n",
        "                prediction=simple_letter_map(heb_input)\n",
        "                real=decode_arr(target_batch[i],targets_len[i].numpy()).strip(BLANK)\n",
        "                accuracy=editdistance.eval(real, prediction)\n",
        "                accuracy/=len(real)\n",
        "                total_accuracy+=accuracy\n",
        "                if print_only_first_in_bath and i!=0:\n",
        "                    continue\n",
        "                real,prediction=show_diff(real,prediction,'red')\n",
        "                print_log_screen(\"({0})\".format(line_counter),LTRchar,heb_input.strip(BLANK),\"|\",real,\"|\",prediction,\"|\",\"{0:.4f}\".format(accuracy))\n",
        "                line_counter+=1\n",
        "          total_examples+=BATCH_SIZE\n",
        "\t\t\t\t\t\t\t \n",
        "  if total_accuracy!=0:\n",
        "    total_accuracy/=total_examples\n",
        "    print_log_screen(\"baseline accuracy: \",1-total_accuracy)\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "  return 1-total_accuracy\n",
        "#baseline(limit=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WehJRO5foBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "d79441f8-6536-4808-a23a-ef0b025cf1fb"
      },
      "source": [
        "baseline(limit=3)\n",
        "# print_log_screen(\"KUZARI TEST\")\n",
        "# baseline(test_dataset_double_kuzari)\n",
        "# print_log_screen(\"RASAG TEST\")\n",
        "# baseline(test_dataset_double_rasag)\n",
        "\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1) ‫ ואהל אלאדיאנ ת'מ עלי | و\u001b[1m\u001b[31mأ\u001b[0mهل ال\u001b[1m\u001b[31mأ\u001b[0mديان ثم\u001b[1m\u001b[31mّ\u001b[0m عل\u001b[1m\u001b[31mى\u001b[0m | و\u001b[1m\u001b[31mا\u001b[0mهل ال\u001b[1m\u001b[31mا\u001b[0mديان ثم عل\u001b[1m\u001b[31mي\u001b[0m | 0.2000\n",
            "(2) ‫ הכד'א כאנ קומה מעה , | هكذا كان قومه معه , | هكذا كان قومه معه , | 0.0000\n",
            "(3) ‫ תקתצ'י אלמעאני אלתי יריד | تقتضي المعاني التي يريد | تقتضي المعاني التي يريد | 0.0000\n",
            "baseline accuracy:  0.9019730996119918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9019730996119918"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKWMVLTywwIW",
        "colab_type": "text"
      },
      "source": [
        "##TEST BASELINE KFIR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlrcOFoswu-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f09076e-c557-4351-8336-04202c00db2f"
      },
      "source": [
        "CELL_NAME=\"DEF TEST_BASELINE_KFIR\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#only once per file\n",
        "kfir_rasag_lines=preprocess_lines(\n",
        "    load_lines(kfir_rasag_test)\n",
        ")\n",
        "kfir_rasag_phrases=create_parralel_phrases(kfir_rasag_lines,1)\n",
        "\n",
        "kfir_kuzari_lines=preprocess_lines(\n",
        "    load_lines(kfir_kuzari_test)\n",
        ")\n",
        "kfir_kuzari_phrases=create_parralel_phrases(kfir_kuzari_lines,1)\n",
        "\n",
        "\n",
        "#data_path options:\n",
        "# kfir_kuzari_test\n",
        "# kfir_rasag_test\n",
        "\n",
        "#replace_GAIN - replace JAIN with GIMEL\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def baseline_kfir(pairs,replace_GAIN=False,SHOW_PRINT=False): \n",
        "  if replace_GAIN:\n",
        "    print_log_screen(\"replaceing gimel with jain to match my train convention\")\n",
        "    hebrew_lines=[heb.replace(\"גג\",\"גג''\").replace(\"גג''''\",\"גג\") for heb, arr in pairs] #ייננבבגג''יי\n",
        "  else:\n",
        "    hebrew_lines=[heb for heb, arr in pairs]\n",
        "  arab_lines=[arr for heb, arr in pairs]\n",
        "  \n",
        "  total_examples=len(pairs)\n",
        "  total_loss=0\n",
        "  sum_of_e_dist=0\n",
        "  num_of_letters=0\n",
        "  for l in arab_lines:\n",
        "    num_of_letters+=len(l)\n",
        "  total_accuracy=0\n",
        "  line_counter=1\n",
        "  for heb_input,real in zip(hebrew_lines,arab_lines):\n",
        "                heb_input=undouble_hebrew(heb_input).strip(BLANK)\n",
        "                prediction=simple_letter_map(heb_input)                \n",
        "                accuracy=editdistance.eval(real, prediction)\n",
        "                normalized_accuracy=accuracy/len(real)\n",
        "                total_accuracy+=normalized_accuracy\n",
        "                real,prediction=show_diff(real,prediction,'red')\n",
        "                sum_of_e_dist+=accuracy\n",
        "                if SHOW_PRINT:\n",
        "                  print_log_screen(\"({0})\".format(line_counter),LTRchar,heb_input.strip(BLANK),\"|\",real,\"|\",prediction,\"|\",str(accuracy))\n",
        "                line_counter+=1\n",
        "\t\t\t\t\t\t\t   \n",
        "  total_accuracy/=total_examples\n",
        "  sum_of_e_dist/num_of_letters\n",
        "  print_log_screen(\"accuracy: \",1-total_accuracy)\n",
        "  print_log_screen(\"accuracy1: \",1-sum_of_e_dist/num_of_letters)\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "  return 0,total_accuracy,sum_of_e_dist/num_of_letters\n",
        "#baseline(limit=3)\n",
        "#baseline_kfir(kfir_kuzari_phrases)\n",
        "baseline_kfir(kfir_kuzari_phrases,False,True)\n",
        "#baseline_kfir(kfir_rasag_phrases)\n",
        "baseline_kfir(kfir_rasag_phrases,False,True)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading text: /gdrive/My Drive/thesis-data/kfir1/kfir_rasag_test.txt\n",
            "first lines: ['דאר\\tدار', 'אלגזא\\tالجزاء', 'וקבל\\tوقبل', \"ד'לך\\tذلك\", 'מא\\tما', 'ראי\\tرأى', 'אן\\tأن', 'יפרק\\tيفرّق', 'בין\\tبين', 'רוחה\\tروحه', 'וגסמה\\tوجسمه', 'אלי\\tإلى', 'וקת\\tوقت', 'אסתכמאל\\tاستكمال', 'אלנפוס\\tالنفوس', 'חתי\\tحتى', 'יגמעהא\\tيجمعها', 'אלגמיע\\tالجميع', 'עלי\\tعلى', 'מא\\tما', 'בינת\\tبيّنت', 'פלא\\tفلا', 'נעלם\\tنعلم', 'יהודיא\\tيهوديّاً', \"יכ'אלף\\tيخالف\", 'עלי\\tعلى', \"הד'ה\\tهذه\", 'אלאמאנה\\tالأمانة', 'ולא\\tولا', 'יסתצעב\\tيستصعب', 'ענד\\tعند', 'עקלה\\tعقله', 'כיף\\tكيف', 'יחיי\\tيحيي', 'רבה\\tربّه', 'אלמותי\\tالموتى', \"אד'\\tإذ\", 'קד\\tقد', 'צח\\tصحّ', 'לה\\tله', 'אנה\\tأنه', \"כ'לק\\tخلق\", 'שיא\\tشيئاً', 'לא\\tلا', 'מן\\tمن', 'שי\\tشيء', 'פלא\\tفلا', 'יגוז\\tيجوز', 'אן\\tأن', 'יסתעסר\\tيستعسر']\n",
            "len(lines) 50\n",
            "loading text: /gdrive/My Drive/thesis-data/kfir1/kfir_kuzari_test.txt\n",
            "first lines: ['לא\\tلا', \"תכ'אף\\tتخاف\", 'אלפנא\\tالفناء', 'אבדא\\tإبداً', 'פתציר\\tفتصير', 'נפס\\tنفس', 'אלאנסאן\\tالإنسان', 'אלכאמל\\tالكامل', \"וד'לך\\tوذلك\", 'אלעקל\\tالعقل', 'שיא\\tشيئاً', 'ואחדא\\tواحداً', 'פלא\\tفلا', 'יבאלי\\tيخلى', 'בפנא\\tبفناء', \"ג'סדה\\tجسده\", 'ואלאתה\\tوآلاته', \"אד'\\tإذ\", 'קד\\tقد', 'צאר\\tصار', \"וד'לך\\tوذلك\", 'שיא\\tشيئاً', 'ואחדא\\tواحداً', 'וטאבת\\tوطابت', 'נפסה\\tنفسه', 'פי\\tفي', 'אלחיאה\\tالحياة', 'אד\\tإذ', 'צאר\\tصار', 'פי\\tفي', 'זמרה\\tزمرة', 'הרמס\\tهرمس', 'ואסקלאביוס\\tوإسقلابيوس', 'וסקראט\\tوسقراط', 'ואפלאטון\\tوإفلاطون', 'וארסטוטאליס\\tوإرسطوطاليس', 'בל\\tبل', 'הו\\tهو', 'והם\\tوهم', 'וכל\\tوكلّ', 'מן\\tمن', 'כאן\\tكان', 'פי\\tفي', \"דרג'תהם\\tدرجتهم\", 'ואלעקל\\tوالعقل', 'אלפעאל\\tالفعّال', 'שי\\tشيء', 'ואחד\\tواحد', \"פהד'א\\tفهذا\", \"אלד'י\\tالذي\", 'יכני\\tيكنّى', 'ענה\\tعنه', \"ברצ'א\\tبرضا\", 'אללה\\tالله', 'עלי\\tعلى', 'סביל\\tسبيل', 'אללגז\\tاللغز', 'או\\tإو', 'אלתקריב\\tالتقريب', 'פאתבעה\\tفاتّبعه', 'ואתבע\\tواتّبع', 'אלעלם\\tالعلم', 'בחקאיק\\tبحقائق', 'אלאמור\\tالإمور', 'ליציר\\tليصير', 'עקלך\\tعقلك', 'פעלא\\tفاعلاً', 'לא\\tلا', 'מנפעלא\\tمنفعلاً', 'ואלזם\\tوالزم', 'אעדל\\tإعدل', 'אלטרק\\tالطرق', 'פי\\tفي', \"אלאכ'לאק\\tالإخلاق\", 'ואלאעמאל\\tوالإعمال', 'לאנה\\tلإنّه', 'מעונה\\tمعونة', 'פי\\tفي', 'תצור\\tتصوّر', 'אלחק\\tالحقّ', 'ולזום\\tولزوم', 'אלתעלם\\tالتعلّم', 'ואלתשבה\\tوالتشبّه', \"בד'לך\\tبذلك\", 'אלעקל\\tالعقل', 'אלפעאל\\tالفعّال', 'ויתבע\\tويتبع', \"הד'א\\tهذا\", 'אלקנוע\\tالقنوع', \"ואלכ'צ'וע\\tوالخضوع\", \"ואלכ'שוע\\tوالخشوع\", 'וכל\\tوكلّ', \"כ'לק\\tخلق\", \"פאצ'ל\\tفاضل\", 'מע\\tمع', \"אלתעט'ים\\tالتعظيم\", 'ללסבב\\tللسبب', 'אלאול\\tالإوّل', 'לא\\tلا', 'ליהבך\\tليهبك']\n",
            "len(lines) 500\n",
            "(1) ‫ לא | لا | لا | 0\n",
            "(2) ‫ תכ'אפ | تخاف | تخاف | 0\n",
            "(3) ‫ אלפנא | الفنا\u001b[1m\u001b[31mء\u001b[0m | الفنا | 1\n",
            "(4) ‫ אבדא | \u001b[1m\u001b[31mإ\u001b[0mبدا\u001b[1m\u001b[31mً\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mبدا | 2\n",
            "(5) ‫ פתציר | فتصير | فتصير | 0\n",
            "(6) ‫ נפס | نفس | نفس | 0\n",
            "(7) ‫ אלאנסאנ | ال\u001b[1m\u001b[31mإ\u001b[0mنسان | ال\u001b[1m\u001b[31mا\u001b[0mنسان | 1\n",
            "(8) ‫ אלכאמל | الكامل | الكامل | 0\n",
            "(9) ‫ וד'לכ | وذلك | وذلك | 0\n",
            "(10) ‫ אלעקל | العقل | العقل | 0\n",
            "(11) ‫ שיא | شي\u001b[1m\u001b[31mئ\u001b[0mا\u001b[1m\u001b[31mً\u001b[0m | شيا | 2\n",
            "(12) ‫ ואחדא | واحدا\u001b[1m\u001b[31mً\u001b[0m | واحدا | 1\n",
            "(13) ‫ פלא | فلا | فلا | 0\n",
            "(14) ‫ יבאלי | ي\u001b[1m\u001b[31mخ\u001b[0mل\u001b[1m\u001b[31mى\u001b[0m | ي\u001b[1m\u001b[31mبا\u001b[0mل\u001b[1m\u001b[31mي\u001b[0m | 3\n",
            "(15) ‫ בפנא | بفنا\u001b[1m\u001b[31mء\u001b[0m | بفنا | 1\n",
            "(16) ‫ ג'סדה | جسده | جسده | 0\n",
            "(17) ‫ ואלאתה | و\u001b[1m\u001b[31mآ\u001b[0mلاته | و\u001b[1m\u001b[31mا\u001b[0mلاته | 1\n",
            "(18) ‫ אד' | \u001b[1m\u001b[31mإ\u001b[0mذ | \u001b[1m\u001b[31mا\u001b[0mذ | 1\n",
            "(19) ‫ קד | قد | قد | 0\n",
            "(20) ‫ צאר | صار | صار | 0\n",
            "(21) ‫ וד'לכ | وذلك | وذلك | 0\n",
            "(22) ‫ שיא | شي\u001b[1m\u001b[31mئ\u001b[0mا\u001b[1m\u001b[31mً\u001b[0m | شيا | 2\n",
            "(23) ‫ ואחדא | واحدا\u001b[1m\u001b[31mً\u001b[0m | واحدا | 1\n",
            "(24) ‫ וטאבת | وطابت | وطابت | 0\n",
            "(25) ‫ נפסה | نفسه | نفسه | 0\n",
            "(26) ‫ פי | في | في | 0\n",
            "(27) ‫ אלחיאה | الحيا\u001b[1m\u001b[31mة\u001b[0m | الحيا\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(28) ‫ אד | \u001b[1m\u001b[31mإذ\u001b[0m | \u001b[1m\u001b[31mاد\u001b[0m | 2\n",
            "(29) ‫ צאר | صار | صار | 0\n",
            "(30) ‫ פי | في | في | 0\n",
            "(31) ‫ זמרה | زمر\u001b[1m\u001b[31mة\u001b[0m | زمر\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(32) ‫ הרמס | هرمس | هرمس | 0\n",
            "(33) ‫ ואסקלאביוס | و\u001b[1m\u001b[31mإ\u001b[0mسقلابيوس | و\u001b[1m\u001b[31mا\u001b[0mسقلابيوس | 1\n",
            "(34) ‫ וסקראט | وسقراط | وسقراط | 0\n",
            "(35) ‫ ואפלאטונ | و\u001b[1m\u001b[31mإ\u001b[0mفلاطون | و\u001b[1m\u001b[31mا\u001b[0mفلاطون | 1\n",
            "(36) ‫ וארסטוטאליס | و\u001b[1m\u001b[31mإ\u001b[0mرسطوطاليس | و\u001b[1m\u001b[31mا\u001b[0mرسطوطاليس | 1\n",
            "(37) ‫ בל | بل | بل | 0\n",
            "(38) ‫ הו | هو | هو | 0\n",
            "(39) ‫ והמ | وهم | وهم | 0\n",
            "(40) ‫ וכל | وكل\u001b[1m\u001b[31mّ\u001b[0m | وكل | 1\n",
            "(41) ‫ מנ | من | من | 0\n",
            "(42) ‫ כאנ | كان | كان | 0\n",
            "(43) ‫ פי | في | في | 0\n",
            "(44) ‫ דרג'תהמ | درجتهم | درجتهم | 0\n",
            "(45) ‫ ואלעקל | والعقل | والعقل | 0\n",
            "(46) ‫ אלפעאל | الفع\u001b[1m\u001b[31mّ\u001b[0mال | الفعال | 1\n",
            "(47) ‫ שי | شي\u001b[1m\u001b[31mء\u001b[0m | شي | 1\n",
            "(48) ‫ ואחד | واحد | واحد | 0\n",
            "(49) ‫ פהד'א | فهذا | فهذا | 0\n",
            "(50) ‫ אלד'י | الذي | الذي | 0\n",
            "(51) ‫ יכני | يكن\u001b[1m\u001b[31mّى\u001b[0m | يكن\u001b[1m\u001b[31mي\u001b[0m | 2\n",
            "(52) ‫ ענה | عنه | عنه | 0\n",
            "(53) ‫ ברצ'א | برضا | برضا | 0\n",
            "(54) ‫ אללה | الله | الله | 0\n",
            "(55) ‫ עלי | عل\u001b[1m\u001b[31mى\u001b[0m | عل\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(56) ‫ סביל | سبيل | سبيل | 0\n",
            "(57) ‫ אללגז | اللغز | اللغز | 0\n",
            "(58) ‫ או | \u001b[1m\u001b[31mإ\u001b[0mو | \u001b[1m\u001b[31mا\u001b[0mو | 1\n",
            "(59) ‫ אלתקריב | التقريب | التقريب | 0\n",
            "(60) ‫ פאתבעה | فات\u001b[1m\u001b[31mّ\u001b[0mبعه | فاتبعه | 1\n",
            "(61) ‫ ואתבע | وات\u001b[1m\u001b[31mّ\u001b[0mبع | واتبع | 1\n",
            "(62) ‫ אלעלמ | العلم | العلم | 0\n",
            "(63) ‫ בחקאיק | بحقا\u001b[1m\u001b[31mئ\u001b[0mق | بحقا\u001b[1m\u001b[31mي\u001b[0mق | 1\n",
            "(64) ‫ אלאמור | ال\u001b[1m\u001b[31mإ\u001b[0mمور | ال\u001b[1m\u001b[31mا\u001b[0mمور | 1\n",
            "(65) ‫ ליציר | ليصير | ليصير | 0\n",
            "(66) ‫ עקלכ | عقلك | عقلك | 0\n",
            "(67) ‫ פעלא | ف\u001b[1m\u001b[31mا\u001b[0mعلا\u001b[1m\u001b[31mً\u001b[0m | فعلا | 2\n",
            "(68) ‫ לא | لا | لا | 0\n",
            "(69) ‫ מנפעלא | منفعلا\u001b[1m\u001b[31mً\u001b[0m | منفعلا | 1\n",
            "(70) ‫ ואלזמ | والزم | والزم | 0\n",
            "(71) ‫ אעדל | \u001b[1m\u001b[31mإ\u001b[0mعدل | \u001b[1m\u001b[31mا\u001b[0mعدل | 1\n",
            "(72) ‫ אלטרק | الطرق | الطرق | 0\n",
            "(73) ‫ פי | في | في | 0\n",
            "(74) ‫ אלאכ'לאק | ال\u001b[1m\u001b[31mإ\u001b[0mخلاق | ال\u001b[1m\u001b[31mا\u001b[0mخلاق | 1\n",
            "(75) ‫ ואלאעמאל | وال\u001b[1m\u001b[31mإ\u001b[0mعمال | وال\u001b[1m\u001b[31mا\u001b[0mعمال | 1\n",
            "(76) ‫ לאנה | ل\u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0mه | ل\u001b[1m\u001b[31mا\u001b[0mنه | 2\n",
            "(77) ‫ מעונה | معون\u001b[1m\u001b[31mة\u001b[0m | معون\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(78) ‫ פי | في | في | 0\n",
            "(79) ‫ תצור | تصو\u001b[1m\u001b[31mّ\u001b[0mر | تصور | 1\n",
            "(80) ‫ אלחק | الحق\u001b[1m\u001b[31mّ\u001b[0m | الحق | 1\n",
            "(81) ‫ ולזומ | ولزوم | ولزوم | 0\n",
            "(82) ‫ אלתעלמ | التعل\u001b[1m\u001b[31mّ\u001b[0mم | التعلم | 1\n",
            "(83) ‫ ואלתשבה | والتشب\u001b[1m\u001b[31mّ\u001b[0mه | والتشبه | 1\n",
            "(84) ‫ בד'לכ | بذلك | بذلك | 0\n",
            "(85) ‫ אלעקל | العقل | العقل | 0\n",
            "(86) ‫ אלפעאל | الفع\u001b[1m\u001b[31mّ\u001b[0mال | الفعال | 1\n",
            "(87) ‫ ויתבע | ويتبع | ويتبع | 0\n",
            "(88) ‫ הד'א | هذا | هذا | 0\n",
            "(89) ‫ אלקנוע | القنوع | القنوع | 0\n",
            "(90) ‫ ואלכ'צ'וע | والخضوع | والخضوع | 0\n",
            "(91) ‫ ואלכ'שוע | والخشوع | والخشوع | 0\n",
            "(92) ‫ וכל | وكل\u001b[1m\u001b[31mّ\u001b[0m | وكل | 1\n",
            "(93) ‫ כ'לק | خلق | خلق | 0\n",
            "(94) ‫ פאצ'ל | فاضل | فاضل | 0\n",
            "(95) ‫ מע | مع | مع | 0\n",
            "(96) ‫ אלתעט'ימ | التعظيم | التعظيم | 0\n",
            "(97) ‫ ללסבב | للسبب | للسبب | 0\n",
            "(98) ‫ אלאול | ال\u001b[1m\u001b[31mإ\u001b[0mو\u001b[1m\u001b[31mّ\u001b[0mل | ال\u001b[1m\u001b[31mا\u001b[0mول | 2\n",
            "(99) ‫ לא | لا | لا | 0\n",
            "(100) ‫ ליהבכ | ليهبك | ليهبك | 0\n",
            "(101) ‫ רצ'אה | رضاه | رضاه | 0\n",
            "(102) ‫ ולא | ولا | ولا | 0\n",
            "(103) ‫ ליזיל | ليزيل | ليزيل | 0\n",
            "(104) ‫ ענכ | عنك | عنك | 0\n",
            "(105) ‫ סכ'טה | سخطه | سخطه | 0\n",
            "(106) ‫ בל | بل | بل | 0\n",
            "(107) ‫ ללתשבה | للتشب\u001b[1m\u001b[31mّ\u001b[0mه | للتشبه | 1\n",
            "(108) ‫ ללעקל | للعقل | للعقل | 0\n",
            "(109) ‫ אלפעאל | الفع\u001b[1m\u001b[31mّ\u001b[0mال | الفعال | 1\n",
            "(110) ‫ פי | في | في | 0\n",
            "(111) ‫ אית'אר | \u001b[1m\u001b[31mإ\u001b[0mيثار | \u001b[1m\u001b[31mا\u001b[0mيثار | 1\n",
            "(112) ‫ אלחק | الحق\u001b[1m\u001b[31mّ\u001b[0m | الحق | 1\n",
            "(113) ‫ ווצפ | ووصف | ووصف | 0\n",
            "(114) ‫ כל | كل\u001b[1m\u001b[31mّ\u001b[0m | كل | 1\n",
            "(115) ‫ שי | شي\u001b[1m\u001b[31mء\u001b[0m | شي | 1\n",
            "(116) ‫ במא | بما | بما | 0\n",
            "(117) ‫ יג'ב | يجب | يجب | 0\n",
            "(118) ‫ לה | له | له | 0\n",
            "(119) ‫ ואעתקאדה | واعتقاده | واعتقاده | 0\n",
            "(120) ‫ עלי | عل\u001b[1m\u001b[31mى\u001b[0m | عل\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(121) ‫ מא | ما | ما | 0\n",
            "(122) ‫ הו | هو | هو | 0\n",
            "(123) ‫ עליה | عليه | عليه | 0\n",
            "(124) ‫ פהד'א | فهذا | فهذا | 0\n",
            "(125) ‫ מנ | من | من | 0\n",
            "(126) ‫ צפאת | صفات | صفات | 0\n",
            "(127) ‫ אלעקל | العقل | العقل | 0\n",
            "(128) ‫ פאד' | ف\u001b[1m\u001b[31mإ\u001b[0mذ | ف\u001b[1m\u001b[31mا\u001b[0mذ | 1\n",
            "(129) ‫ צרת | صرت | صرت | 0\n",
            "(130) ‫ בהד'ה | بهذه | بهذه | 0\n",
            "(131) ‫ אלצפה | الصف\u001b[1m\u001b[31mة\u001b[0m | الصف\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(132) ‫ מנ | من | من | 0\n",
            "(133) ‫ אלאעתקאד | الاعتقاد | الاعتقاد | 0\n",
            "(134) ‫ לא | لا | لا | 0\n",
            "(135) ‫ תבאלי | تبالي | تبالي | 0\n",
            "(136) ‫ באי | ب\u001b[1m\u001b[31mإ\u001b[0mي\u001b[1m\u001b[31mّ\u001b[0m | ب\u001b[1m\u001b[31mا\u001b[0mي | 2\n",
            "(137) ‫ שרע | شرع | شرع | 0\n",
            "(138) ‫ תשרעת | تشر\u001b[1m\u001b[31mّ\u001b[0mعت | تشرعت | 1\n",
            "(139) ‫ או | \u001b[1m\u001b[31mإ\u001b[0mو | \u001b[1m\u001b[31mا\u001b[0mو | 1\n",
            "(140) ‫ תדינת | تدي\u001b[1m\u001b[31mّ\u001b[0mنت | تدينت | 1\n",
            "(141) ‫ ועט'מת | وعظ\u001b[1m\u001b[31mّ\u001b[0mمت | وعظمت | 1\n",
            "(142) ‫ ובאי | وب\u001b[1m\u001b[31mإ\u001b[0mي\u001b[1m\u001b[31mّ\u001b[0m | وب\u001b[1m\u001b[31mا\u001b[0mي | 2\n",
            "(143) ‫ קול | قول | قول | 0\n",
            "(144) ‫ ובאי | وب\u001b[1m\u001b[31mإ\u001b[0mي\u001b[1m\u001b[31mّ\u001b[0m | وب\u001b[1m\u001b[31mا\u001b[0mي | 2\n",
            "(145) ‫ לסאנ | لسان | لسان | 0\n",
            "(146) ‫ ובאי | وب\u001b[1m\u001b[31mإ\u001b[0mي\u001b[1m\u001b[31mّ\u001b[0m | وب\u001b[1m\u001b[31mا\u001b[0mي | 2\n",
            "(147) ‫ אעמאל | \u001b[1m\u001b[31mإ\u001b[0mعمال | \u001b[1m\u001b[31mا\u001b[0mعمال | 1\n",
            "(148) ‫ או | \u001b[1m\u001b[31mإ\u001b[0mو | \u001b[1m\u001b[31mا\u001b[0mو | 1\n",
            "(149) ‫ אכ'תרע | اخترع | اخترع | 0\n",
            "(150) ‫ לנפסכ | لنفسك | لنفسك | 0\n",
            "(151) ‫ דינא | دينا\u001b[1m\u001b[31mً\u001b[0m | دينا | 1\n",
            "(152) ‫ למעני | لمعن\u001b[1m\u001b[31mى\u001b[0m | لمعن\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(153) ‫ אלתכ'שע | التخش\u001b[1m\u001b[31mّ\u001b[0mع | التخشع | 1\n",
            "(154) ‫ ואלתעט'ימ | والتعظيم | والتعظيم | 0\n",
            "(155) ‫ ואלתסביח | والتسبيح | والتسبيح | 0\n",
            "(156) ‫ ולתדביר | وتدبير | و\u001b[1m\u001b[31mل\u001b[0mتدبير | 1\n",
            "(157) ‫ אכ'לאקכ | \u001b[1m\u001b[31mإ\u001b[0mخلاقك | \u001b[1m\u001b[31mا\u001b[0mخلاقك | 1\n",
            "(158) ‫ ותדביר | وتدبير | وتدبير | 0\n",
            "(159) ‫ מנזלכ | منزلك | منزلك | 0\n",
            "(160) ‫ ומדינתכ | ومدينتك | ومدينتك | 0\n",
            "(161) ‫ אנ | \u001b[1m\u001b[31mإ\u001b[0mن | \u001b[1m\u001b[31mا\u001b[0mن | 1\n",
            "(162) ‫ כנת | كنت | كنت | 0\n",
            "(163) ‫ מקבולא | مقبولا\u001b[1m\u001b[31mً\u001b[0m | مقبولا | 1\n",
            "(164) ‫ מנהמ | منهم | منهم | 0\n",
            "(165) ‫ או | \u001b[1m\u001b[31mإ\u001b[0mو | \u001b[1m\u001b[31mا\u001b[0mو | 1\n",
            "(166) ‫ תדינ | تدي\u001b[1m\u001b[31mّ\u001b[0mن | تدين | 1\n",
            "(167) ‫ באלנואמיס | بالنواميس | بالنواميس | 0\n",
            "(168) ‫ אלעקליה | العقلي\u001b[1m\u001b[31mة\u001b[0m | العقلي\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(169) ‫ אלמולפה | الم\u001b[1m\u001b[31mؤ\u001b[0mل\u001b[1m\u001b[31mّ\u001b[0mف\u001b[1m\u001b[31mة\u001b[0m | الم\u001b[1m\u001b[31mو\u001b[0mلف\u001b[1m\u001b[31mه\u001b[0m | 3\n",
            "(170) ‫ ללפלאספה | للفلاسف\u001b[1m\u001b[31mة\u001b[0m | للفلاسف\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(171) ‫ ואג'על | واجعل | واجعل | 0\n",
            "(172) ‫ קצדכ | قصدك | قصدك | 0\n",
            "(173) ‫ וגרצ'כ | وغرضك | وغرضك | 0\n",
            "(174) ‫ צפא | صفا\u001b[1m\u001b[31mء\u001b[0m | صفا | 1\n",
            "(175) ‫ נפסכ | نفسك | نفسك | 0\n",
            "(176) ‫ ובאלג'מלה | وبالجمل\u001b[1m\u001b[31mة\u001b[0m | وبالجمل\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(177) ‫ פאטלב | فاطلب | فاطلب | 0\n",
            "(178) ‫ צפא | صفا\u001b[1m\u001b[31mء\u001b[0m | صفا | 1\n",
            "(179) ‫ אלקלב | القلب | القلب | 0\n",
            "(180) ‫ באי | ب\u001b[1m\u001b[31mإ\u001b[0mي\u001b[1m\u001b[31mّ\u001b[0m | ب\u001b[1m\u001b[31mا\u001b[0mي | 2\n",
            "(181) ‫ וג'ה | وجه | وجه | 0\n",
            "(182) ‫ אמכנכ | \u001b[1m\u001b[31mإ\u001b[0mمكنك | \u001b[1m\u001b[31mا\u001b[0mمكنك | 1\n",
            "(183) ‫ בעד | بعد | بعد | 0\n",
            "(184) ‫ תחציל | تحصيل | تحصيل | 0\n",
            "(185) ‫ כליאת | كل\u001b[1m\u001b[31mّ\u001b[0mيات | كليات | 1\n",
            "(186) ‫ אלעלומ | العلوم | العلوم | 0\n",
            "(187) ‫ עלי | عل\u001b[1m\u001b[31mى\u001b[0m | عل\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(188) ‫ חקאיקהא | حقا\u001b[1m\u001b[31mئ\u001b[0mقها | حقا\u001b[1m\u001b[31mي\u001b[0mقها | 1\n",
            "(189) ‫ פתצאדפ | فتصادف | فتصادف | 0\n",
            "(190) ‫ מטלובכ | مطلبك | مطل\u001b[1m\u001b[31mو\u001b[0mبك | 1\n",
            "(191) ‫ אעני | \u001b[1m\u001b[31mإ\u001b[0mعني | \u001b[1m\u001b[31mا\u001b[0mعني | 1\n",
            "(192) ‫ אלאתצאל | الات\u001b[1m\u001b[31mّ\u001b[0mصال | الاتصال | 1\n",
            "(193) ‫ בד'לכ | بذلك | بذلك | 0\n",
            "(194) ‫ אלרוחאני | الروحاني\u001b[1m\u001b[31mّ\u001b[0m | الروحاني | 1\n",
            "(195) ‫ אעני | \u001b[1m\u001b[31mإ\u001b[0mعني | \u001b[1m\u001b[31mا\u001b[0mعني | 1\n",
            "(196) ‫ אלעקל | العقل | العقل | 0\n",
            "(197) ‫ אלפעאל | الفع\u001b[1m\u001b[31mّ\u001b[0mال | الفعال | 1\n",
            "(198) ‫ ורבמא | ورب\u001b[1m\u001b[31mّ\u001b[0mما | وربما | 1\n",
            "(199) ‫ אנבאכ | \u001b[1m\u001b[31mإ\u001b[0mنب\u001b[1m\u001b[31mإ\u001b[0mك | \u001b[1m\u001b[31mا\u001b[0mنب\u001b[1m\u001b[31mا\u001b[0mك | 2\n",
            "(200) ‫ ואמרכ | و\u001b[1m\u001b[31mإ\u001b[0mمرك | و\u001b[1m\u001b[31mا\u001b[0mمرك | 1\n",
            "(201) ‫ בעלמ | بعلم | بعلم | 0\n",
            "(202) ‫ גיב | غيب | غيب | 0\n",
            "(203) ‫ מנ | من | من | 0\n",
            "(204) ‫ מנאמאת | منامات | منامات | 0\n",
            "(205) ‫ צאדקה | صادق\u001b[1m\u001b[31mة\u001b[0m | صادق\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(206) ‫ וכ'יאלאת | وخيالات | وخيالات | 0\n",
            "(207) ‫ מציבה | مصيب\u001b[1m\u001b[31mة\u001b[0m | مصيب\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(208) ‫ קאל | قال | قال | 0\n",
            "(209) ‫ לה | له | له | 0\n",
            "(210) ‫ אלכ'זרי | الخزري\u001b[1m\u001b[31mّ\u001b[0m | الخزري | 1\n",
            "(211) ‫ אנ | \u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(212) ‫ כלאמכ | كلامك | كلامك | 0\n",
            "(213) ‫ למקנע | لمقنع | لمقنع | 0\n",
            "(214) ‫ לכנה | لكن\u001b[1m\u001b[31mّ\u001b[0mه | لكنه | 1\n",
            "(215) ‫ גיר | غير | غير | 0\n",
            "(216) ‫ מטאבק | مطابق | مطابق | 0\n",
            "(217) ‫ לטלבתי | لطلبتي | لطلبتي | 0\n",
            "(218) ‫ לאני | ل\u001b[1m\u001b[31mإ\u001b[0mني\u001b[1m\u001b[31mّ\u001b[0m | ل\u001b[1m\u001b[31mا\u001b[0mني | 2\n",
            "(219) ‫ אעלמ | \u001b[1m\u001b[31mإ\u001b[0mعلم | \u001b[1m\u001b[31mا\u001b[0mعلم | 1\n",
            "(220) ‫ מנ | من | من | 0\n",
            "(221) ‫ נפסי | نفسي | نفسي | 0\n",
            "(222) ‫ אני | \u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0mي | \u001b[1m\u001b[31mا\u001b[0mني | 2\n",
            "(223) ‫ צאפי | صافي | صافي | 0\n",
            "(224) ‫ אלנפס | النفس | النفس | 0\n",
            "(225) ‫ מסדד | مسد\u001b[1m\u001b[31mّ\u001b[0mد | مسدد | 1\n",
            "(226) ‫ אלאעמאל | ال\u001b[1m\u001b[31mإ\u001b[0mعمال | ال\u001b[1m\u001b[31mا\u001b[0mعمال | 1\n",
            "(227) ‫ נחו | نحو | نحو | 0\n",
            "(228) ‫ רצ'א | رضا | رضا | 0\n",
            "(229) ‫ אלרב | الرب\u001b[1m\u001b[31mّ\u001b[0m | الرب | 1\n",
            "(230) ‫ לכנ | لكن | لكن | 0\n",
            "(231) ‫ כאנ | كان | كان | 0\n",
            "(232) ‫ ג'ואבי | جوابي | جوابي | 0\n",
            "(233) ‫ אנ | \u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(234) ‫ הד'א | هذا | هذا | 0\n",
            "(235) ‫ אלעמל | العمل | العمل | 0\n",
            "(236) ‫ ליס | ليس | ليس | 0\n",
            "(237) ‫ במרצ'י | بمرضي\u001b[1m\u001b[31mّ\u001b[0m | بمرضي | 1\n",
            "(238) ‫ ואנ | و\u001b[1m\u001b[31mإ\u001b[0mن | و\u001b[1m\u001b[31mا\u001b[0mن | 1\n",
            "(239) ‫ כאנת | كانت | كانت | 0\n",
            "(240) ‫ אלניה | الني\u001b[1m\u001b[31mّة\u001b[0m | الني\u001b[1m\u001b[31mه\u001b[0m | 2\n",
            "(241) ‫ מרצ'יה | مرضي\u001b[1m\u001b[31mّة\u001b[0m | مرضي\u001b[1m\u001b[31mه\u001b[0m | 2\n",
            "(242) ‫ פלא | فلا | فلا | 0\n",
            "(243) ‫ שכ | شك\u001b[1m\u001b[31mّ\u001b[0m | شك | 1\n",
            "(244) ‫ אנ | \u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(245) ‫ ת'מ | ثم\u001b[1m\u001b[31mّ\u001b[0m | ثم | 1\n",
            "(246) ‫ עמלא | عملا\u001b[1m\u001b[31mً\u001b[0m | عملا | 1\n",
            "(247) ‫ מא | ما | ما | 0\n",
            "(248) ‫ מרצ'יא | مرضيا\u001b[1m\u001b[31mً\u001b[0m | مرضيا | 1\n",
            "(249) ‫ בד'אתה | بذاته | بذاته | 0\n",
            "(250) ‫ לא | لا | لا | 0\n",
            "(251) ‫ בחסב | بحسب | بحسب | 0\n",
            "(252) ‫ אלט'נונ | الظنون | الظنون | 0\n",
            "(253) ‫ ואלא | و\u001b[1m\u001b[31mإ\u001b[0mلا\u001b[1m\u001b[31mّ\u001b[0m | و\u001b[1m\u001b[31mا\u001b[0mلا | 2\n",
            "(254) ‫ פאנ | ف\u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | ف\u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(255) ‫ אלנצראני | النصراني\u001b[1m\u001b[31mّ\u001b[0m | النصراني | 1\n",
            "(256) ‫ ואלמסלמ | والمسلم | والمسلم | 0\n",
            "(257) ‫ אללד'ינ | اللذين | اللذين | 0\n",
            "(258) ‫ אקתסמא | اقتسما | اقتسما | 0\n",
            "(259) ‫ אלמעמורה | المعمور\u001b[1m\u001b[31mة\u001b[0m | المعمور\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(260) ‫ יתקאתלאנ | يتقاتلان | يتقاتلان | 0\n",
            "(261) ‫ וכל | وكل\u001b[1m\u001b[31mّ\u001b[0m | وكل | 1\n",
            "(262) ‫ ואחד | واحد | واحد | 0\n",
            "(263) ‫ מנהמא | منهما | منهما | 0\n",
            "(264) ‫ קד | قد | قد | 0\n",
            "(265) ‫ אצפי | \u001b[1m\u001b[31mإ\u001b[0mصف\u001b[1m\u001b[31mى\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mصف\u001b[1m\u001b[31mي\u001b[0m | 2\n",
            "(266) ‫ ניתה | ني\u001b[1m\u001b[31mّ\u001b[0mته | نيته | 1\n",
            "(267) ‫ ללה | لله | لله | 0\n",
            "(268) ‫ ותרהב | وتره\u001b[1m\u001b[31mّ\u001b[0mب | وترهب | 1\n",
            "(269) ‫ ותזהד | وتزه\u001b[1m\u001b[31mّ\u001b[0mد | وتزهد | 1\n",
            "(270) ‫ וצאמ | وصام | وصام | 0\n",
            "(271) ‫ וצלי | وصل\u001b[1m\u001b[31mّى\u001b[0m | وصل\u001b[1m\u001b[31mي\u001b[0m | 2\n",
            "(272) ‫ ומצ'י | ومض\u001b[1m\u001b[31mى\u001b[0m | ومض\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(273) ‫ מצממא | مصم\u001b[1m\u001b[31mّ\u001b[0mما\u001b[1m\u001b[31mً\u001b[0m | مصمما | 2\n",
            "(274) ‫ לקתל | لقتل | لقتل | 0\n",
            "(275) ‫ צאחבה | صاحبه | صاحبه | 0\n",
            "(276) ‫ והו | وهو | وهو | 0\n",
            "(277) ‫ יעתקד | يعتقد | يعتقد | 0\n",
            "(278) ‫ אנ | \u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(279) ‫ פי | في | في | 0\n",
            "(280) ‫ קתלה | قتله | قتله | 0\n",
            "(281) ‫ אעט'מ | \u001b[1m\u001b[31mإ\u001b[0mعظم | \u001b[1m\u001b[31mا\u001b[0mعظم | 1\n",
            "(282) ‫ חסנה | حسن\u001b[1m\u001b[31mة\u001b[0m | حسن\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(283) ‫ ותקרב | وتقر\u001b[1m\u001b[31mّ\u001b[0mب | وتقرب | 1\n",
            "(284) ‫ אלי | \u001b[1m\u001b[31mإ\u001b[0mل\u001b[1m\u001b[31mى\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mل\u001b[1m\u001b[31mي\u001b[0m | 2\n",
            "(285) ‫ אללה | الله | الله | 0\n",
            "(286) ‫ פיקתתלאנ | فيقتتلان | فيقتتلان | 0\n",
            "(287) ‫ וכל | وكل\u001b[1m\u001b[31mّ\u001b[0m | وكل | 1\n",
            "(288) ‫ ואחד | واحد | واحد | 0\n",
            "(289) ‫ מנהמא | منهما | منهما | 0\n",
            "(290) ‫ יעתקד | يعتقد | يعتقد | 0\n",
            "(291) ‫ אנ | \u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(292) ‫ מסירה | مسيره | مسيره | 0\n",
            "(293) ‫ אלי | \u001b[1m\u001b[31mإ\u001b[0mل\u001b[1m\u001b[31mى\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mل\u001b[1m\u001b[31mي\u001b[0m | 2\n",
            "(294) ‫ אלג'נה | الجن\u001b[1m\u001b[31mّة\u001b[0m | الجن\u001b[1m\u001b[31mه\u001b[0m | 2\n",
            "(295) ‫ ואלפרדוס | والفردوس | والفردوس | 0\n",
            "(296) ‫ ותצידקהמא | وتصد\u001b[1m\u001b[31mي\u001b[0mقهما | وتص\u001b[1m\u001b[31mي\u001b[0mدقهما | 2\n",
            "(297) ‫ מחאל | محال | محال | 0\n",
            "(298) ‫ ענד | عند | عند | 0\n",
            "(299) ‫ אלעקל | العقل | العقل | 0\n",
            "(300) ‫ קאל | قال | قال | 0\n",
            "(301) ‫ אלפילסופ | الفيلسوف | الفيلسوف | 0\n",
            "(302) ‫ ליס | ليس | ليس | 0\n",
            "(303) ‫ פי | في | في | 0\n",
            "(304) ‫ דינ | دين | دين | 0\n",
            "(305) ‫ אלפלאספה | الفلاسف\u001b[1m\u001b[31mة\u001b[0m | الفلاسف\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(306) ‫ קתל | قتل | قتل | 0\n",
            "(307) ‫ ואחד | واحد | واحد | 0\n",
            "(308) ‫ מנ | من | من | 0\n",
            "(309) ‫ האולא | ه\u001b[1m\u001b[31mؤ\u001b[0mلا\u001b[1m\u001b[31mء\u001b[0m | ه\u001b[1m\u001b[31mاو\u001b[0mلا | 3\n",
            "(310) ‫ אד' | \u001b[1m\u001b[31mإ\u001b[0mذ | \u001b[1m\u001b[31mا\u001b[0mذ | 1\n",
            "(311) ‫ יומונ | ي\u001b[1m\u001b[31mؤ\u001b[0mم\u001b[1m\u001b[31mّ\u001b[0mون | ي\u001b[1m\u001b[31mو\u001b[0mمون | 2\n",
            "(312) ‫ אלעקל | العقل | العقل | 0\n",
            "(313) ‫ קאל | قال | قال | 0\n",
            "(314) ‫ אלכ'זרי | الخزري\u001b[1m\u001b[31mّ\u001b[0m | الخزري | 1\n",
            "(315) ‫ ואי | و\u001b[1m\u001b[31mإ\u001b[0mي\u001b[1m\u001b[31mّ\u001b[0m | و\u001b[1m\u001b[31mا\u001b[0mي | 2\n",
            "(316) ‫ חירה | حير\u001b[1m\u001b[31mةٍ\u001b[0m | حير\u001b[1m\u001b[31mه\u001b[0m | 2\n",
            "(317) ‫ ענד | عند | عند | 0\n",
            "(318) ‫ אלפלאספה | الفلاسف\u001b[1m\u001b[31mة\u001b[0m | الفلاسف\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(319) ‫ אעט'מ | \u001b[1m\u001b[31mإ\u001b[0mعظم | \u001b[1m\u001b[31mا\u001b[0mعظم | 1\n",
            "(320) ‫ מנ | من | من | 0\n",
            "(321) ‫ אעתקאדהמ | اعتقادهم | اعتقادهم | 0\n",
            "(322) ‫ אלחד'ת | الح\u001b[1m\u001b[31mدث\u001b[0m | الح\u001b[1m\u001b[31mذت\u001b[0m | 2\n",
            "(323) ‫ ואנ | و\u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | و\u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(324) ‫ אלעאלמ | العالم | العالم | 0\n",
            "(325) ‫ כ'לק | خلق | خلق | 0\n",
            "(326) ‫ פי | في | في | 0\n",
            "(327) ‫ סתה' | ستة | ستة | 0\n",
            "(328) ‫ איאמ | \u001b[1m\u001b[31mإ\u001b[0mيام | \u001b[1m\u001b[31mا\u001b[0mيام | 1\n",
            "(329) ‫ ואנ | و\u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | و\u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(330) ‫ אלסבב | السبب | السبب | 0\n",
            "(331) ‫ אלאול | ال\u001b[1m\u001b[31mإ\u001b[0mو\u001b[1m\u001b[31mّ\u001b[0mل | ال\u001b[1m\u001b[31mا\u001b[0mول | 2\n",
            "(332) ‫ יכלמ | يكل\u001b[1m\u001b[31mّ\u001b[0mم | يكلم | 1\n",
            "(333) ‫ שכ'צא | شخصا\u001b[1m\u001b[31mً\u001b[0m | شخصا | 1\n",
            "(334) ‫ מנ | من | من | 0\n",
            "(335) ‫ אלנאס | الناس | الناس | 0\n",
            "(336) ‫ פצ'לא | فضلا\u001b[1m\u001b[31mً\u001b[0m | فضلا | 1\n",
            "(337) ‫ ענ | عن | عن | 0\n",
            "(338) ‫ ד'לכ | ذلك | ذلك | 0\n",
            "(339) ‫ אלתנזיה | التنزيه | التنزيه | 0\n",
            "(340) ‫ אלד'י | الذي | الذي | 0\n",
            "(341) ‫ תנזהה | تنز\u001b[1m\u001b[31mّ\u001b[0mهه | تنزهه | 1\n",
            "(342) ‫ אלפלאספה | الفلاسف\u001b[1m\u001b[31mة\u001b[0m | الفلاسف\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(343) ‫ ענ | عن | عن | 0\n",
            "(344) ‫ מערפה | معرف\u001b[1m\u001b[31mة\u001b[0m | معرف\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(345) ‫ אלג'זאיאת | الجز\u001b[1m\u001b[31mئ\u001b[0mيات | الجز\u001b[1m\u001b[31mا\u001b[0mيات | 1\n",
            "(346) ‫ ומע | ومع | ومع | 0\n",
            "(347) ‫ הד'א | هذا | هذا | 0\n",
            "(348) ‫ פכאנ | فكان | فكان | 0\n",
            "(349) ‫ ינבגי | ينبغي | ينبغي | 0\n",
            "(350) ‫ עלי | عل\u001b[1m\u001b[31mى\u001b[0m | عل\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(351) ‫ אעמאל | \u001b[1m\u001b[31mإ\u001b[0mعمال | \u001b[1m\u001b[31mا\u001b[0mعمال | 1\n",
            "(352) ‫ אלפלאספה | الفلاسف\u001b[1m\u001b[31mة\u001b[0m | الفلاسف\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(353) ‫ ועלומהמ | وعلومهم | وعلومهم | 0\n",
            "(354) ‫ ותחקיקיהמ | وتحقيقهم | وتحقيق\u001b[1m\u001b[31mي\u001b[0mهم | 1\n",
            "(355) ‫ ואג'תהאדהמ | واجتهادهم | واجتهادهم | 0\n",
            "(356) ‫ אנ | \u001b[1m\u001b[31mإ\u001b[0mن | \u001b[1m\u001b[31mا\u001b[0mن | 1\n",
            "(357) ‫ תכונ | تكون | تكون | 0\n",
            "(358) ‫ אלנבוה | النبو\u001b[1m\u001b[31mّة\u001b[0m | النبو\u001b[1m\u001b[31mه\u001b[0m | 2\n",
            "(359) ‫ משהורה | مشهور\u001b[1m\u001b[31mة\u001b[0m | مشهور\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(360) ‫ פיהמ | فيهم | فيهم | 0\n",
            "(361) ‫ שאיעה | شا\u001b[1m\u001b[31mئ\u001b[0mع\u001b[1m\u001b[31mة\u001b[0m | شا\u001b[1m\u001b[31mي\u001b[0mع\u001b[1m\u001b[31mه\u001b[0m | 2\n",
            "(362) ‫ בינהמ | بينهم | بينهم | 0\n",
            "(363) ‫ לאתצאלהמ | لات\u001b[1m\u001b[31mّ\u001b[0mصالهم | لاتصالهم | 1\n",
            "(364) ‫ באלרוחאניאת | بالروحانيات | بالروحانيات | 0\n",
            "(365) ‫ ואנ | و\u001b[1m\u001b[31mإ\u001b[0mن | و\u001b[1m\u001b[31mا\u001b[0mن | 1\n",
            "(366) ‫ יוצפ | يوصف | يوصف | 0\n",
            "(367) ‫ ענהמ | عنهم | عنهم | 0\n",
            "(368) ‫ גראיב | غرا\u001b[1m\u001b[31mئ\u001b[0mب | غرا\u001b[1m\u001b[31mي\u001b[0mب | 1\n",
            "(369) ‫ ומעג'זאת | ومعجزات | ومعجزات | 0\n",
            "(370) ‫ וכראמאת | وكرامات | وكرامات | 0\n",
            "(371) ‫ ולקד | ولقد | ولقد | 0\n",
            "(372) ‫ נרי | نر\u001b[1m\u001b[31mى\u001b[0m | نر\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(373) ‫ אלמנאמאת | المنامات | المنامات | 0\n",
            "(374) ‫ אלצאדקה | الصادق\u001b[1m\u001b[31mة\u001b[0m | الصادق\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(375) ‫ למנ | لمن | لمن | 0\n",
            "(376) ‫ למ | لم | لم | 0\n",
            "(377) ‫ יענ | يعن | يعن | 0\n",
            "(378) ‫ באלעלמ | بالعلم | بالعلم | 0\n",
            "(379) ‫ ולא | ولا | ولا | 0\n",
            "(380) ‫ באצפא | ب\u001b[1m\u001b[31mإ\u001b[0mصفا\u001b[1m\u001b[31mء\u001b[0m | ب\u001b[1m\u001b[31mا\u001b[0mصفا | 2\n",
            "(381) ‫ נפסה | نفسه | نفسه | 0\n",
            "(382) ‫ ונג'ד | ونجد | ونجد | 0\n",
            "(383) ‫ צ'ד | ضد\u001b[1m\u001b[31mّ\u001b[0m | ضد | 1\n",
            "(384) ‫ ד'לכ | ذلك | ذلك | 0\n",
            "(385) ‫ פי | في | في | 0\n",
            "(386) ‫ מנ | من | من | 0\n",
            "(387) ‫ ראמה | رامه | رامه | 0\n",
            "(388) ‫ פדל | فدل\u001b[1m\u001b[31mّ\u001b[0m | فدل | 1\n",
            "(389) ‫ אנ | \u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(390) ‫ ללאמר | لل\u001b[1m\u001b[31mإ\u001b[0mمر | لل\u001b[1m\u001b[31mا\u001b[0mمر | 1\n",
            "(391) ‫ אלאלאהי | ال\u001b[1m\u001b[31mإ\u001b[0mلهي\u001b[1m\u001b[31mّ\u001b[0m | ال\u001b[1m\u001b[31mا\u001b[0mل\u001b[1m\u001b[31mا\u001b[0mهي | 3\n",
            "(392) ‫ וללנפוס | وللنفوس | وللنفوس | 0\n",
            "(393) ‫ סרא | سر\u001b[1m\u001b[31mّ\u001b[0mا\u001b[1m\u001b[31mً\u001b[0m | سرا | 2\n",
            "(394) ‫ סוי | سو\u001b[1m\u001b[31mى\u001b[0m | سو\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(395) ‫ מא | ما | ما | 0\n",
            "(396) ‫ ד'כרתה | ذكرته | ذكرته | 0\n",
            "(397) ‫ יא | يا | يا | 0\n",
            "(398) ‫ פילסופ | فيلسوف | فيلسوف | 0\n",
            "(399) ‫ ת'מ | ثم\u001b[1m\u001b[31mّ\u001b[0m | ثم | 1\n",
            "(400) ‫ קאל | قال | قال | 0\n",
            "(401) ‫ אלכ'זרי | الخزري\u001b[1m\u001b[31mّ\u001b[0m | الخزري | 1\n",
            "(402) ‫ פי | في | في | 0\n",
            "(403) ‫ נפסה | نفسه | نفسه | 0\n",
            "(404) ‫ אסאל | \u001b[1m\u001b[31mإ\u001b[0mس\u001b[1m\u001b[31mإ\u001b[0mل | \u001b[1m\u001b[31mا\u001b[0mس\u001b[1m\u001b[31mا\u001b[0mل | 2\n",
            "(405) ‫ אלנצארי | النصار\u001b[1m\u001b[31mى\u001b[0m | النصار\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(406) ‫ ואלמסלמינ | والمسلمين | والمسلمين | 0\n",
            "(407) ‫ פאנ | ف\u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | ف\u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(408) ‫ אחד | \u001b[1m\u001b[31mإ\u001b[0mحد | \u001b[1m\u001b[31mا\u001b[0mحد | 1\n",
            "(409) ‫ אלעמלינ | العملين | العملين | 0\n",
            "(410) ‫ הו | هو | هو | 0\n",
            "(411) ‫ לא | لا | لا | 0\n",
            "(412) ‫ שכ | شك | شك | 0\n",
            "(413) ‫ אלמרצ'י | المرضي\u001b[1m\u001b[31mّ\u001b[0m | المرضي | 1\n",
            "(414) ‫ ואמא | و\u001b[1m\u001b[31mإ\u001b[0mم\u001b[1m\u001b[31mّ\u001b[0mا | و\u001b[1m\u001b[31mا\u001b[0mما | 2\n",
            "(415) ‫ אליהוד | اليهود | اليهود | 0\n",
            "(416) ‫ פכפי | فكف\u001b[1m\u001b[31mى\u001b[0m | فكف\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(417) ‫ מא | ما | ما | 0\n",
            "(418) ‫ ט'הר | ظهر | ظهر | 0\n",
            "(419) ‫ מנ | من | من | 0\n",
            "(420) ‫ ד'לתהמ | ذل\u001b[1m\u001b[31mّ\u001b[0mتهم | ذلتهم | 1\n",
            "(421) ‫ וקלתהמ | وقل\u001b[1m\u001b[31mّ\u001b[0mتهم | وقلتهم | 1\n",
            "(422) ‫ ומקת | ومقت | ومقت | 0\n",
            "(423) ‫ אלג'מיע | الجميع | الجميع | 0\n",
            "(424) ‫ להמ | لهم | لهم | 0\n",
            "(425) ‫ פדעא | فدعا | فدعا | 0\n",
            "(426) ‫ בעאלמ | بعالم | بعالم | 0\n",
            "(427) ‫ מנ | من | من | 0\n",
            "(428) ‫ עלמא | علما\u001b[1m\u001b[31mء\u001b[0m | علما | 1\n",
            "(429) ‫ אלנצארי | النصار\u001b[1m\u001b[31mى\u001b[0m | النصار\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(430) ‫ פסאלה | فس\u001b[1m\u001b[31mإ\u001b[0mله | فس\u001b[1m\u001b[31mا\u001b[0mله | 1\n",
            "(431) ‫ ענ | عن | عن | 0\n",
            "(432) ‫ עלמה | علمه | علمه | 0\n",
            "(433) ‫ ועמלה | وعمله | وعمله | 0\n",
            "(434) ‫ פקאל | فقال | فقال | 0\n",
            "(435) ‫ לה | له | له | 0\n",
            "(436) ‫ אנא | \u001b[1m\u001b[31mإ\u001b[0mنا | \u001b[1m\u001b[31mا\u001b[0mنا | 1\n",
            "(437) ‫ מומנ | م\u001b[1m\u001b[31mؤ\u001b[0mمن | م\u001b[1m\u001b[31mو\u001b[0mمن | 1\n",
            "(438) ‫ באלחדת' | بالحدث | بالحدث | 0\n",
            "(439) ‫ ללמכ'לוקאת | للمخلوقات | للمخلوقات | 0\n",
            "(440) ‫ ובאלקדמ | وبالقدم | وبالقدم | 0\n",
            "(441) ‫ לכ'אלק | \u001b[1m\u001b[31mل\u001b[0mلخالق | لخالق | 1\n",
            "(442) ‫ תע' | تع\u001b[1m\u001b[31mالى\u001b[0m | تع\u001b[1m\u001b[31m'\u001b[0m | 3\n",
            "(443) ‫ ואנה | و\u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0mه | و\u001b[1m\u001b[31mا\u001b[0mنه | 2\n",
            "(444) ‫ כ'לק | خلق | خلق | 0\n",
            "(445) ‫ אלעאלמ | العالم | العالم | 0\n",
            "(446) ‫ באסרה | ب\u001b[1m\u001b[31mإ\u001b[0mسره | ب\u001b[1m\u001b[31mا\u001b[0mسره | 1\n",
            "(447) ‫ פי | في | في | 0\n",
            "(448) ‫ סתה' | ستة | ستة | 0\n",
            "(449) ‫ איאמ | \u001b[1m\u001b[31mإ\u001b[0mيام | \u001b[1m\u001b[31mا\u001b[0mيام | 1\n",
            "(450) ‫ ואנ | و\u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | و\u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(451) ‫ ג'מיע | جميع | جميع | 0\n",
            "(452) ‫ אלנאטקינ | الناطقين | الناطقين | 0\n",
            "(453) ‫ מנ | من | من | 0\n",
            "(454) ‫ ד'ריה | ذري\u001b[1m\u001b[31mة\u001b[0m | ذري\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(455) ‫ אדמ | \u001b[1m\u001b[31mآ\u001b[0mدم | \u001b[1m\u001b[31mا\u001b[0mدم | 1\n",
            "(456) ‫ ת'מ | ثم\u001b[1m\u001b[31mّ\u001b[0m | ثم | 1\n",
            "(457) ‫ ד'ריה | ذري\u001b[1m\u001b[31mة\u001b[0m | ذري\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(458) ‫ נוח | نوح | نوح | 0\n",
            "(459) ‫ ואליה | و\u001b[1m\u001b[31mإ\u001b[0mليه | و\u001b[1m\u001b[31mا\u001b[0mليه | 1\n",
            "(460) ‫ ינתסבונ | ينتسبون | ينتسبون | 0\n",
            "(461) ‫ כלהמ | كل\u001b[1m\u001b[31mّ\u001b[0mهم | كلهم | 1\n",
            "(462) ‫ ואנ | و\u001b[1m\u001b[31mإ\u001b[0mن\u001b[1m\u001b[31mّ\u001b[0m | و\u001b[1m\u001b[31mا\u001b[0mن | 2\n",
            "(463) ‫ ללה | لله | لله | 0\n",
            "(464) ‫ ענאיה | عناي\u001b[1m\u001b[31mة\u001b[0m | عناي\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(465) ‫ באלכ'לק | بالخلق | بالخلق | 0\n",
            "(466) ‫ ואתצאלא | وات\u001b[1m\u001b[31mّ\u001b[0mصالا\u001b[1m\u001b[31mً\u001b[0m | واتصالا | 2\n",
            "(467) ‫ באלנאטקינ | بالناطقين | بالناطقين | 0\n",
            "(468) ‫ וסכ'טא | وسخطا\u001b[1m\u001b[31mً\u001b[0m | وسخطا | 1\n",
            "(469) ‫ ורצ'א | ورضا\u001b[1m\u001b[31mً\u001b[0m | ورضا | 1\n",
            "(470) ‫ ורחמה | ورحم\u001b[1m\u001b[31mة\u001b[0m | ورحم\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(471) ‫ וכלאמא | وكلاما\u001b[1m\u001b[31mً\u001b[0m | وكلاما | 1\n",
            "(472) ‫ וט'הורא | وظهورا\u001b[1m\u001b[31mً\u001b[0m | وظهورا | 1\n",
            "(473) ‫ ותג'ליא | وتجل\u001b[1m\u001b[31mّ\u001b[0mيا\u001b[1m\u001b[31mً\u001b[0m | وتجليا | 2\n",
            "(474) ‫ לאנביאה | ل\u001b[1m\u001b[31mإ\u001b[0mنبيا\u001b[1m\u001b[31mئ\u001b[0mه | ل\u001b[1m\u001b[31mا\u001b[0mنبياه | 2\n",
            "(475) ‫ ואוליאה | و\u001b[1m\u001b[31mإ\u001b[0mوليا\u001b[1m\u001b[31mئ\u001b[0mه | و\u001b[1m\u001b[31mا\u001b[0mولياه | 2\n",
            "(476) ‫ וחלולא | وحلولا\u001b[1m\u001b[31mً\u001b[0m | وحلولا | 1\n",
            "(477) ‫ פי | في | في | 0\n",
            "(478) ‫ מא | ما | ما | 0\n",
            "(479) ‫ בינ | بين | بين | 0\n",
            "(480) ‫ מנ | من | من | 0\n",
            "(481) ‫ ירצ'אה | يرضاه | يرضاه | 0\n",
            "(482) ‫ מנ | من | من | 0\n",
            "(483) ‫ אלג'מאהיר | الجماهير | الجماهير | 0\n",
            "(484) ‫ ואלג'מלה | والجمل\u001b[1m\u001b[31mة\u001b[0m | والجمل\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(485) ‫ פכל | فكل\u001b[1m\u001b[31mّ\u001b[0m | فكل | 1\n",
            "(486) ‫ מא | ما | ما | 0\n",
            "(487) ‫ ג'א | جا\u001b[1m\u001b[31mء\u001b[0m | جا | 1\n",
            "(488) ‫ פי | في | في | 0\n",
            "(489) ‫ אלתוראה | التورا\u001b[1m\u001b[31mة\u001b[0m | التورا\u001b[1m\u001b[31mه\u001b[0m | 1\n",
            "(490) ‫ ופי | وفي | وفي | 0\n",
            "(491) ‫ את'אר | \u001b[1m\u001b[31mآ\u001b[0mثار | \u001b[1m\u001b[31mا\u001b[0mثار | 1\n",
            "(492) ‫ בני | بني | بني | 0\n",
            "(493) ‫ אסראיל | \u001b[1m\u001b[31mإ\u001b[0mسرا\u001b[1m\u001b[31mئ\u001b[0mيل | \u001b[1m\u001b[31mا\u001b[0mسرايل | 2\n",
            "(494) ‫ אלתי | التي | التي | 0\n",
            "(495) ‫ לא | لا | لا | 0\n",
            "(496) ‫ מדפע | مدفع | مدفع | 0\n",
            "(497) ‫ פי | في | في | 0\n",
            "(498) ‫ צדקהא | صدقها | صدقها | 0\n",
            "(499) ‫ לשהרתהא | لشهرتها | لشهرتها | 0\n",
            "(500) ‫ ודואמהא | ودوامها | ودوامها | 0\n",
            "accuracy:  0.8769578643578643\n",
            "accuracy1:  0.8774193548387097\n",
            "(1) ‫ דאר | دار | دار | 0\n",
            "(2) ‫ אלגזא | ال\u001b[1m\u001b[31mج\u001b[0mزا\u001b[1m\u001b[31mء\u001b[0m | ال\u001b[1m\u001b[31mغ\u001b[0mزا | 2\n",
            "(3) ‫ וקבל | وقبل | وقبل | 0\n",
            "(4) ‫ ד'לכ | ذلك | ذلك | 0\n",
            "(5) ‫ מא | ما | ما | 0\n",
            "(6) ‫ ראי | ر\u001b[1m\u001b[31mأى\u001b[0m | ر\u001b[1m\u001b[31mاي\u001b[0m | 2\n",
            "(7) ‫ אנ | \u001b[1m\u001b[31mأ\u001b[0mن | \u001b[1m\u001b[31mا\u001b[0mن | 1\n",
            "(8) ‫ יפרק | يفر\u001b[1m\u001b[31mّ\u001b[0mق | يفرق | 1\n",
            "(9) ‫ בינ | بين | بين | 0\n",
            "(10) ‫ רוחה | روحه | روحه | 0\n",
            "(11) ‫ וגסמה | و\u001b[1m\u001b[31mج\u001b[0mسمه | و\u001b[1m\u001b[31mغ\u001b[0mسمه | 1\n",
            "(12) ‫ אלי | \u001b[1m\u001b[31mإ\u001b[0mل\u001b[1m\u001b[31mى\u001b[0m | \u001b[1m\u001b[31mا\u001b[0mل\u001b[1m\u001b[31mي\u001b[0m | 2\n",
            "(13) ‫ וקת | وقت | وقت | 0\n",
            "(14) ‫ אסתכמאל | استكمال | استكمال | 0\n",
            "(15) ‫ אלנפוס | النفوس | النفوس | 0\n",
            "(16) ‫ חתי | حت\u001b[1m\u001b[31mى\u001b[0m | حت\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(17) ‫ יגמעהא | ي\u001b[1m\u001b[31mج\u001b[0mمعها | ي\u001b[1m\u001b[31mغ\u001b[0mمعها | 1\n",
            "(18) ‫ אלגמיע | ال\u001b[1m\u001b[31mج\u001b[0mميع | ال\u001b[1m\u001b[31mغ\u001b[0mميع | 1\n",
            "(19) ‫ עלי | عل\u001b[1m\u001b[31mى\u001b[0m | عل\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(20) ‫ מא | ما | ما | 0\n",
            "(21) ‫ בינת | بي\u001b[1m\u001b[31mّ\u001b[0mنت | بينت | 1\n",
            "(22) ‫ פלא | فلا | فلا | 0\n",
            "(23) ‫ נעלמ | نعلم | نعلم | 0\n",
            "(24) ‫ יהודיא | يهودي\u001b[1m\u001b[31mّ\u001b[0mا\u001b[1m\u001b[31mً\u001b[0m | يهوديا | 2\n",
            "(25) ‫ יכ'אלפ | يخالف | يخالف | 0\n",
            "(26) ‫ עלי | عل\u001b[1m\u001b[31mى\u001b[0m | عل\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(27) ‫ הד'ה | هذه | هذه | 0\n",
            "(28) ‫ אלאמאנה | ال\u001b[1m\u001b[31mأ\u001b[0mمان\u001b[1m\u001b[31mة\u001b[0m | ال\u001b[1m\u001b[31mا\u001b[0mمان\u001b[1m\u001b[31mه\u001b[0m | 2\n",
            "(29) ‫ ולא | ولا | ولا | 0\n",
            "(30) ‫ יסתצעב | يستصعب | يستصعب | 0\n",
            "(31) ‫ ענד | عند | عند | 0\n",
            "(32) ‫ עקלה | عقله | عقله | 0\n",
            "(33) ‫ כיפ | كيف | كيف | 0\n",
            "(34) ‫ יחיי | يحيي | يحيي | 0\n",
            "(35) ‫ רבה | رب\u001b[1m\u001b[31mّ\u001b[0mه | ربه | 1\n",
            "(36) ‫ אלמותי | الموت\u001b[1m\u001b[31mى\u001b[0m | الموت\u001b[1m\u001b[31mي\u001b[0m | 1\n",
            "(37) ‫ אד' | \u001b[1m\u001b[31mإ\u001b[0mذ | \u001b[1m\u001b[31mا\u001b[0mذ | 1\n",
            "(38) ‫ קד | قد | قد | 0\n",
            "(39) ‫ צח | صح\u001b[1m\u001b[31mّ\u001b[0m | صح | 1\n",
            "(40) ‫ לה | له | له | 0\n",
            "(41) ‫ אנה | \u001b[1m\u001b[31mأ\u001b[0mنه | \u001b[1m\u001b[31mا\u001b[0mنه | 1\n",
            "(42) ‫ כ'לק | خلق | خلق | 0\n",
            "(43) ‫ שיא | شي\u001b[1m\u001b[31mئ\u001b[0mا\u001b[1m\u001b[31mً\u001b[0m | شيا | 2\n",
            "(44) ‫ לא | لا | لا | 0\n",
            "(45) ‫ מנ | من | من | 0\n",
            "(46) ‫ שי | شي\u001b[1m\u001b[31mء\u001b[0m | شي | 1\n",
            "(47) ‫ פלא | فلا | فلا | 0\n",
            "(48) ‫ יגוז | ي\u001b[1m\u001b[31mج\u001b[0mوز | ي\u001b[1m\u001b[31mغ\u001b[0mوز | 1\n",
            "(49) ‫ אנ | \u001b[1m\u001b[31mأ\u001b[0mن | \u001b[1m\u001b[31mا\u001b[0mن | 1\n",
            "(50) ‫ יסתעסר | يستعسر | يستعسر | 0\n",
            "accuracy:  0.845952380952381\n",
            "accuracy1:  0.8489583333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0.15404761904761904, 0.15104166666666666)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVLQxjcHkq74",
        "colab_type": "text"
      },
      "source": [
        "##test our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1pus1Jr4rLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"DEF general TEST_LOSS\"\n",
        "\n",
        "\n",
        "def test(this_dataset=test_dataset_double_kuzari,only_first=True,limit=False):\n",
        "  num_of_paths=1\n",
        "  total_loss=0\n",
        "  total_accuracy=0\n",
        "  total_examples=0\n",
        "  line_counter=1\n",
        "  if limit:\n",
        "    this_dataset=this_dataset.take(limit)\n",
        "  for input_example_batch, target_example_batch, inputs_len,targets_len in this_dataset:\n",
        "          predictions = model(input_example_batch)                 \n",
        "          logits=tf.transpose(predictions,perm=[1,0,2])    \n",
        "          #loss=tf.nn.ctc_loss_v2(target_example_batch,logits, targets_len,inputs_len,blank_index=targ_lang.char2idx[BLANK])\n",
        "          loss=tf.nn.ctc_loss(target_example_batch,logits, targets_len,inputs_len,blank_index=targ_lang.char2idx[BLANK])\n",
        "          cost = tf.reduce_mean(loss)\n",
        "          total_loss+=cost \n",
        "          \n",
        "          \n",
        "          #decoded, log_probabilities=tf.nn.ctc_beam_search_decoder_v2(\n",
        "          decoded, log_probabilities=tf.nn.ctc_beam_search_decoder(\n",
        "                      logits,\n",
        "                      inputs_len,top_paths=num_of_paths) \n",
        "          dense=tf.sparse.to_dense(decoded[0])\n",
        "            \n",
        "          for i in range(BATCH_SIZE):\n",
        "                heb_input=decode_JA(input_example_batch[i])\n",
        "\n",
        "                heb_input=undouble_hebrew(heb_input).strip(BLANK)\n",
        "                prediction=decode_arr(dense[i]).strip() #SHOULD BE STRING(BLANKS)?\n",
        "                real=decode_arr(target_example_batch[i],targets_len[i].numpy()).strip(BLANK)  \n",
        "                accuracy=editdistance.eval(real, prediction)\n",
        "                accuracy/=len(real)\n",
        "                total_accuracy+=accuracy\n",
        "                if only_first and i!=0: \n",
        "                  continue\n",
        "                real,prediction=show_diff(real,prediction,'red')\n",
        "                print_log_screen(\"({0})\".format(line_counter),LTRchar,heb_input.strip(BLANK),\"|\",real,\"|\",prediction,\"|\",\"{0:.4f}\".format(accuracy))\n",
        "                line_counter+=1\n",
        "\n",
        "          total_examples+=BATCH_SIZE\n",
        "  #total_loss/=total_examples\n",
        "  if total_accuracy!=0:\n",
        "    total_accuracy/=total_examples\n",
        "    print_log_screen(\"LER (label error rate): \",total_accuracy)\n",
        "  #print_log(\"total_test loss: \",total_loss.numpy())\n",
        "  return total_loss.numpy(),total_accuracy\n",
        "\n",
        "#test(limit=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpW54oxAkxCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "8c8c5709-0b9a-4023-e249-329f315e32ec"
      },
      "source": [
        "test(test_dataset_double_kuzari,limit=3)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/ctc_ops.py:1399: alias_inplace_add (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/ctc_ops.py:1382: alias_inplace_update (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.\n",
            "(1) ‫ ואהל אלאדיאנ ת'מ עלי | \u001b[1m\u001b[31mوأهل الأديان ثمّ على\u001b[0m | \u001b[1m\u001b[31mطحطحتحتحتحتحتحتحتحت\u001b[0m | 1.0000\n",
            "(2) ‫ הכד'א כאנ קומה מעה , | \u001b[1m\u001b[31mهكذا كان قومه معه ,\u001b[0m | \u001b[1m\u001b[31mطحطحتحتحتحتحتحتحتح\u001b[0m | 1.0000\n",
            "(3) ‫ תקתצ'י אלמעאני אלתי יריד | ت\u001b[1m\u001b[31mق\u001b[0mت\u001b[1m\u001b[31mضي المعاني ال\u001b[0mت\u001b[1m\u001b[31mي يريد\u001b[0m | \u001b[1m\u001b[31mطحطح\u001b[0mت\u001b[1m\u001b[31mح\u001b[0mت\u001b[1m\u001b[31mح\u001b[0mت\u001b[1m\u001b[31mحتحتحتحتحتحتحت\u001b[0m | 0.9565\n",
            "LER (label error rate):  0.974396171171294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(441.35394, 0.974396171171294)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcIFcI-ghO2f",
        "colab_type": "text"
      },
      "source": [
        "##test guide perplex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DGjAhEUfxbRc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "ef236cff-7da1-4985-b58f-dd41fd8a348a"
      },
      "source": [
        "CELL_NAME=\"GUIDE TEXT\"\n",
        "#NOTICE:there's a mix up compared to the arab translitartaion by attai in the 5 6 raw mark here in brackets\n",
        "\n",
        "###TODO : change hebrew insertion to \"H\"\n",
        "\n",
        "#THIS IS THE ORIGNAL FROM THE GNIZA WEBSITE\n",
        "guide_text='''כנת איהא אלתלמיד' אלעזיז עברית-ר' עברית-יוסף עברית-ש\"צ עברית-ב\"ר \n",
        "עברית-יהודה עברית-נ\"ע למא מת'לת ענדי וקצדת\n",
        " מן אקאצי אלבלאד ללקראה עלי , עט'ם שאנך ענדי לשדהֿ חרצך עלי \n",
        " אלטלב ולמא ראיתה פי אשעארך מן שדה' אלאשתיאק ללאמור אלנט'ריה וכאן ד'לך מנד' וצלתני רסאילך ומקאמאתך מן\n",
        "אלאסכנדריה קבל אן אמתחן\n",
        "תצורך וקלת לעל שוקה אקוי מן אדראכה פלמא קראת עלי מא קד\n",
        "קראתה מן עלם אלהיאה ומא תקדם לך ממא לא בד מנה תוטיה להא מן אלתעאלים \n",
        "זדת בך גבטה לג'ודה' ד'הנך וסרעה' תצורך וראית שוקך ללתעאלים \n",
        "עט'ימא פתרכתך ללארתיאץ' פיהא לעלמי במאלך.   \n",
        "פלמא קראת עלי מא קד קראתה מן צנאעה' אלמנטק תעלקת אמאלי בך \n",
        "וראיתך אהלא לתכשף לך אסראר אלכתב אלנבויה חתי תטלע מנהא עלי מא ינבגי \n",
        "אן יטלע עליה אלכאמלון פאכ'ד'ת אן אלוח לך תלויחאת ואשיר לך באשאראת\n",
        "פראיתך תטלב מני אלאזדיאד וסמתני אן אבין לך אשיא מן אלאמור'''\n",
        "\n",
        "guide_text=re.sub(r'עברית-[^\\s]+', 'H',guide_text)\n",
        "guide_lines=guide_text.split('\\n')\n",
        "\n",
        "for l in guide_lines:\n",
        "  print(LTRchar+l)\n",
        "\n",
        "#AND THIS IS FROM THE SECOND PAGE ON (in attai book)\n",
        "#      אלאלאהיה ואן אכ'ברך בהד'ה מקאצד\n",
        "# אלמתכלמין והל תלך אלטרק ברהאניה ואן לם תכן פמן אי צנאעה הי\n",
        "# וראיתך קד שדות שיא מן ד'לך עלי גירי ואנת חאיר קד בדתך אלדהשה\n",
        "# ונפסך אלשריפה תטאלבך למצא דברי חפץ פלם אזל אדפעך ען ד'לך\n",
        "# ואמרך אן תאכ'ד' אלאשיא עלי תרתיב קצדא מני אן יצח לך אלחק\n",
        "# בטרקה לא אן יקע אליקין באלערץ' ולם אמתנע טאל אג'תמאעך בי אד'א\n",
        "# מא ד'כר עברית-פסוק או נץ מן נצוץ אלחכמים פיה תנביה עלי מעני גריב מן\n",
        "# תביין ד'לך לך . פלמא קדר אללה באלאפתראק ותוג'הת אלי חית' תוג'הת\n",
        "# את'ארת מני תלך אלאג'תמאעאת עזימה קד כאנת פתרת וחרכתני גיבתך\n",
        "# לוצ'ע הד'ה אלמקאלה אלתי וצ'עתהא לך ולאמת'אלך וקלילא מא הם\n",
        "# וג'עלתהא פצולא מנת'ורה וכל מא אנכתב מנהא פהו יצלך אולא אולא\n",
        "# חית' כנת ואנת סאלם'''"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‫כנת איהא אלתלמיד' אלעזיז H H H H \n",
            "‫H H למא מת'לת ענדי וקצדת\n",
            "‫ מן אקאצי אלבלאד ללקראה עלי , עט'ם שאנך ענדי לשדהֿ חרצך עלי \n",
            "‫ אלטלב ולמא ראיתה פי אשעארך מן שדה' אלאשתיאק ללאמור אלנט'ריה וכאן ד'לך מנד' וצלתני רסאילך ומקאמאתך מן\n",
            "‫אלאסכנדריה קבל אן אמתחן\n",
            "‫תצורך וקלת לעל שוקה אקוי מן אדראכה פלמא קראת עלי מא קד\n",
            "‫קראתה מן עלם אלהיאה ומא תקדם לך ממא לא בד מנה תוטיה להא מן אלתעאלים \n",
            "‫זדת בך גבטה לג'ודה' ד'הנך וסרעה' תצורך וראית שוקך ללתעאלים \n",
            "‫עט'ימא פתרכתך ללארתיאץ' פיהא לעלמי במאלך.   \n",
            "‫פלמא קראת עלי מא קד קראתה מן צנאעה' אלמנטק תעלקת אמאלי בך \n",
            "‫וראיתך אהלא לתכשף לך אסראר אלכתב אלנבויה חתי תטלע מנהא עלי מא ינבגי \n",
            "‫אן יטלע עליה אלכאמלון פאכ'ד'ת אן אלוח לך תלויחאת ואשיר לך באשאראת\n",
            "‫פראיתך תטלב מני אלאזדיאד וסמתני אן אבין לך אשיא מן אלאמור\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbZb2SwOhSxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "674d6ce8-cc06-4e7f-a552-587428ecfd99"
      },
      "source": [
        "CELL_NAME=\"DEF TEST_GUIDE\"\n",
        "\n",
        "def test_guide(limit=1000000,num_of_paths=5):\n",
        "  return forward_text(guide_lines,num_of_paths,BATCH_SIZE)\n",
        "print_log_screen(test_guide())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "כנת איהא אלתלמיד' אלעזיז H H H H \n",
            "#####PREDICTION4:  طحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                                               \n",
            "#####PREDICTION3:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتح                                                               \n",
            "#####PREDICTION2:  طحطحطحتحتحتحتحتحتحتحتحتحتحتحت                                                                \n",
            "#####PREDICTION1:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتح                                                               \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحت                                                               \n",
            "H H למא מת'לת ענדי וקצדת\n",
            "#####PREDICTION4:  حطحطحتحتحتحتحتحتحتحتحت                                                                      \n",
            "#####PREDICTION3:  حطحتحتحتحتحتحتحتحتحتحت                                                                      \n",
            "#####PREDICTION2:  طحطحطحتحتحتحتحتحتحتحتح                                                                       \n",
            "#####PREDICTION1:  طحطتحتحتحتحتحتحتحتحتحت                                                                      \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتح                                                                      \n",
            " מן אקאצי אלבלאד ללקראה עלי , עט'ם שאנך ענדי לשדהֿ חרצך עלי \n",
            "#####PREDICTION4:  حطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                       \n",
            "#####PREDICTION3:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                       \n",
            "#####PREDICTION2:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                        \n",
            "#####PREDICTION1:  طحطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                       \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                       \n",
            " אלטלב ולמא ראיתה פי אשעארך מן שדה' אלאשתיאק ללאמור אלנט'ריה וכאן ד'לך מנד' וצלתני רסאילך ומקאמאתך מן\n",
            "#####PREDICTION4:  حطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحش\n",
            "#####PREDICTION3:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحش\n",
            "#####PREDICTION2:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحش\n",
            "#####PREDICTION1:  طحطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتش\n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتش\n",
            "אלאסכנדריה קבל אן אמתחן\n",
            "#####PREDICTION4:  حطحطحتحتحتحتحتحتحتحتحت                                                                      \n",
            "#####PREDICTION3:  طحطتحتحتحتحتحتحتحتحتحت                                                                      \n",
            "#####PREDICTION2:  حطحتحتحتحتحتحتحتحتحتحت                                                                       \n",
            "#####PREDICTION1:  طحطحطحتحتحتحتحتحتحتحتح                                                                      \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتح                                                                      \n",
            "תצורך וקלת לעל שוקה אקוי מן אדראכה פלמא קראת עלי מא קד\n",
            "#####PREDICTION4:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                           \n",
            "#####PREDICTION3:  حطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                           \n",
            "#####PREDICTION2:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                            \n",
            "#####PREDICTION1:  طحطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                           \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                           \n",
            "קראתה מן עלם אלהיאה ומא תקדם לך ממא לא בד מנה תוטיה להא מן אלתעאלים \n",
            "#####PREDICTION4:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                               \n",
            "#####PREDICTION3:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                \n",
            "#####PREDICTION2:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                 \n",
            "#####PREDICTION1:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                               \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                \n",
            "זדת בך גבטה לג'ודה' ד'הנך וסרעה' תצורך וראית שוקך ללתעאלים \n",
            "#####PREDICTION4:  حطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                      \n",
            "#####PREDICTION3:  طحطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                      \n",
            "#####PREDICTION2:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                       \n",
            "#####PREDICTION1:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                      \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                      \n",
            "עט'ימא פתרכתך ללארתיאץ' פיהא לעלמי במאלך.   \n",
            "#####PREDICTION4:  حطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                                     \n",
            "#####PREDICTION3:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                                     \n",
            "#####PREDICTION2:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                                      \n",
            "#####PREDICTION1:  طحطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                                     \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                                     \n",
            "פלמא קראת עלי מא קד קראתה מן צנאעה' אלמנטק תעלקת אמאלי בך \n",
            "#####PREDICTION4:  حطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                        \n",
            "#####PREDICTION3:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                        \n",
            "#####PREDICTION2:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                         \n",
            "#####PREDICTION1:  طحطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                        \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                        \n",
            "וראיתך אהלא לתכשף לך אסראר אלכתב אלנבויה חתי תטלע מנהא עלי מא ינבגי \n",
            "#####PREDICTION4:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                               \n",
            "#####PREDICTION3:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                              \n",
            "#####PREDICTION2:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                \n",
            "#####PREDICTION1:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                              \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                               \n",
            "אן יטלע עליה אלכאמלון פאכ'ד'ת אן אלוח לך תלויחאת ואשיר לך באשאראת\n",
            "#####PREDICTION4:  حطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                \n",
            "#####PREDICTION3:  طحطحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                \n",
            "#####PREDICTION2:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                 \n",
            "#####PREDICTION1:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                \n",
            "פראיתך תטלב מני אלאזדיאד וסמתני אן אבין לך אשיא מן אלאמור\n",
            "#####PREDICTION4:  طحطتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                        \n",
            "#####PREDICTION3:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                       \n",
            "#####PREDICTION2:  حطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                         \n",
            "#####PREDICTION1:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                       \n",
            "#####PREDICTION0:  طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                        \n",
            "\n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحت                                                               \n",
            "طحطحتحتحتحتحتحتحتحتحتح                                                                      \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                       \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتش\n",
            "طحطحتحتحتحتحتحتحتحتحتح                                                                      \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                           \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                      \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                                                     \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                        \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحت                               \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                \n",
            "طحطحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتحتح                                        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpeiuwvnOySt",
        "colab_type": "text"
      },
      "source": [
        "#TRAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqCrkXujeClQ",
        "colab_type": "text"
      },
      "source": [
        "##pre-train letters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq9adhW06Rjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"DEF pretrain_letters\"\n",
        "#train only non-tag letters with cross_entropy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "LEN=10\n",
        "\n",
        "def pretrain_letters(EPOCHS=10000,_BATCH_SIZE=BATCH_SIZE):\n",
        "  \n",
        "  for epoch in range(EPOCHS):\n",
        "    total_loss=0\n",
        "    if STATEFUL:\n",
        "      hidden = model.reset_states()  #needed?\n",
        "    for batch_n in range(30):\n",
        "        inp=[]\n",
        "        target=[]\n",
        "        for i in range(_BATCH_SIZE):\n",
        "          #draw hebrew letter with tag or not. translate to ints   ###SHOULD USE THE DICT #arab_heb_maping\n",
        "          heb_res=[]\n",
        "          arab_res=[]\n",
        "          for jj in range(LEN):\n",
        "            choosen_arr=random.choice(list(arab_heb_maping.keys()))            \n",
        "            choosen_heb=arab_heb_maping[choosen_arr]\n",
        "            if len(choosen_heb)==2:\n",
        "              heb_res.append(choosen_heb[0])\n",
        "            else:\n",
        "              heb_res.append(choosen_heb)\n",
        "            arab_res.append(choosen_arr)       \n",
        "          heb_choosen_int=[inp_lang.char2idx[cr] for cr in heb_res]\n",
        "          arab_choosen_int=[targ_lang.char2idx[cr] for cr in arab_res]              \n",
        "          inp.append(heb_choosen_int)          \n",
        "          target.append(arab_choosen_int)    \n",
        "\n",
        "        inp=tf.convert_to_tensor(inp)\n",
        "        target=tf.convert_to_tensor(target)\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(inp)   \n",
        "            cost = tf.compat.v1.losses.sparse_softmax_cross_entropy(target, predictions)\n",
        "            total_loss+=cost\n",
        "\n",
        "        grads = tape.gradient(cost, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    template = 'Epoch {} Loss {:.4f}'\n",
        "    #test_single_letters()\n",
        "    print_log_screen(template.format(epoch+1,  total_loss))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJQQCzYQPWy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BASIC_MODEL=\"/gdrive/My Drive/checkpoints/BASIC_MODEL_PRETRAIN\"\n",
        "\n",
        "\n",
        "\n",
        "# if not optimizer:\n",
        "#   optimizer = tf.compat.v1.train.RMSPropOptimizer(0.001)\n",
        "\n",
        "# model=load_checkpoint(BASIC_MODEL)\n",
        "# pretrain_letters(10)\n",
        "\n",
        "# save_checkpoint(\"\",ckp_path=BASIC_MODEL)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUMwJyqa6ZA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"TRAIN SINGLE LETTERS AND TEST LETTERS\"\n",
        "# model=rebuild()\n",
        "# test_single_letters()\n",
        "# optimizer = tf.compat.v1.train.RMSPropOptimizer(0.001)\n",
        "# pretrain_letters(10,BATCH_SIZE)\n",
        "# test_single_letters()\n",
        "# save_checkpoint(\"testing1\")\n",
        "# model=rebuild()\n",
        "# test_single_letters()\n",
        "# model=load_checkpoint()\n",
        "# test_single_letters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaFWkYAG99Du",
        "colab_type": "text"
      },
      "source": [
        "##train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZNb9x9W6bS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"DEF main TRAIN_LOOP\"\n",
        "\n",
        "\n",
        "#A SINGLE EPOCH\n",
        "def train(cur_dataset=dataset_double_kuzari,stop_loop=10000000000):\n",
        "  global GLOBAL_epoch\n",
        "  if STATEFUL:\n",
        "    hidden = model.reset_states()\n",
        "  total_loss=0\n",
        "  for (batch_n, (inp, target,input_lens,target_lens)) in enumerate(cur_dataset):\n",
        "        if batch_n>stop_loop:\n",
        "          break\n",
        "        with tf.GradientTape() as tape:            \n",
        "            predictions = model(inp)                \n",
        "            #labels=tf.cast(target, tf.int32) #need?\n",
        "            logits=tf.transpose(predictions,perm=[1,0,2])  \n",
        "            loss=tf.nn.ctc_loss(target,logits, target_lens,input_lens,blank_index=targ_lang.char2idx[BLANK])              \n",
        "            \n",
        "            cost = tf.reduce_mean(loss)\n",
        "            total_loss+=cost\n",
        "\n",
        "        grads = tape.gradient(cost, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        if batch_n % 10 == 0:\n",
        "            template = 'Epoch {} Batch {} Loss {:.4f}'\n",
        "            print_log_screen(template.format(GLOBAL_epoch+1, batch_n, cost))\n",
        "  GLOBAL_epoch+=1\n",
        "  return total_loss.numpy()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtlmUGP0i-uA",
        "colab_type": "text"
      },
      "source": [
        "#MAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiPPcVK2jDyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"MAIN\"\n",
        "\n",
        "##############################################\n",
        "####RUN PARAMETERS:\n",
        "mail_subject=\"NOT STATEFULL: pretrain letters. synt DROPOUT 0.9 no KUZARI\"\n",
        "mail_subject=this_time+\":\"+mail_subject\n",
        "\n",
        "pretrain_letter=15\n",
        "synth=True\n",
        "keep_percent=0.85\n",
        "\n",
        "description=\"\\n\"+\"pretrain: \"+str(pretrain_letter)+\"\\n\"+ \\\n",
        "    (\"no synth\" if not synth else \"with synth data\")+ \\\n",
        "    \"\\n\"+\"dropout:\"+str(keep_percent) +\"\\n\"\n",
        "print_log_screen(description)\n",
        "#################################\n",
        "\n",
        "#INIT\n",
        "BEST_ACCURACY=1\n",
        "f= open(\"my_log.txt\",\"w+\") #attach to mail summary of tests\n",
        "init_random()\n",
        "\n",
        "losses=[]\n",
        "test_losses=[]\n",
        "accuracys=[]\n",
        "\n",
        "model=rebuild()\n",
        "\n",
        "optimizer = tf.compat.v1.train.RMSPropOptimizer(0.001)\n",
        "\n",
        "###################################\n",
        "####PRETRAIN\n",
        "if pretrain_letter>0:\n",
        "  print_log_screen(\"PRETRAIN\")\n",
        "  pretrain_letters(pretrain_letter,BATCH_SIZE)\n",
        "  print_log_screen('-'*200)\n",
        "##################################\n",
        "print_log_screen(\"START TRAIN\")\n",
        "\n",
        "for jjj in range(10): #after each of this iterations - send mail and calc full test\n",
        "  for i in range(3): #iter without sendmail and only partial test    \n",
        "    if keep_percent<1:\n",
        "        train_dataset_double_kuzari= produce_dataset(\n",
        "            create_parralel_phrases(kuzari_lines_train,keep_percent),\n",
        "            to_shuffle=TO_SHUFFLE)        \n",
        "    if synth:\n",
        "      dataset_double_synt=gen_all_synth(keep_percent).concatenate(dataset_double_kuzari).shuffle(BUFFER_SIZE)\n",
        "      loss=train(dataset_double_synt,stop_loop=350)\n",
        "    else:\n",
        "      loss=train(train_dataset_double_kuzari)\n",
        "    \n",
        "    #total_test_loss,total_accuracy=test(single_words_test_dataset,limit=5)\n",
        "    \n",
        "    total_test_loss,total_accuracy=test(limit=5)\n",
        "    test(this_dataset=test_dataset_double_rasag,limit=5)\n",
        "\n",
        "    #losses.append(loss)\n",
        "    #test_losses.append(total_test_loss)\n",
        "    #accuracys.append(total_accuracy)\n",
        "    # print ('Epoch {} Loss {:.4f} Test Loss {:.4f} accuracy {:.4f}' \\\n",
        "    #        .format(GLOBAL_epoch, loss, total_test_loss,total_accuracy))    \n",
        "       \n",
        "    print_log_screen('-'*200)\n",
        "    test_kfir(kfir_kuzari_test,False)\n",
        "    test_kfir(kfir_rasag_test,False)\n",
        "    print_log_screen('-'*200)\n",
        "    \n",
        "  print_log('FULL STATISTICS')\n",
        "  print_log('='*200)\n",
        "  test_kfir(kfir_kuzari_test,False,True)  \n",
        "  test_kfir(kfir_rasag_test,False,True)\n",
        "  #TESTING ALL EVERY OUTER LOOP \n",
        "  all_test_loss,all_accuracy=test()\n",
        "  #shuffle_loss,shuffle_accuracy=test_shuffle()\n",
        "  all_test_loss1,all_accuracy1=test(test_dataset_double_rasag)  #HAEMUNOT VEHADEOT\n",
        "  #shuffle_loss1,shuffle_accuracy1=test_shuffle(shuffle_test_dataset_double_rasag)\n",
        "  \n",
        "  \n",
        "  guide_result=test_guide()\n",
        "  \n",
        "  #TODO SAVE CHECKPOINT\n",
        "  if all_accuracy<BEST_ACCURACY:\n",
        "    save_checkpoint(\"improvement in accuracy. Current LER on KUZARI test data: \"+str(all_accuracy))\n",
        "    BEST_ACCURACY=all_accuracy\n",
        "\n",
        "#  my_plot_save(losses,\"train.png\",decor='r--')\n",
        "#  my_plot_save(test_losses,\"test.png\",decor='b-')\n",
        "#  my_plot_save(accuracys,\"accuracys.png\",decor='g-')\n",
        "  \n",
        "  print_log(\"full test: loss \",all_test_loss,\" accuracy \",all_accuracy)\n",
        "  print_log(\"full test (HAEMUNOT): loss \",all_test_loss1,\" accuracy \",all_accuracy1)\n",
        "\n",
        " # print_log(\"shuffle test (HAEMUNOT): loss \",shuffle_loss1,\" accuracy \",shuffle_accuracy1)\n",
        "  print('='*200)\n",
        "  print('CONTINUE TRAINING')\n",
        "\n",
        "  # for l,t,a in zip(losses,test_losses,accuracys):\n",
        "  #   print(l,t,a)\n",
        "  #   f.write(\"%.3f %.3f %.6f\\r\\n\" % (l,t,a))\n",
        "  \n",
        "  f.write(\"EPOCH \"+str(GLOBAL_epoch)+'\\n')\n",
        "  f.write(\"full test: loss %.6f accuracy %.6f\\r\\n\" % (all_test_loss,all_accuracy))\n",
        "  f.write(\"full test (HAEMUNOT): loss  %.6f accuracy %.6f\\r\\n\" % (all_test_loss1,all_accuracy1))\n",
        "  #f.write(\"shuffle test (HAEMUNOT): loss %.6f accuracy %.6f\\r\\n\" % (shuffle_loss1,shuffle_accuracy1))\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #[(l,t,a) for l,t,a in zip(losses,test_losses,accuracys)]\n",
        "  \n",
        "  log_flush()\n",
        "  f.flush()\n",
        "  send_results(mail_subject,str(all_accuracy)+'\\n'+str(all_accuracy1)+description+'\\n\\n'+guide_result)\n",
        "\n",
        "\n",
        "  \n",
        "f.close()\n",
        "close_log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwpwDinoeIu5",
        "colab_type": "text"
      },
      "source": [
        "#MAIN OUTPUT (ABOVE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdj5RlXokVZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test()\n",
        "#test(test_dataset_double_rasag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFG_Z9-HjEVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_guide()\n",
        "# test_shuffle()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj4qfAwZhuDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXh1zFNmDjX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(50):\n",
        "#   train()\n",
        "#   test(single_words_test_dataset,limit=5)\n",
        "#   test(limit=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcQWJJJiGMYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # test(only_first=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ukMRiAym05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(this_dataset=test_dataset_double_kuzari,only_first=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPjO2JYZhw02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffle_loss,shuffle_accuracy=test_shuffle()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxrgk68_hwBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  shuffle_loss1,shuffle_accuracy1=test_shuffle(shuffle_test_dataset_double_rasag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVg68eKuh2eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(this_dataset=test_dataset_double_rasag,only_first=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBxC8ziVJuTe",
        "colab_type": "text"
      },
      "source": [
        "test_guide(limit=3)TESTTtttt#TODO\n",
        "\n",
        "\n",
        "1.   varied length for data - to makes the system more robust for sentneces with different lengths. can do this with SENTENCE_LIMIT=20 set to random limit when sentences length exceedes current limit\n",
        "\n",
        "2.   abstraction for the testing functions (see comparesment in notpad++)\n",
        "\n",
        "3.   try TPU\n",
        "\n",
        "4.   new idea: input - arab baseline. train network to correct it\n",
        "\n",
        "5.    predict only middle word. input (1 true arab words) - (2 arab baseline word) - (3 true arab words) output - the middle word in corrected arab.\n",
        "\n",
        "or calc results only on middle word(s)\n",
        "\n",
        "6.   transformer (see tf tutorial)\n",
        "\n",
        "7.    NEW AND INTERESTING!!!!!: add space to each line at start and at end\n",
        "so the network knows this is end of word!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zcZ9IdHq23e",
        "colab_type": "text"
      },
      "source": [
        "#OLD STAFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIrBodSVerlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"SMALL TRY\"\n",
        "\n",
        "# this_string='وأهل الأديان ثمّ على'\n",
        "# this_string='سُئِلْتُ عمّا عنديَ من الاحتجاج'\n",
        "# this_string='ثمّ'\n",
        "\n",
        "# #this_string='كان عند مَلِك الخَزَرِ الداخل'\n",
        "# print_log_screen(len(this_string))\n",
        "# this_string=normalize_unicode(remove_arab_nikud(this_string)) #new!!!!\n",
        "\n",
        "# print_log_screen(len(this_string))\n",
        "# this_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBvz3vMxLIH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"TRY SYNTH\"\n",
        "\n",
        "# #ACTIVATE\n",
        "# ibnsina_text=load_lines_synth()\n",
        "\n",
        "# #STATSTICS OF SYNTH TEXT\n",
        "# sina_vocab=sorted(set(ibnsina_text))\n",
        "\n",
        "# print_log(\"NOT IN LETTER LIST:\")\n",
        "# for c in sina_vocab:\n",
        "#    if c not in targ_lang.char2idx:\n",
        "#       print_log(\"(\",c,\")\")\n",
        "\n",
        "# print_log(\"\\nLETTER COUNTS\")\n",
        "# for i in range(len(sina_vocab)):\n",
        "#   print_log(LTRchar,i,'\"',sina_vocab[i],'\"',ibnsina_text.count(sina_vocab[i])) #64 is shadda   \n",
        "\n",
        "# #ibnsina_text=ibnsina_text.replace(\"\\r\\n\\r\\n\",\"\\r\\n\").replace(\"\\r\\n\",\" \\r\\n \") #TODO rethink this\n",
        "# #sina_words=ibnsina_text.split(\" \")\n",
        "# #ibnsina_text=ibnsina_text.replace(\"\\r\\n\\r\\n\",\"\\r\\n\").replace(\"\\r\\n\",\". \") #TODO rethink this\n",
        "# sina_words=ibnsina_text.split() #for removing also newlines\n",
        "# print_log(ibnsina_text[:100])\n",
        "# sina_words[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMQxNPpy_MXA",
        "colab_type": "text"
      },
      "source": [
        "##Shuffled test (NOT USED NOW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wjB8kq4zAli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"SHUFFLED TEST\"\n",
        "\n",
        "# def get_shuffled_word_pairs(test_dataset):\n",
        "  \n",
        "#   val_inputs_list=[]\n",
        "#   val_outputs_list=[]\n",
        "\n",
        "#   for i,j,l1,l2 in test_dataset:\n",
        "#     for tt in range(BATCH_SIZE):\n",
        "#      # print_log(i[tt],j[tt])\n",
        "#       i_prediction=decode_JA(tf.constant(i[tt]),l1[tt])\n",
        "#       j_prediction=decode_arr(tf.constant(j[tt]),l2[tt])      \n",
        "#       if (len(i_prediction.split())==len(j_prediction.split())):\n",
        "#         val_inputs_list+=i_prediction.split()\n",
        "#         val_outputs_list+=j_prediction.split()\n",
        "    \n",
        "#   print_log(\"len(val_inputs_list),len(val_outputs_list)\",len(val_inputs_list),len(val_outputs_list)) #10836 10836\n",
        "\n",
        "#   word_pairs=list(zip(val_inputs_list,val_outputs_list))\n",
        "#   print_log(\"BEFORE SHUFFLE\")\n",
        "#   for i in word_pairs[:5]:\n",
        "#     print_log(i)\n",
        "#   random.shuffle(word_pairs)\n",
        "#   print_log(\"AFTER SHUFFLE\")\n",
        "#   for i in word_pairs[:5]:\n",
        "#     print_log(i)\n",
        "#   return word_pairs\n",
        "\n",
        "# #TESTING\n",
        "# #word_pairs1=get_shuffled_word_pairs(test_dataset_double_rasag.take(1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXrW_yjRZS_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"DEF GET SHUFFLE DATA\"\n",
        "# def get_shuffled_data(word_pairs):\n",
        "\n",
        "#   accum=0\n",
        "#   heb_acum=\"\"\n",
        "#   arab_acum=\"\"\n",
        "#   results_line=[]\n",
        "#   for i,j in word_pairs:\n",
        "#     if accum>19:\n",
        "#       results_line.append(undouble_hebrew(heb_acum)+'\\t'+arab_acum)\n",
        "#       assert(len(i)%2==0)\n",
        "#       accum=len(i)/2\n",
        "#       heb_acum=i\n",
        "#       arab_acum=j\n",
        "#     else:\n",
        "#       heb_acum+=\" \"+i\n",
        "#       arab_acum+=\" \"+j \n",
        "#       assert(len(i)%2==0)\n",
        "#       accum += len(i)/2 + 1;\n",
        "#   results_line.append(heb_acum+'\\t'+arab_acum)  #needed?\n",
        "\n",
        "#   print_log(\"len(results_line)\",len(results_line)) # 2175 before was: 2185 lines \n",
        "\n",
        "\n",
        "#   input_tensor_shuffle, target_tensor_shuffle \\\n",
        "#   ,input_lenghts_shuffle,target_lengths_shuffle = create_data_tensors(create_parralel_phrases(results_line))\n",
        "\n",
        "#   print_log(\"len(input_tensor_shuffle), len(input_lenghts_shuffle)\",len(input_tensor_shuffle), len(input_lenghts_shuffle))\n",
        "#   print_log(\"len(target_tensor_shuffle),  len(target_lengths_shuffle)\",len(target_tensor_shuffle), len(target_lengths_shuffle))\n",
        "\n",
        "#   BUFFER_SIZE = len(target_lengths_shuffle)\n",
        "\n",
        "#   shuffle_test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_shuffle,\n",
        "#                                                             target_tensor_shuffle,\n",
        "#                                                             input_lenghts_shuffle,\n",
        "#                                                             target_lengths_shuffle)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "#   shuffle_test_dataset_double=shuffle_test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "#   return shuffle_test_dataset_double\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QPdoa03o6gD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CELL_NAME=\"GEN SHUFFLED DATA\"\n",
        "\n",
        "# word_pairs=get_shuffled_word_pairs(test_dataset_double_kuzari)\n",
        "# shuffle_test_dataset_double=get_shuffled_data(word_pairs)\n",
        "# view_data(shuffle_test_dataset_double)\n",
        "\n",
        "\n",
        "# word_pairs1=get_shuffled_word_pairs(test_dataset_double_rasag)\n",
        "# shuffle_test_dataset_double_rasag=get_shuffled_data(word_pairs1)\n",
        "# view_data(shuffle_test_dataset_double_rasag)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jI08UDJhkS9",
        "colab_type": "text"
      },
      "source": [
        "##test shuffle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSpgkEQxhmFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"DEF TEST_SHUFFLE\"\n",
        "# def test_shuffle(data=shuffle_test_dataset_double,limit=False):\n",
        "#   return test(this_dataset=data,limit=limit)\n",
        "# #shuffle_loss,shuffle_accuracy=test_shuffle(limit=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFLoKpwg9rJ6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Single words test (NOT USED NOW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSr5HALl9qDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CELL_NAME=\"GEN SINGEL WORDS\"\n",
        "\n",
        "# # results_line=[]\n",
        "# # for i,j in word_pairs:\n",
        "# #     results_line.append(undouble_hebrew(i)+'\\t'+j)\n",
        "\n",
        "# # print_log(\"len(results_line)\",len(results_line)) \n",
        "\n",
        "\n",
        "# # input_tensor_shuffle, target_tensor_shuffle \\\n",
        "# # , input_lenghts_shuffle,target_lengths_shuffle = create_data_tensors(create_parralel_phrases(results_line))\n",
        "\n",
        "# # print_log(\"len(input_tensor_shuffle), len(target_tensor_shuffle), len(input_lenghts_shuffle), len(target_lengths_shuffle)\",len(input_tensor_shuffle), len(target_tensor_shuffle), len(input_lenghts_shuffle), len(target_lengths_shuffle))\n",
        "\n",
        "# # BUFFER_SIZE = len(target_lengths_shuffle)\n",
        "\n",
        "# # single_words_test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_shuffle,\n",
        "# #                                                                 target_tensor_shuffle,\n",
        "# #                                                                 input_lenghts_shuffle,\n",
        "# #                                                                 target_lengths_shuffle)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# # single_words_test_dataset=single_words_test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# # view_data(single_words_test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}